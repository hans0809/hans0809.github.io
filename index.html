<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>南极Python - Python|机器学习|深度学习</title><meta name="keywords" content="Python|机器学习|深度学习|生活感悟"><meta name="author" content="雨落诗山山亦奇"><meta name="copyright" content="雨落诗山山亦奇"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本站为读研版&amp;工作版博客，大学版移步 --&gt; fuhanshi.github.io">
<meta property="og:type" content="website">
<meta property="og:title" content="南极Python">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="南极Python">
<meta property="og:description" content="本站为读研版&amp;工作版博客，大学版移步 --&gt; fuhanshi.github.io">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png">
<meta property="article:author" content="雨落诗山山亦奇">
<meta property="article:tag" content="Python|机器学习|深度学习|生活感悟">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png"><link rel="shortcut icon" href="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png"><link rel="canonical" href="http://yoursite.com/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '南极Python',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-02-24 20:50:47'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/macblack.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">167</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div></div><hr/></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/tag1.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">南极Python</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">南极Python</h1><div id="site-subtitle"><span id="subtitle"></span></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2025/02/20/%E4%BB%8E%E7%A6%BB%E6%95%A3%E7%9A%84tokenID%E5%88%B0%E5%85%B7%E6%9C%89%E8%AF%AD%E4%B9%89%E4%BF%A1%E6%81%AF%E7%9A%84embedding-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%BA%8C)/" title="从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)"><img class="post_bg" src="https://i.miji.bid/2025/02/20/14ccff2337c64f4aef4ba366814fd5e2.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/02/20/%E4%BB%8E%E7%A6%BB%E6%95%A3%E7%9A%84tokenID%E5%88%B0%E5%85%B7%E6%9C%89%E8%AF%AD%E4%B9%89%E4%BF%A1%E6%81%AF%E7%9A%84embedding-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%BA%8C)/" title="从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)">从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-02-20T14:28:29.000Z" title="发表于 2025-02-20 22:28:29">2025-02-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF/">大模型炼丹术</a></span></div><div class="content">在完成了tokenization之后，我们已经可以将一个个的单词映射到对应的数字，称之为token ID，这些数字已经可以被计算机处理。然而，若直接将这些数字应用于模型训练，仍存在一些问题：

缺乏语义信息： Token ID 只是一个索引，本身不包含任何语义信息。例如，“cat” 可能被映射为 ID 1254，而 “dog” 是 ID 3920，这两个 ID 之间的数值关系是无意义的。直接使用它们可能会导致模型误解 token 之间的关联性。

整数之间的数值关系会误导模型： 机器学习模型通常会学习数据之间的模式。如果直接输入 token ID，模型可能会误以为 ID 1254（”cat”）和 ID 3920（”dog”）之间存在某种数学关系（如加减乘除），但实际上 ID 只是索引，没有数值上的逻辑关系。

无法捕捉相似 token 的关系 语义相近的 token 在 embedding 空间中应该具有接近的表示。例如，”king” 和 “queen” 应该在高维空间中比较接近，而 “apple” 和 “computer” 应该相距较远。然而，单纯的 token ID 无法提供这种分 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2025/02/20/%E4%BB%8Etokenizer%E8%AF%B4%E8%B5%B7%EF%BC%8C%E4%B8%BALLM%E8%87%AA%E5%9B%9E%E5%BD%92%E9%A2%84%E8%AE%AD%E7%BB%83%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%B8%80)/" title="从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)"><img class="post_bg" src="https://i.miji.bid/2025/02/20/14ccff2337c64f4aef4ba366814fd5e2.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/02/20/%E4%BB%8Etokenizer%E8%AF%B4%E8%B5%B7%EF%BC%8C%E4%B8%BALLM%E8%87%AA%E5%9B%9E%E5%BD%92%E9%A2%84%E8%AE%AD%E7%BB%83%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%B8%80)/" title="从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)">从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-02-20T14:28:29.000Z" title="发表于 2025-02-20 22:28:29">2025-02-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF/">大模型炼丹术</a></span></div><div class="content">本文首先介绍了如何从头开始实现一个自定义tokenizer，用于将原始文本数据转化为模型能够理解的格式。通过这个例子，来直观理解什么是tokenize；接着，分析这种tokenizer的优缺点，引出更常用的BPE；最后，基于BPE构建的tokenizer，构建用于GPT预训练时的数据加载器。
在阅读完本文后，你将学会如何构建用于GPT自回归预训练阶段的数据加载器，这将是你向着LLM训练迈出的第一步！
一、先动手，编写自定义tokenizerstep1. 读取语料读取the-verdict.txt:
12345with open(&quot;the-verdict.txt&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:    raw_text = f.read()    print(&quot;Total number of character:&quot;, len(raw_text))print(raw_text[:99])
输出：
12Total number of character: 20479I HAD alwa ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/12/30/%E6%8A%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%90%AC%E5%88%B0GPU-%E8%8B%B1%E4%BC%9F%E8%BE%BEDALI%E5%8A%A0%E9%80%9F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" title="把数据预处理搬到GPU-英伟达DALI加速数据预处理"><img class="post_bg" src="https://ice.frostsky.com/2024/12/30/88a897ed803ad9cb7462f4320a31ac67.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="把数据预处理搬到GPU-英伟达DALI加速数据预处理"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/12/30/%E6%8A%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%90%AC%E5%88%B0GPU-%E8%8B%B1%E4%BC%9F%E8%BE%BEDALI%E5%8A%A0%E9%80%9F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" title="把数据预处理搬到GPU-英伟达DALI加速数据预处理">把数据预处理搬到GPU-英伟达DALI加速数据预处理</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-12-30T13:32:21.000Z" title="发表于 2024-12-30 21:32:21">2024-12-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">在执行模型前向推理时，往往涉及到一些列数据预处理操作，比如Resize，Normalize等，这些操作通常在CPU上完成，然后CPU将预处理后的图片传送到GPU上执行推理。
由于GPU的运算速度远快于CPU，所以能不能将这些数据预处理操作放到GPU上执行从而加快数据加载的速度呢？
NVIDIA DALI 可以！
NVIDIA DALI (Data Loading Library) 是一个加速数据加载和预处理的库，专为深度学习任务设计。它能将图像和视频的复杂预处理操作（尤其是在模型训练阶段，通常涉及大量的数据增强预处理操作）从 CPU 转移到 GPU 上，从而减少数据加载瓶颈，提升 GPU 的利用率。DALI 支持多种格式（如 JPEG、PNG、TFRecord 等），并能与主流深度学习框架（如 PyTorch 和 TensorFlow）无缝集成，使得数据预处理和模型前向推理可以高效并行进行。
本文介绍DALI的使用方法，以及如何将PyTorch的数据加载器替换成DALI的数据加载器，并测试加速效果。
安装NVIDIA DALI对于CUDA 11.x，执行如下命令行：
1pip inst ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/12/07/PyTorch%E8%BD%ACTensorRT-engine%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%95%99%E7%A8%8B/Markdown%20_%20%E8%AE%A9%E6%8E%92%E7%89%88%E5%8F%98%20Nice/" title="无题"><img class="post_bg" src="/img/tag1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/12/07/PyTorch%E8%BD%ACTensorRT-engine%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%95%99%E7%A8%8B/Markdown%20_%20%E8%AE%A9%E6%8E%92%E7%89%88%E5%8F%98%20Nice/" title="无题">无题</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-12-07T07:43:12.125Z" title="发表于 2024-12-07 15:43:12">2024-12-07</time></span></div><div class="content">


.anticon {
  display: inline-block;
  color: inherit;
  font-style: normal;
  line-height: 0;
  text-align: center;
  text-transform: none;
  vertical-align: -0.125em;
  text-rendering: optimizeLegibility;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

.anticon > * {
  line-height: 1;
}

.anticon svg {
  display: inline-block;
}

.anticon::before {
  display: none;
}

.anticon .anticon-icon {
  display: block;
}

.anticon[tabindex] {
  cursor: pointer;
}

.ant ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/12/07/%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%E5%85%A5%E9%97%A8%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" title="万字长文入门扩散模型"><img class="post_bg" src="https://ice.frostsky.com/2024/12/07/bf4bfcbe17c50e1fcbc8d26acfac57c8.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="万字长文入门扩散模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/12/07/%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%E5%85%A5%E9%97%A8%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" title="万字长文入门扩散模型">万字长文入门扩散模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-12-07T06:51:51.000Z" title="发表于 2024-12-07 14:51:51">2024-12-07</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">扩散模型问世至今，因其训练过程的稳定性和生成样本的多样性，受到了广泛的关注和应用，相应的开源社区贡献的工具链也趋向于更易用，HuggingFace的diffusers库便是其中之一。
diffusers提供了非常简洁和直观的API接口，能够让研究人员和开发者快速实现扩散模型的训练和推理。即便是对扩散模型不太熟悉的用户，也能通过少量的代码实现高效的图像生成任务。
本文基于diffusers，包含如下内容：
1.通过一个简易demo来直观感受使用diffusers中的快速生图的方法
2.使用smithsonian_butterflies_subset数据集，通过diffusers来搭建一个完整的图像生成小项目，包括数据集准备、模型训练、模型推理等步骤
3.介绍如何基于已有的预训练权重，通过微调和引导技术，来控制生成图片整体的细节走向，如颜色偏好，内容偏好等
4.介绍火出圈的StableDiffusion
5.介绍DDIM反转，用于控制图像的局部区域生成细节走向，该技术极大地提高了扩散模型的可玩性
零. 准备工具函数首先，导入常用的库，并编写后续将被重复使用的工具函数，用于图像可视化。
12 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/10/27/%E4%BD%BF%E7%94%A8%E5%8E%9F%E7%94%9FTensortRT-API%E5%8A%A0%E9%80%9F%E6%8E%A8%E7%90%86/" title="使用原生TensortRT-API加速推理"><img class="post_bg" src="https://ice.frostsky.com/2024/10/27/fddae99226a3fef4f567cd1922aef787.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用原生TensortRT-API加速推理"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/10/27/%E4%BD%BF%E7%94%A8%E5%8E%9F%E7%94%9FTensortRT-API%E5%8A%A0%E9%80%9F%E6%8E%A8%E7%90%86/" title="使用原生TensortRT-API加速推理">使用原生TensortRT-API加速推理</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-10-27T04:49:43.000Z" title="发表于 2024-10-27 12:49:43">2024-10-27</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">Polygraphy 是构建在 TensorRT API 之上的高级工具，简化了一些常见的操作，特别是模型转换、性能分析和调试。Polygraphy 提供了更高层次的抽象，使得许多复杂的操作更加简便和自动化。在上一篇文章中，我们已经基于Polygraphy实现了对于PyTorch模型–&gt;TensorRT的推理加速。
然而，原生的TensorRT API提供了更低层的 API，允许用户对引擎的每一步（包括构建、优化、推理）进行更细致的控制。因此，本文将使用原生的TensorRT API，重新梳理将PyTorch模型转换为TensorRT的详细步骤。
本文目标基于官方的demo，将FC-ResNet101的PyTorch模型转换为TensorRT 的engine，演示如何使用原生TensorRT API而非Polygraphy实现PyTorch模型的推理加速。
操作步骤step1. 环境搭建在上一篇环境搭建的基础上，需要额外安装pycuda工具包：
1pip install pycuda

step2. 执行转换step2.1 定义模型123456789101112131415161 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/10/25/PyTorch%E8%BD%ACTensorRT-engine%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%95%99%E7%A8%8B/" title="PyTorch转TensorRT-engine保姆级教程"><img class="post_bg" src="https://s21.ax1x.com/2024/04/22/pk9nSiQ.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PyTorch转TensorRT-engine保姆级教程"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/10/25/PyTorch%E8%BD%ACTensorRT-engine%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%95%99%E7%A8%8B/" title="PyTorch转TensorRT-engine保姆级教程">PyTorch转TensorRT-engine保姆级教程</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-10-25T11:49:44.000Z" title="发表于 2024-10-25 19:49:44">2024-10-25</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">torch2onnx2trt使用指南-详细版本在模型训练完成后，所得到的权重往往存在一定的冗余，在基于该权重进行推理时，会消耗一部分时间来执行这些冗余部分的前向传播过程。
通过一些技术手段来减少这些冗余，往往可以在保证推理结果准确性的基础上获得一定程度的推理效率提升。
TensorRT 是 NVIDIA 开发的高性能深度学习推理优化器，专为加速神经网络推理而设计。使用TensorRT ，能够将模型权重转换为高效的推理引擎，显著提升推理速度和降低延迟，适用于各种深度学习应用。
以下是我在RTX3060显卡上使用TensorRT前后测试的单模型推理时间结果：



模型格式
前向推理时间(单位：s)



PyTorch
51s


ONNX
44s


TensorRT Engine(FP32)
35s


TensorRT Engine(FP16)
15s


可以看到，借助TensorRT，在保持模型全精度(FP32)的前提下，前向推理时间降低为原来的32%，加速比为145%；如果进一步开启半精度(FP16)，前向推理时间可以降低为原来的70%，加速比达到了340%。
本文目标将训练 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/09/03/%E5%A6%82%E4%BD%95%E7%9B%91%E6%8E%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%97%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E4%BF%A1%E6%81%AF/" title="如何监控模型推理时的系统状态信息"><img class="post_bg" src="https://s21.ax1x.com/2024/05/04/pkAljWq.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何监控模型推理时的系统状态信息"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/09/03/%E5%A6%82%E4%BD%95%E7%9B%91%E6%8E%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%97%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E4%BF%A1%E6%81%AF/" title="如何监控模型推理时的系统状态信息">如何监控模型推理时的系统状态信息</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-03T13:00:05.000Z" title="发表于 2024-09-03 21:00:05">2024-09-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">在使用训练好的深度学习模型进行推理时，为了了解推理过程中所使用的系统资源信息，如CPU利用率、GPU利用率等，往往需要一个监控工具。
对于CPU利用率，可以使用psutil库获取：
1psutil.cpu_percent(interval=1, percpu=False)

封装成函数：
12345678def get_cpu_utilization():    try:        cpu_utilization = psutil.cpu_percent(interval=1, percpu=False)        return cpu_utilization    except Exception as e:        print(f&quot;Error while fetching CPU utilization: &#123;e&#125;&quot;)        return []

对于GPU利用率，可以使用命令行工具 nvidia-smi获取，封装成函数：
12345678910def get_gpu_utilization():    try:      ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/06/01/Transformer%E7%9A%84Decoder%E5%9C%A8%E8%AE%AD%E7%BB%83%E5%92%8C%E6%8E%A8%E7%90%86%E9%98%B6%E6%AE%B5%E7%9A%84%E5%BC%82%E5%90%8C%E7%82%B9%E6%80%BB%E7%BB%93/" title="Transformer的Decoder在训练和推理阶段的异同点总结"><img class="post_bg" src="https://s21.ax1x.com/2024/06/01/pk8xi1x.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Transformer的Decoder在训练和推理阶段的异同点总结"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/06/01/Transformer%E7%9A%84Decoder%E5%9C%A8%E8%AE%AD%E7%BB%83%E5%92%8C%E6%8E%A8%E7%90%86%E9%98%B6%E6%AE%B5%E7%9A%84%E5%BC%82%E5%90%8C%E7%82%B9%E6%80%BB%E7%BB%93/" title="Transformer的Decoder在训练和推理阶段的异同点总结">Transformer的Decoder在训练和推理阶段的异同点总结</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-06-01T07:15:20.000Z" title="发表于 2024-06-01 15:15:20">2024-06-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">在训练阶段，decoder的输入是(seq_length,)的目标序列，也就是训练数据集中的GT，经过OutputEmbedding层和PositionalEmbedding层得到(seq_length,model_dim)的序列。
接下来这个序列会经过一个MHA层，对应的q、k和v都是刚才得到的序列本身，此时如果直接计算注意力，那么序列中每一个词既能看到它前面的词的信息，又能看到它后面的词的信息，这样容易导致模型就不学习了，因为在推理阶段，模型是一个词一个词的采用一种自回归方式进行预测的，如果训练时模型已经看到了其所在序列位置后面的词的信息，那么直接读取这些词就好了，无需学习。
因此，需要对q和k计算得到的attention map添加一个mask操作，以保证序列中的每一个词只能看到位于其前面的词的信息。

在走完第一个MHA层之后，还有第二个MHA层，只不过，这里的k和v来自encoder的输出，q来自decoder刚刚上一个MHA层的输出，而计算attention map是q和k的事，k又是一个全局的encoder的输出，q序列的每一个位置的token都可以访问它，不需要担心未来 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/05/04/Python-Flask%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/" title="Python-Flask快速上手"><img class="post_bg" src="https://s21.ax1x.com/2024/05/04/pkAljWq.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python-Flask快速上手"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/05/04/Python-Flask%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/" title="Python-Flask快速上手">Python-Flask快速上手</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-05-04T09:27:57.000Z" title="发表于 2024-05-04 17:27:57">2024-05-04</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%A5%9E%E5%A5%87%E7%9A%84Python/">神奇的Python</a></span></div><div class="content">在训练好深度学习模型后，可以使用Python的Flask框架快速搭建一个服务，用于模型效果的展示
最近遇到了这个需求，于是在网络上找到了一些资料(主要参考了台大-彭老师的视频)，对Flask的基础内容进行了整理总结成此文
下面正文开始
1. URL的组成与运作方式组成通讯协议：//主机名称:端口号/路径?要求字串
比如：
https：//www.google.com/search?q=test
其中的“要求字串”允许省略，上述例子中的“端口号”省略不写，实际上使用的是默认值

通讯协议：通过后端以及网络环境决定使用http或https
主机名称：购买域名，设定dns记录，应用AWS云端服务决定主机名称
端口号：通过后端程序或设定档决定
路径：通过后端程序或设定档决定
要求字串：通过后端程序决定运作方式浏览器前端根据通讯协议，主机名称、端口号连接到网络上的服务器，服务器根据路径，要求字串决定要采取的动作，并回传给前端

2. 路由基础基本路由决定后端程序要支援的路径
比如
123@app.route(&quot;/data&quot;):def getData():    return  ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/#content-inner">17</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">雨落诗山山亦奇</div><div class="author-info__description">本站为读研版&工作版博客，大学版移步 --> fuhanshi.github.io</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">167</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">本站内容的最终版本将发布在微信公众号[南极Python]</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/02/20/%E4%BB%8E%E7%A6%BB%E6%95%A3%E7%9A%84tokenID%E5%88%B0%E5%85%B7%E6%9C%89%E8%AF%AD%E4%B9%89%E4%BF%A1%E6%81%AF%E7%9A%84embedding-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%BA%8C)/" title="从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)"><img src="https://i.miji.bid/2025/02/20/14ccff2337c64f4aef4ba366814fd5e2.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)"/></a><div class="content"><a class="title" href="/2025/02/20/%E4%BB%8E%E7%A6%BB%E6%95%A3%E7%9A%84tokenID%E5%88%B0%E5%85%B7%E6%9C%89%E8%AF%AD%E4%B9%89%E4%BF%A1%E6%81%AF%E7%9A%84embedding-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%BA%8C)/" title="从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)">从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)</a><time datetime="2025-02-20T14:28:29.000Z" title="发表于 2025-02-20 22:28:29">2025-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/20/%E4%BB%8Etokenizer%E8%AF%B4%E8%B5%B7%EF%BC%8C%E4%B8%BALLM%E8%87%AA%E5%9B%9E%E5%BD%92%E9%A2%84%E8%AE%AD%E7%BB%83%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%B8%80)/" title="从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)"><img src="https://i.miji.bid/2025/02/20/14ccff2337c64f4aef4ba366814fd5e2.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)"/></a><div class="content"><a class="title" href="/2025/02/20/%E4%BB%8Etokenizer%E8%AF%B4%E8%B5%B7%EF%BC%8C%E4%B8%BALLM%E8%87%AA%E5%9B%9E%E5%BD%92%E9%A2%84%E8%AE%AD%E7%BB%83%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%B8%80)/" title="从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)">从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)</a><time datetime="2025-02-20T14:28:29.000Z" title="发表于 2025-02-20 22:28:29">2025-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/30/%E6%8A%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%90%AC%E5%88%B0GPU-%E8%8B%B1%E4%BC%9F%E8%BE%BEDALI%E5%8A%A0%E9%80%9F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" title="把数据预处理搬到GPU-英伟达DALI加速数据预处理"><img src="https://ice.frostsky.com/2024/12/30/88a897ed803ad9cb7462f4320a31ac67.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="把数据预处理搬到GPU-英伟达DALI加速数据预处理"/></a><div class="content"><a class="title" href="/2024/12/30/%E6%8A%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%90%AC%E5%88%B0GPU-%E8%8B%B1%E4%BC%9F%E8%BE%BEDALI%E5%8A%A0%E9%80%9F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" title="把数据预处理搬到GPU-英伟达DALI加速数据预处理">把数据预处理搬到GPU-英伟达DALI加速数据预处理</a><time datetime="2024-12-30T13:32:21.000Z" title="发表于 2024-12-30 21:32:21">2024-12-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/07/PyTorch%E8%BD%ACTensorRT-engine%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%95%99%E7%A8%8B/Markdown%20_%20%E8%AE%A9%E6%8E%92%E7%89%88%E5%8F%98%20Nice/" title="无题"><img src="/img/tag1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2024/12/07/PyTorch%E8%BD%ACTensorRT-engine%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%95%99%E7%A8%8B/Markdown%20_%20%E8%AE%A9%E6%8E%92%E7%89%88%E5%8F%98%20Nice/" title="无题">无题</a><time datetime="2024-12-07T07:43:12.125Z" title="发表于 2024-12-07 15:43:12">2024-12-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/07/%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%E5%85%A5%E9%97%A8%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" title="万字长文入门扩散模型"><img src="https://ice.frostsky.com/2024/12/07/bf4bfcbe17c50e1fcbc8d26acfac57c8.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="万字长文入门扩散模型"/></a><div class="content"><a class="title" href="/2024/12/07/%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%E5%85%A5%E9%97%A8%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" title="万字长文入门扩散模型">万字长文入门扩散模型</a><time datetime="2024-12-07T06:51:51.000Z" title="发表于 2024-12-07 14:51:51">2024-12-07</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%91%93%E8%AF%AD%E7%B3%BB%E5%88%97%E8%BF%9E%E8%BD%BD/"><span class="card-category-list-name">呓语系列连载</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF/"><span class="card-category-list-name">大模型炼丹术</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"><span class="card-category-list-name">推荐系统</span><span class="card-category-list-count">18</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/"><span class="card-category-list-name">数据竞赛</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"><span class="card-category-list-name">机器学习算法</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="card-category-list-name">深度学习笔记</span><span class="card-category-list-count">95</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%A5%9E%E5%A5%87%E7%9A%84Python/"><span class="card-category-list-name">神奇的Python</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%B7%A8%E8%80%83%E5%B0%8F%E7%99%BD%E5%AD%A6%E5%88%B7%E9%A2%98/"><span class="card-category-list-name">跨考小白学刷题</span><span class="card-category-list-count">2</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/DL/" style="font-size: 1.5em; color: #99a9bf">DL</a> <a href="/tags/GAN/" style="font-size: 1.43em; color: #99a6b9">GAN</a> <a href="/tags/LLM/" style="font-size: 1.17em; color: #999c9f">LLM</a> <a href="/tags/ML/" style="font-size: 1.3em; color: #99a1ac">ML</a> <a href="/tags/Python/" style="font-size: 1.43em; color: #99a6b9">Python</a> <a href="/tags/RL/" style="font-size: 1.1em; color: #999">RL</a> <a href="/tags/Spark/" style="font-size: 1.1em; color: #999">Spark</a> <a href="/tags/Transformer/" style="font-size: 1.1em; color: #999">Transformer</a> <a href="/tags/%E5%91%93%E8%AF%AD/" style="font-size: 1.3em; color: #99a1ac">呓语</a> <a href="/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/" style="font-size: 1.1em; color: #999">性能优化</a> <a href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" style="font-size: 1.1em; color: #999">扩散模型</a> <a href="/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/" style="font-size: 1.37em; color: #99a4b2">推荐算法</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/" style="font-size: 1.23em; color: #999ea6">数据竞赛</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86/" style="font-size: 1.1em; color: #999">模型推理</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/" style="font-size: 1.1em; color: #999">计算机基础</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/02/"><span class="card-archive-list-date">二月 2025</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">十二月 2024</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">十月 2024</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">五月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/01/"><span class="card-archive-list-date">一月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">十月 2023</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">167</div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">351.5k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-02-24T12:50:46.568Z"></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/tag1.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By 雨落诗山山亦奇</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#subtitle", {
      strings: ["期望始终为零，方差交给时间"],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '期望始终为零，方差交给时间'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>