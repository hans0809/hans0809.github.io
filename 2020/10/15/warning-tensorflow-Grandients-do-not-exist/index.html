<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="雨落诗山山亦奇"><meta name="copyright" content="雨落诗山山亦奇"><meta name="generator" content="Hexo 4.2.1"><meta name="theme" content="hexo-theme-yun"><title>【警告原因不明，怀疑是梯度消失】warning:tensorflow:Grandients_do_not_exist | 南极Python</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.25/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_dxory92pb0h.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="icon" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"yoursite.com","root":"/","title":"云游君的小站","version":"1.6.3","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><meta name="description" content="更新！！！ 好像并不是Dropout的原因，在训练SGAN时也出现了同样的警告，即使已经设置了Dropout层的traing&#x3D;True，怀疑是梯度消失（有文章说是这个 https:&#x2F;&#x2F;www.jiqizhixin.com&#x2F;articles&#x2F;2018-11-27-24 ）或爆炸  在本文中，可能设置training&#x3D;Trur恰好避免了梯度消失或爆炸，只是凑巧而已（猜测） 具体原因后续再来分析，先这样">
<meta property="og:type" content="article">
<meta property="og:title" content="【警告原因不明，怀疑是梯度消失】warning:tensorflow:Grandients_do_not_exist">
<meta property="og:url" content="http://yoursite.com/2020/10/15/warning-tensorflow-Grandients-do-not-exist/index.html">
<meta property="og:site_name" content="南极Python">
<meta property="og:description" content="更新！！！ 好像并不是Dropout的原因，在训练SGAN时也出现了同样的警告，即使已经设置了Dropout层的traing&#x3D;True，怀疑是梯度消失（有文章说是这个 https:&#x2F;&#x2F;www.jiqizhixin.com&#x2F;articles&#x2F;2018-11-27-24 ）或爆炸  在本文中，可能设置training&#x3D;Trur恰好避免了梯度消失或爆炸，只是凑巧而已（猜测） 具体原因后续再来分析，先这样">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2020/10/15/warning-tensorflow-Grandients-do-not-exist/1.jpg">
<meta property="article:published_time" content="2020-10-15T07:29:51.000Z">
<meta property="article:modified_time" content="2021-10-14T06:26:06.395Z">
<meta property="article:author" content="雨落诗山山亦奇">
<meta property="article:tag" content="DL">
<meta property="article:tag" content="GAN">
<meta property="article:tag" content="Tensorflow">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/10/15/warning-tensorflow-Grandients-do-not-exist/1.jpg"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="雨落诗山山亦奇"><img width="96" loading="lazy" src="/yun.png" alt="雨落诗山山亦奇"></a><div class="site-author-name"><a href="/about/">雨落诗山山亦奇</a></div><span class="site-name">南极Python</span><sub class="site-subtitle">Python|机器学习|深度学习</sub><div class="site-desciption">昨夜星辰昨夜风</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">116</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">7</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">11</span></a></div><a class="site-state-item hty-icon-button" href="https://yun.yunyoujun.cn" target="_blank" rel="noopener" title="文档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-settings-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://qm.qq.com/cgi-bin/qm/qr?k=kZJzggTTCf4SpvEQ8lXWoi5ZjhAx0ILZ&amp;jump_from=webapi" title="QQ 群 1050458482" target="_blank" style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/YunYouJun" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://weibo.com/jizhideyunyoujun" title="微博" target="_blank" style="color:#E6162D"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-weibo-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.douban.com/people/yunyoujun/" title="豆瓣" target="_blank" style="color:#007722"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-douban-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://music.163.com/#/user/home?id=247102977" title="网易云音乐" target="_blank" style="color:#C20C0C"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-netease-cloud-music-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.zhihu.com/people/yunyoujun/" title="知乎" target="_blank" style="color:#0084FF"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhihu-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/1579790" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/about/white-qrcode-and-search.jpg" title="微信公众号" target="_blank" style="color:#1AAD19"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-2-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://twitter.com/YunYouJun" title="Twitter" target="_blank" style="color:#1da1f2"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-twitter-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://t.me/elpsycn" title="Telegram Channel" target="_blank" style="color:#0088CC"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-telegram-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:me@yunyoujun.cn" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://travellings.link" title="Travelling" target="_blank" style="color:var(--hty-text-color)"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-train-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#问题提出"><span class="toc-number">1.</span> <span class="toc-text">问题提出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#问题解决"><span class="toc-number">2.</span> <span class="toc-text">问题解决</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分析"><span class="toc-number">3.</span> <span class="toc-text">分析</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/15/warning-tensorflow-Grandients-do-not-exist/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="雨落诗山山亦奇"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="南极Python"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">【警告原因不明，怀疑是梯度消失】warning:tensorflow:Grandients_do_not_exist</h1><div class="post-meta"><div class="post-time" style="display:inline-block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2020-10-15 15:29:51" itemprop="dateCreated datePublished" datetime="2020-10-15T15:29:51+08:00">2020-10-15</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-2-line"></use></svg></span> <time title="修改时间：2021-10-14 14:26:06" itemprop="dateModified" datetime="2021-10-14T14:26:06+08:00">2021-10-14</time></div><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">深度学习笔记</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag-item" href="/tags/DL/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">DL</span></a><a class="tag-item" href="/tags/GAN/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">GAN</span></a><a class="tag-item" href="/tags/Tensorflow/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">Tensorflow</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#0078E7;"><p>更新！！！</p>
<p>好像并不是<code>Dropout</code>的原因，在训练<code>SGAN</code>时也出现了同样的警告，即使已经设置了<code>Dropout</code>层的<code>traing=True</code>，怀疑是梯度消失（有文章说是这个 <a href="https://www.jiqizhixin.com/articles/2018-11-27-24" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2018-11-27-24</a> ）或爆炸</p>
<p><img src="1.jpg" alt="" loading="lazy"></p>
<p>在本文中，可能设置<code>training=Trur</code>恰好避免了梯度消失或爆炸，只是凑巧而已（猜测）</p>
<p>具体原因后续再来分析，先这样了。</p>
<h3 id="问题提出"><a href="#问题提出" class="headerlink" title="问题提出"></a>问题提出</h3><p>基于DCGAN（<a href="https://fx0809.gitee.io/2020/10/07/DCGAN/）的代码，想要将生成器和判别器的实现方式改为继承自`tf.keras.Model`类的方式，修改部分的代码如下：" target="_blank" rel="noopener">https://fx0809.gitee.io/2020/10/07/DCGAN/）的代码，想要将生成器和判别器的实现方式改为继承自`tf.keras.Model`类的方式，修改部分的代码如下：</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator_model</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        </span><br><span class="line">        self.dense=tf.keras.layers.Dense(<span class="number">7</span>*<span class="number">7</span>*<span class="number">256</span>,use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1=tf.keras.layers.BatchNormalization()</span><br><span class="line">        self.leakyrelu1=tf.keras.layers.LeakyReLU()</span><br><span class="line">        </span><br><span class="line">        self.reshape=tf.keras.layers.Reshape((<span class="number">7</span>,<span class="number">7</span>,<span class="number">256</span>))</span><br><span class="line">        </span><br><span class="line">        self.convT1=tf.keras.layers.Conv2DTranspose(<span class="number">128</span>,(<span class="number">5</span>,<span class="number">5</span>),strides=(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">'same'</span>,use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2=tf.keras.layers.BatchNormalization()</span><br><span class="line">        self.leakyrelu2=tf.keras.layers.LeakyReLU()</span><br><span class="line">        </span><br><span class="line">        self.convT2=tf.keras.layers.Conv2DTranspose(<span class="number">64</span>,(<span class="number">5</span>,<span class="number">5</span>),strides=(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">'same'</span>,use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn3=tf.keras.layers.BatchNormalization()</span><br><span class="line">        self.leakyrelu3=tf.keras.layers.LeakyReLU()</span><br><span class="line">        </span><br><span class="line">        self.convT3=tf.keras.layers.Conv2DTranspose(<span class="number">1</span>,(<span class="number">5</span>,<span class="number">5</span>),strides=(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">'same'</span>,use_bias=<span class="literal">False</span>,activation=<span class="string">'tanh'</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,inputs,training=True)</span>:</span></span><br><span class="line">        x=self.dense(inputs)</span><br><span class="line">        x=self.bn1(x,training)</span><br><span class="line">        x=self.leakyrelu1(x)</span><br><span class="line">        </span><br><span class="line">        x=self.reshape(x)</span><br><span class="line">        </span><br><span class="line">        x=self.convT1(x)</span><br><span class="line">        x=self.bn2(x,training)</span><br><span class="line">        x=self.leakyrelu2(x)</span><br><span class="line">        </span><br><span class="line">        x=self.convT2(x)</span><br><span class="line">        x=self.bn3(x,training)</span><br><span class="line">        x=self.leakyrelu3(x)</span><br><span class="line">        </span><br><span class="line">        x=self.convT3(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator_model</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        </span><br><span class="line">        self.conv1=tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">5</span>,<span class="number">5</span>),strides=(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">'same'</span>)</span><br><span class="line">        self.leakyrelu1=tf.keras.layers.LeakyReLU()</span><br><span class="line">        self.dropout1=tf.keras.layers.Dropout(<span class="number">0.3</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv2=tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">5</span>,<span class="number">5</span>),strides=(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">'same'</span>)</span><br><span class="line">        self.leakyrelu2=tf.keras.layers.LeakyReLU()</span><br><span class="line">        self.dropout2=tf.keras.layers.Dropout(<span class="number">0.3</span>)</span><br><span class="line">        </span><br><span class="line">        self.flatten=tf.keras.layers.Flatten()</span><br><span class="line">        </span><br><span class="line">        self.dense=tf.keras.layers.Dense(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,inputs,training=True)</span>:</span></span><br><span class="line">        x=self.conv1(inputs)</span><br><span class="line">        x=self.leakyrelu1(x)</span><br><span class="line">        x=self.dropout1(x)</span><br><span class="line">        </span><br><span class="line">        x=self.conv2(inputs)</span><br><span class="line">        x=self.leakyrelu2(x)</span><br><span class="line">        x=self.dropout2(x)  </span><br><span class="line">        </span><br><span class="line">        x=self.flatten(x)</span><br><span class="line">        </span><br><span class="line">        x=self.dense(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>



<p>运行全部完整后，发现会不断地弹出<code>warning</code>信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARNING:tensorflow:Gradients do not exist for variables [&#39;discriminator_model&#x2F;conv2d&#x2F;kernel:0&#39;, &#39;discriminator_model&#x2F;conv2d&#x2F;bias:0&#39;] when minimizing the loss.</span><br></pre></td></tr></table></figure>

<h3 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h3><p>把判别器的<code>Dropout</code>层中的<code>traing</code>参数设置为<code>Ture</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator_model</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        </span><br><span class="line">        self.conv1=tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">5</span>,<span class="number">5</span>),strides=(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">'same'</span>)</span><br><span class="line">        self.leakyrelu1=tf.keras.layers.LeakyReLU()</span><br><span class="line">        self.dropout1=tf.keras.layers.Dropout(<span class="number">0.3</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv2=tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">5</span>,<span class="number">5</span>),strides=(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">'same'</span>)</span><br><span class="line">        self.leakyrelu2=tf.keras.layers.LeakyReLU()</span><br><span class="line">        self.dropout2=tf.keras.layers.Dropout(<span class="number">0.3</span>)</span><br><span class="line">        </span><br><span class="line">        self.flatten=tf.keras.layers.Flatten()</span><br><span class="line">        </span><br><span class="line">        self.dense=tf.keras.layers.Dense(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,inputs,training=True)</span>:</span></span><br><span class="line">        x=self.conv1(inputs)</span><br><span class="line">        x=self.leakyrelu1(x)</span><br><span class="line">        x=self.dropout1(x,training)</span><br><span class="line">        </span><br><span class="line">        x=self.conv2(inputs)</span><br><span class="line">        x=self.leakyrelu2(x)</span><br><span class="line">        x=self.dropout2(x,training)  </span><br><span class="line">        </span><br><span class="line">        x=self.flatten(x)</span><br><span class="line">        </span><br><span class="line">        x=self.dense(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>官网关于<code>Dropout</code>层的描述如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1&#x2F;(1 - rate) such that the sum over all inputs is unchanged.</span><br><span class="line"></span><br><span class="line">Note that the Dropout layer only applies when training is set to True such that no values are dropped during inference. When using model.fit, training will be appropriately set to True automatically, and in other contexts, you can set the kwarg explicitly to True when calling the layer.</span><br><span class="line"></span><br><span class="line">(This is in contrast to setting trainable&#x3D;False for a Dropout layer. trainable does not affect the layer&#39;s behavior, as Dropout does not have any variables&#x2F;weights that can be frozen during training.)</span><br></pre></td></tr></table></figure>

<p>或许正如<code>in other contexts, you can set the kwarg explicitly to True when calling the layer</code>所说，我们在使用其他方式搭建模型(比如这里的call方法)时，要手动设置<code>training=True</code>。</p>
</div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="打赏" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">I'm so cute. Please give me money.</div><div id="qr" style="display:none;"><div style="display:inline-block"><a href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/alipay-qrcode.jpg" target="_blank" rel="noopener"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/alipay-qrcode.jpg" alt="支付宝" title="支付宝"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/qqpay-qrcode.png" target="_blank" rel="noopener"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/qqpay-qrcode.png" alt="QQ 支付" title="QQ 支付"></a><div><span style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></span></div></div><div style="display:inline-block"><a href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/wechatpay-qrcode.jpg" target="_blank" rel="noopener"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/wechatpay-qrcode.jpg" alt="微信支付" title="微信支付"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>雨落诗山山亦奇</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://yoursite.com/2020/10/15/warning-tensorflow-Grandients-do-not-exist/" title="【警告原因不明，怀疑是梯度消失】warning:tensorflow:Grandients_do_not_exist">http://yoursite.com/2020/10/15/warning-tensorflow-Grandients-do-not-exist/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2020/10/15/DCGAN-V2-0/" rel="prev" title="DCGAN_V2.0"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">DCGAN_V2.0</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2020/10/15/SGAN/" rel="next" title="【训练结果很糟糕】SGAN"><span class="post-nav-text">【训练结果很糟糕】SGAN</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>要不要和我说些什么？</span><br></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 雨落诗山山亦奇</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v4.2.1</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.6.3</span></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a></div></body></html>