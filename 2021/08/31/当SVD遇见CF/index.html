<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>当SVD遇见CF | 南极Python</title><meta name="description" content="在之前的协同过滤算法中，我们使用了共现矩阵： 共现矩阵中每一个元素是特定用户对于特定物品(这里是电影)的打分。 但这存在一个问题：算法头部效应较明显，导致模型泛化能力较弱。具体来说，热门物品容易跟大量物品产生相似性，而尾部的物品由于其特征向量较稀疏，很少与其它物品产生相似性，从而很少被推荐。 一种比较好用的方法是，通过矩阵分解技术获取隐向量，用更稠密的隐向量来替代之前共现矩阵中对应的行(用户)和列"><meta name="keywords" content="推荐算法"><meta name="author" content="雨落诗山山亦奇"><meta name="copyright" content="雨落诗山山亦奇"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/avatar.png"><link rel="canonical" href="http://yoursite.com/2021/08/31/%E5%BD%93SVD%E9%81%87%E8%A7%81CF/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="当SVD遇见CF"><meta property="og:url" content="http://yoursite.com/2021/08/31/%E5%BD%93SVD%E9%81%87%E8%A7%81CF/"><meta property="og:site_name" content="南极Python"><meta property="og:description" content="在之前的协同过滤算法中，我们使用了共现矩阵： 共现矩阵中每一个元素是特定用户对于特定物品(这里是电影)的打分。 但这存在一个问题：算法头部效应较明显，导致模型泛化能力较弱。具体来说，热门物品容易跟大量物品产生相似性，而尾部的物品由于其特征向量较稀疏，很少与其它物品产生相似性，从而很少被推荐。 一种比较好用的方法是，通过矩阵分解技术获取隐向量，用更稠密的隐向量来替代之前共现矩阵中对应的行(用户)和列"><meta property="og:image" content="https://www.cdnjson.com/images/2021/08/31/dan-lefebvre-RfUy0XMCkhQ-unsplash.jpg"><meta property="article:published_time" content="2021-08-31T04:03:24.000Z"><meta property="article:modified_time" content="2021-08-31T07:09:46.340Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="prev" title="推荐模型:从逻辑回归到POLY2到FM再到FFM" href="http://yoursite.com/2021/09/02/%E7%94%A8%E4%B8%80%E6%A0%B9%E7%BA%BF%E4%B8%B2%E8%B5%B7%E6%9D%A5-%E4%BB%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%88%B0POLY2%E5%88%B0FM%E5%86%8D%E5%88%B0FFM/"><link rel="next" title="用Python搭建一个课程推荐系统:基于协同过滤算法" href="http://yoursite.com/2021/08/28/%E7%94%A8Python%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%AF%BE%E7%A8%8B%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"我爱学习,机器学习,深度学习,学习使我快乐","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-08-31 15:09:46'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><link rel="stylesheet" href="/css/mouse.css">
<link rel="stylesheet" href="/css/gundongtiao.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/macblack.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"> <link rel="stylesheet" href="/css/waigua.css"> <link rel="stylesheet" href="/css/beijing.css"><div class="aplayer" data-id="476185587" data-server="netease" data-type="playlist" data-fixed="true" data-listFolded="false" data-order="list" data-preload="auto"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/lete114/CDN/music/APlayer/APlayer.min.css"><script src="https://cdn.jsdelivr.net/gh/lete114/CDN/music/APlayer/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@1.2.0/dist/Meting.min.js"></script><meta name="generator" content="Hexo 4.2.1"></head><body><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">114</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">12</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">13</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#奇异值分解-SVD"><span class="toc-number">1.</span> <span class="toc-text">奇异值分解(SVD)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Python实现基于协同过滤算法的菜品推荐系统"><span class="toc-number">2.</span> <span class="toc-text">Python实现基于协同过滤算法的菜品推荐系统</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SVD在协同过滤中的应用"><span class="toc-number">3.</span> <span class="toc-text">SVD在协同过滤中的应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">4.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div><div id="body-wrap"><div id="web_bg" data-type="color"></div><header class="post-bg" id="page-header" style="background-image: url(https://www.cdnjson.com/images/2021/08/31/dan-lefebvre-RfUy0XMCkhQ-unsplash.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">南极Python</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">当SVD遇见CF</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2021-08-31 12:03:24"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2021-08-31</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2021-08-31 15:09:46"><i class="fas fa-history fa-fw"></i> 更新于 2021-08-31</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>在之前的协同过滤算法中，我们使用了共现矩阵：<br><img src= "/img/loading.gif" data-src="./1.png" alt="Alt text"></p>
<p>共现矩阵中每一个元素是特定用户对于特定物品(这里是电影)的打分。</p>
<p>但这存在一个问题：算法头部效应较明显，导致模型泛化能力较弱。具体来说，热门物品容易跟大量物品产生相似性，而尾部的物品由于其特征向量较稀疏，很少与其它物品产生相似性，从而很少被推荐。</p>
<p>一种比较好用的方法是，通过<strong>矩阵分解</strong>技术获取隐向量，用更稠密的<strong>隐向量</strong>来替代之前共现矩阵中对应的行(用户)和列（物品）组成的向量，从而加强了协同过滤模型处理稀疏矩阵的能力，提升了模型的泛化能力。</p>
<p>矩阵分解方法较多，比如梯度下降，SVD等.</p>
<p>隐向量的维度可自行设定或根据一定的规则确定(稍后就会看到)，每一个维度都代表一种具体的含义。比如在之前举过的栗子中，每部电影的特征由一个二维向量来表示，两个维度分别代表了该电影中爱情元素和动作元素的含量；同样，每个用户也由一个二维向量来表示，两个维度分别代表该用户对于爱情元素和动作元素所喜爱的程度。其中所提及的二维向量，本质上就是隐向量。</p>
<p>回忆一下，在上面的栗子中，我们采用了梯度下降的方法来获取隐向量。</p>
<p>在接下来，你将看到另一种获取隐向量的方法：奇异值分解(SVD).</p>
<p>注意：在用户数或物品数量不大的情况下，基于SVD获取隐向量的方式是比较合适的，但当用户数或物品数达到百万、千万级别时，SVD的计算复杂度会很高；而且，SVD要求原始的共现矩阵是稠密的，但互联网场景下大部分用户的历史行为非常少，举个可能不太恰当的栗子，比如某网上商城共5000万条物品，但用户浏览/点击/购买的顶多可能就100条，这导致用户-物品之间的共现矩阵非常稀疏(只有极个别位置才有数据)，此时若想使用SVD，就得想办法填充缺失值。</p>
<p>由于SVD的以上缺陷，梯度下降法成为了矩阵分解的主要方法。关于该方法的具体应用，我们之前已经讲过了，可以回头查看下(传送门)。</p>
<p>虽然事实如此，但作为学习，还是有必要了解一下基于SVD的矩阵分解技术在协同过滤中的应用的。</p>
<p>啰里啰唆一大堆，下面正文开始~</p>
<h2 id="奇异值分解-SVD"><a href="#奇异值分解-SVD" class="headerlink" title="奇异值分解(SVD)"></a>奇异值分解(SVD)</h2><p>对于一个<code>m*n</code>的矩阵，通过SVD，可得到3个小的矩阵，即：</p>
<p>$$M_{m<em>n}=U_{m</em>m} \Sigma_{m<em>n} V_{n</em>n}$$</p>
<p>其中，$U$和$V$是正交矩阵，$\Sigma$是对角矩阵，对角线元素值从左到右，从大到小依次递减。</p>
<p>这里举个栗子介绍如何通过Python来求解SVD：</p>
<p>首先创建一个矩阵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d=np.mat([[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">3</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>]])</span><br><span class="line">print(d)</span><br></pre></td></tr></table></figure>
<p>这是一个<code>6*5</code>的矩阵：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[0 0 0 2 2]</span><br><span class="line"> [0 0 0 3 3]</span><br><span class="line"> [0 0 0 1 1]</span><br><span class="line"> [2 2 2 0 0]</span><br><span class="line"> [5 5 5 0 0]</span><br><span class="line"> [1 1 1 0 0]]</span><br></pre></td></tr></table></figure>

<p>然后对该矩阵进行SVD：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> linalg <span class="keyword">as</span> la</span><br><span class="line">U,Sigma,VT=la.svd(d)</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="./2.png" alt="Alt text"></p>
<p>注意，原本期望输出的$\Sigma$如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#为了方便展示，去掉了部分小数位，你知道就好~~~</span><br><span class="line">[[9.48 0 0 0 0]</span><br><span class="line"> [0 5.29 0 0 0]</span><br><span class="line"> [0 0 5.86e-16 0 0]</span><br><span class="line"> [0 0 0 2.96e-17 0]</span><br><span class="line"> [0 0 0 0 1.37e-33]</span><br><span class="line"> [0 0 0 0 0]]</span><br></pre></td></tr></table></figure>

<p>但由于对角矩阵除了对角线外其余位置元素都是0，因此$\Sigma$仅仅返回对角线上的元素，这样做能够节省空间。</p>
<h2 id="Python实现基于协同过滤算法的菜品推荐系统"><a href="#Python实现基于协同过滤算法的菜品推荐系统" class="headerlink" title="Python实现基于协同过滤算法的菜品推荐系统"></a>Python实现基于协同过滤算法的菜品推荐系统</h2><p>在讲解如何将SVD应用到协同过滤算法之前，先来搭建一个基于传统协同过滤算法的菜品推荐系统。</p>
<p>然后，将SVD引入该菜品推荐系统。</p>
<p>假设有一餐馆，共5种不同的菜品，至今为止，共有7个客人的用餐信息。该餐馆想搭建一个推荐系统，当回头客来用餐时，希望能够根据该客人的历史用餐情况，自动推荐合适的菜品。</p>
<p>根据以上数据，可以得到客人-菜品的共现矩阵，假设是这样的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">4</span> <span class="number">4</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">0</span> <span class="number">0</span> <span class="number">3</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">5</span> <span class="number">5</span> <span class="number">5</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure>
<p>其中元素位0的位置代表对应的客人还未曾对相应菜品进行打分，非0元素代表对应的客人对于相应菜品的打分。</p>
<p>对于餐馆来说，菜品数往往是小于客人数的，因此，我们选取基于物品的协同过滤算法(计算物品之间两两相似度)，这样做能够降低共现矩阵的大小，减少存储/计算开销。</p>
<p>现在来写代码搭建菜品推荐系统，然后使用该推荐系统预测客人未曾打分的菜品的打分值，根据预测打分值从高到低进行菜品推荐。</p>
<p>首先实现打分预测函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> linalg <span class="keyword">as</span> la</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">standEst</span><span class="params">(dataMat,user,simMeas,item)</span>:</span></span><br><span class="line">    n=shape(dataMat)[<span class="number">1</span>]<span class="comment">#物品数</span></span><br><span class="line">    simTotal=<span class="number">0</span></span><br><span class="line">    ratSimTotal=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#对于每一件物品</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="comment">#获取user对当前物品的评分</span></span><br><span class="line">        userRating=dataMat[user,j]</span><br><span class="line">        <span class="comment">#若未评分，则跳过该物品</span></span><br><span class="line">        <span class="keyword">if</span> userRating==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment">#对于item和j这两个物品，寻找对这两个物品同时进行了打分的全部用户，将用户(所在行索引)存入overLap</span></span><br><span class="line">        overLap=nonzero(logical_and(dataMat[:,item].A&gt;<span class="number">0</span>,dataMat[:,j].A&gt;<span class="number">0</span>))[<span class="number">0</span>]</span><br><span class="line">        <span class="comment">#print(overLap)</span></span><br><span class="line">        <span class="comment">#若找不到符合以上条件的，则说明没有一个用户对物品item和j同时进行了打分，此时将这两个物品的相似度置为0</span></span><br><span class="line">        <span class="keyword">if</span> len(overLap)==<span class="number">0</span>:</span><br><span class="line">            similarity=<span class="number">0</span></span><br><span class="line">        <span class="comment">#若找到,则计算这两物品的相似度，用于计算的向量长度为len(overLap)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            similarity=simMeas(dataMat[overLap,item],dataMat[overLap,j])</span><br><span class="line">            </span><br><span class="line">        <span class="comment">#分母累加    </span></span><br><span class="line">        simTotal+=similarity</span><br><span class="line">        <span class="comment">#分子累加。</span></span><br><span class="line">        ratSimTotal+=similarity*userRating</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#返回估计的用户user对物品item的评分值</span></span><br><span class="line">    <span class="keyword">if</span> simTotal==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> ratSimTotal/simTotal</span><br></pre></td></tr></table></figure>
<p><code>dataMat</code>就是共现矩阵，<code>user</code>是客人，<code>item</code>是菜品，<code>simMeas</code>是相似度度量方法，这里使用余弦相似度，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cosSim</span><span class="params">(inA,inB)</span>:</span></span><br><span class="line">    num=float(inA.T*inB)</span><br><span class="line">    denom=la.norm(inA)*la.norm(inB)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.5</span>+<span class="number">0.5</span>*(num/denom)</span><br></pre></td></tr></table></figure>

<p><code>standEst</code>的作用是预测客人user对于菜品item的打分值。详细解释请看代码注释。</p>
<p>有了打分值预测的函数，就可以实现推荐入口了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recommend</span><span class="params">(dataMat,user,N=<span class="number">3</span>,simMeas=cosSim,estMethod=standEst)</span>:</span></span><br><span class="line">    <span class="comment">#获取用户user未评级的物品(所在列索引)</span></span><br><span class="line">    unratedItems=nonzero(dataMat[user,:].A==<span class="number">0</span>)[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> len(unratedItems)==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'对于全部物品，你都评价过了'</span></span><br><span class="line">    itemScores=[]</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> unratedItems:</span><br><span class="line">        estimatedScore=estMethod(dataMat,user,simMeas,item)</span><br><span class="line">        itemScores.append((item,estimatedScore))</span><br><span class="line">    <span class="keyword">return</span> sorted(itemScores,key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>],reverse=<span class="literal">True</span>)[:N]</span><br></pre></td></tr></table></figure>
<p>该函数寻找客人user未曾打分的全部菜品，然后预测打分值，并按照分支从高到底排序，选择预测打分值最高的前N个菜品，推荐给客人user.</p>
<p>尝试调用该函数，为第2个客人进行推荐。第二个客人对于全部菜品的打分情况如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[4, 0, 0, 1, 1],</span><br></pre></td></tr></table></figure>
<p>开始推荐：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">recommend(dataMat,user=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(2, 2.5), (1, 2.0243290220056256)]</span><br></pre></td></tr></table></figure>
<p>这表明，该推荐系统将为第2个客人推荐菜品2和菜品1，对应的预测评分值分别是2.5和2.0243.</p>
<h2 id="SVD在协同过滤中的应用"><a href="#SVD在协同过滤中的应用" class="headerlink" title="SVD在协同过滤中的应用"></a>SVD在协同过滤中的应用</h2><p>实际情况中，共现矩阵是很稀疏的。在这一部分，假设共现矩阵如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">matrix([[2, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0],</span><br><span class="line">        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5],</span><br><span class="line">        [0, 0, 0, 0, 0, 0, 0, 1, 0, 4, 0],</span><br><span class="line">        [3, 3, 4, 0, 3, 0, 0, 2, 2, 0, 0],</span><br><span class="line">        [5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0],</span><br><span class="line">        [0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0],</span><br><span class="line">        [4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 5],</span><br><span class="line">        [0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4],</span><br><span class="line">        [0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0],</span><br><span class="line">        [0, 0, 0, 3, 0, 0, 0, 0, 4, 5, 0],</span><br><span class="line">        [1, 1, 2, 1, 1, 2, 1, 0, 4, 5, 0]])</span><br></pre></td></tr></table></figure>

<p>这是一个<code>11*11</code>的矩阵，和之前一样，行代表客人，列代表菜品。</p>
<p>将SVD应用于协同过滤算法的思想是，使用SVD对共现矩阵进行分解，然后将客人(共现矩阵的一行)向量转换到另一个向量的空间中，或将菜品(共现矩阵的一列)向量转换到另一个向量空间中。</p>
<p>这里，另一个向量空间对于客人和菜品来说是同一个，这也就是隐向量所在空间。</p>
<p>一般来说，隐向量的维度可以根据$\Sigma$对角线元素来确定。</p>
<p>对角线元素值就是奇异值，奇异值中包含的信息能够代表整个矩阵的信息。将这些信息看作能量值，那么整个矩阵包含的信息就是总能量值。</p>
<p>为了使得隐向量的维度低一些，我们可以考虑只取总能量的部分，比如90%，用损耗10%的代价换取更低的隐向量维度。</p>
<p>既然奇异值中包含的信息能够代表整个矩阵的信息，那么很自然的，可以用奇异值的大小来衡量能量值的大小。</p>
<p>具体到上面的栗子，首先对共现矩阵做SVD，得到$U$，$V$以及$\Sigma$. </p>
<p>$\Sigma$如下：<br><img src= "/img/loading.gif" data-src="./3.png" alt="Alt text"></p>
<p>求平方如下：<br><img src= "/img/loading.gif" data-src="./4.png" alt="Alt text"></p>
<p>总能量如下：<br><img src= "/img/loading.gif" data-src="./5.png" alt="Alt text"></p>
<p>90%的能量如下：<br><img src= "/img/loading.gif" data-src="./6.png" alt="Alt text"></p>
<p>确定合适的隐向量维度：<br><img src= "/img/loading.gif" data-src="./7.png" alt="Alt text"></p>
<p>可以看到，前5维就蕴含了总能量的90+%，因此我们可以只取5维作为隐向量的维度。</p>
<p>在之前打分值预测函数<code>standEst</code>的基础上，稍加修改就得到了基于SVD的打分值预测函数<code>svdEst</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svdEst</span><span class="params">(dataMat,user,simMeas,item)</span>:</span></span><br><span class="line">    n=shape(dataMat)[<span class="number">1</span>]<span class="comment">#物品数</span></span><br><span class="line">    simTotal=<span class="number">0</span></span><br><span class="line">    ratSimTotal=<span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#做奇异值分解（SVD）</span></span><br><span class="line">    U,Sigma,VT=la.svd(dataMat)</span><br><span class="line">    <span class="comment">#只利用包含90%能量值的奇异值,构建一个对角矩阵</span></span><br><span class="line">    Sig5=mat(eye(<span class="number">5</span>)*Sigma[:<span class="number">5</span>])</span><br><span class="line">    <span class="comment">#构建转换后的物品(使用U矩阵将物品转换到低维空间中)，记得V代表用户空间，U代表物品空间</span></span><br><span class="line">    xformedItems=dataMat.T*U[:,:<span class="number">5</span>]*Sig5.T<span class="comment">#11*11,11*5,5*5-&gt;11*5,含义：共11个物品，每个物品用5维向量表示</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="comment">#获取用户user对物品j的评分</span></span><br><span class="line">        userRating=dataMat[user,j]</span><br><span class="line">        <span class="keyword">if</span> userRating==<span class="number">0</span> <span class="keyword">or</span> j==item:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment">#根据低维矩阵，计算物品item与物品j之间的相似度</span></span><br><span class="line">        similarity=simMeas(xformedItems[item,:].T,xformedItems[j,:].T)</span><br><span class="line">        <span class="comment">#print('物品&#123;&#125;和物品&#123;&#125;之间的相似度=&#123;&#125;'.format(item,j,similarity))</span></span><br><span class="line">        <span class="comment">#分母累加    </span></span><br><span class="line">        simTotal+=similarity</span><br><span class="line">        <span class="comment">#分子累加。</span></span><br><span class="line">        ratSimTotal+=similarity*userRating</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#返回估计的用户user对物品item的评分值</span></span><br><span class="line">    <span class="keyword">if</span> simTotal==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> ratSimTotal/simTotal</span><br></pre></td></tr></table></figure>
<p>其中的<code>xforedItems</code>指的是转换后菜品的隐向量，它的维度是<code>11*5</code>的，11代表共11个不同的菜品，5代表每个菜品的特征向量的维度(也就是隐向量的维度)。</p>
<p>这里的栗子中，客人数和菜品数都是11，可能看起来没那么清晰，所以下面举个客人数不等于菜品数的栗子，相信看过之后一切都清楚了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#为了方便观察，假设共11个用户，6个物品</span><br><span class="line"></span><br><span class="line">#以下分别是（1）dataMat, （2）U&#x2F;V只取前5个奇异值对应列，（3）前5个奇异值组成的对角矩阵的维度</span><br><span class="line"></span><br><span class="line">#若是使用U矩阵，则将物品(列)转换到隐向量空间中，(11*6).T&#x3D;6*11, 11*5, 5*5-&gt;6*5，共6个物品，每个物品用5维向量表示</span><br><span class="line"></span><br><span class="line">#若是使用V矩阵，则将用户(行)转换到隐向量空间中，11*6，6*5，5*5-&gt;11*5，共11个用户，每个用户用5维向量表示</span><br></pre></td></tr></table></figure>

<p>测试一下，对客人10做推荐。客人10的相关信息如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[0, 0, 0, 3, 0, 0, 0, 0, 4, 5, 0],</span><br></pre></td></tr></table></figure>
<p>开始推荐：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">recommend(dataMat,user=<span class="number">10</span>,estMethod=svdEst)</span><br></pre></td></tr></table></figure>
<p>输出推荐结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(7, 1.941290911249691), (10, 1.9353594511741503)]</span><br></pre></td></tr></table></figure>
<p>结果表明，应该向客人10推荐的Top-2菜品为：菜品7和菜品10，对应预测打分值分别为1.941和1.935.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>传统的协同过滤算法基于共现矩阵计算物品之间的相似度。由于每个用户对于每个物品的打分情况是不一样的，有的用户只对物品1 和物品2打了分，有的用户只对物品2和物品3打了分，类似情况有很多，因此在计算两个物品的相似度时，需要将同时对这两个物品进行了打分的用户筛选出来，假设共m个用户，那么用于计算这两个物品相似度的向量的维度就是m。而对于另外两个物品，同时对另外这两个物品打分的用户数可能是n，从而用于计算另外这两个物品相似度的向量的维度是n.</p>
<p>而通过矩阵分解方法得到用户或物品的隐向量的维度是固定的，因此在用隐向量计算相似度时，不需要像上面那样寻找同时对两个物品进行了打分的用户。而且，由于隐向量的维度一般是低于传统的协同过滤算法中使用的向量维度的，因此也在一定程度上减少了计算开销；隐向量的获取过程可以看作是对于包含全局信息的共现矩阵的拟合，因此也能降低过拟合风险，提升模型的泛化能力。</p>
<p>隐向量可以通过矩阵分解的方法进行获取。矩阵分解方法有很多，本文介绍了SVD，但这种方法要求原始的共现矩阵是稠密的，而且当用户数和物品数数量级达到百万、千万级别时，计算开销会非常大。于是，梯度下降法成为了矩阵分解的主要方法。</p>
</div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/">推荐算法</a></div><div class="post_share"><div class="social-share" data-image="https://www.cdnjson.com/images/2021/10/06/0.png" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/09/02/%E7%94%A8%E4%B8%80%E6%A0%B9%E7%BA%BF%E4%B8%B2%E8%B5%B7%E6%9D%A5-%E4%BB%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%88%B0POLY2%E5%88%B0FM%E5%86%8D%E5%88%B0FFM/"><img class="prev-cover" data-src="https://www.cdnjson.com/images/2021/09/03/111.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">推荐模型:从逻辑回归到POLY2到FM再到FFM</div></div></a></div><div class="next-post pull-right"><a href="/2021/08/28/%E7%94%A8Python%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%AF%BE%E7%A8%8B%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95/"><img class="next-cover" data-src="https://www.cdnjson.com/images/2021/08/29/sigmund-eTgMFFzroGc-unsplash.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">用Python搭建一个课程推荐系统:基于协同过滤算法</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2021/08/22/协同过滤算法/" title="协同过滤算法"><img class="relatedPosts_cover" data-src="https://www.cdnjson.com/images/2021/08/27/Endgame-Lead-1.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-22</div><div class="relatedPosts_title">协同过滤算法</div></div></a></div><div class="relatedPosts_item"><a href="/2021/08/15/基于内容的推荐算法/" title="基于内容的推荐算法：以电影推荐为例"><img class="relatedPosts_cover" data-src="https://www.cdnjson.com/images/2021/08/15/1111111.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-15</div><div class="relatedPosts_title">基于内容的推荐算法：以电影推荐为例</div></div></a></div><div class="relatedPosts_item"><a href="/2021/08/27/用Python搭建一个电影推荐系统/" title="用Python搭建一个电影推荐系统"><img class="relatedPosts_cover" data-src="https://www.cdnjson.com/images/2021/08/27/11111111111.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-27</div><div class="relatedPosts_title">用Python搭建一个电影推荐系统</div></div></a></div><div class="relatedPosts_item"><a href="/2021/08/28/用Python搭建一个课程推荐系统-基于协同过滤算法/" title="用Python搭建一个课程推荐系统:基于协同过滤算法"><img class="relatedPosts_cover" data-src="https://www.cdnjson.com/images/2021/08/29/sigmund-eTgMFFzroGc-unsplash.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-28</div><div class="relatedPosts_title">用Python搭建一个课程推荐系统:基于协同过滤算法</div></div></a></div><div class="relatedPosts_item"><a href="/2021/09/02/用一根线串起来-从逻辑回归到POLY2到FM再到FFM/" title="推荐模型:从逻辑回归到POLY2到FM再到FFM"><img class="relatedPosts_cover" data-src="https://www.cdnjson.com/images/2021/09/03/111.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-09-02</div><div class="relatedPosts_title">推荐模型:从逻辑回归到POLY2到FM再到FFM</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 雨落诗山山亦奇</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
document.body.addEventListener('input', POWERMODE);
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/third-party/ClickShowText.js"></script><script src="https://cdn.jsdelivr.net/gh/lete114/CDN/Sum/sakura.js"></script><script src="/js/egao.js"></script><script src="https://cdn.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/autoload.js"></script><script src="/js/snow.js"></script></body></html>