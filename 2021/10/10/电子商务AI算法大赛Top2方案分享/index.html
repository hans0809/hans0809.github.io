<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>电子商务AI算法大赛Top2方案分享 | 南极Python</title><meta name="keywords" content="数据竞赛"><meta name="author" content="雨落诗山山亦奇"><meta name="copyright" content="雨落诗山山亦奇"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="上一次，我们介绍了电子商务AI算法大赛中我个人的解决方案。虽然在经过一顿操作后，线上分数得到了肉眼可见的提升，但相比于大佬们的成绩还是差了亿点点的 所以呢，这次来解读top2选手的解决方案，从优秀开源代码中学习思路，积累经验。 关于赛题的介绍以及数据集说明，可以回看上一篇文章哈：xxxxxx 线下验证方案date字段代表的是第几天，训练集中date的取值范围是从1 到116，共116天；测试集中d">
<meta property="og:type" content="article">
<meta property="og:title" content="电子商务AI算法大赛Top2方案分享">
<meta property="og:url" content="http://yoursite.com/2021/10/10/%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1AI%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9BTop2%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/index.html">
<meta property="og:site_name" content="南极Python">
<meta property="og:description" content="上一次，我们介绍了电子商务AI算法大赛中我个人的解决方案。虽然在经过一顿操作后，线上分数得到了肉眼可见的提升，但相比于大佬们的成绩还是差了亿点点的 所以呢，这次来解读top2选手的解决方案，从优秀开源代码中学习思路，积累经验。 关于赛题的介绍以及数据集说明，可以回看上一篇文章哈：xxxxxx 线下验证方案date字段代表的是第几天，训练集中date的取值范围是从1 到116，共116天；测试集中d">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.cdnjson.com/images/2021/10/06/0.png">
<meta property="article:published_time" content="2021-10-10T06:25:26.000Z">
<meta property="article:modified_time" content="2024-04-19T16:39:46.000Z">
<meta property="article:author" content="雨落诗山山亦奇">
<meta property="article:tag" content="数据竞赛">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.cdnjson.com/images/2021/10/06/0.png"><link rel="shortcut icon" href="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png"><link rel="canonical" href="http://yoursite.com/2021/10/10/%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1AI%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9BTop2%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '电子商务AI算法大赛Top2方案分享',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-04-20 00:39:46'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/macblack.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">157</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">10</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://www.cdnjson.com/images/2021/10/06/0.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">南极Python</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">电子商务AI算法大赛Top2方案分享</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-10-10T06:25:26.000Z" title="发表于 2021-10-10 14:25:26">2021-10-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-19T16:39:46.000Z" title="更新于 2024-04-20 00:39:46">2024-04-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/">数据竞赛</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>23分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="电子商务AI算法大赛Top2方案分享"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>上一次，我们介绍了电子商务AI算法大赛中我个人的解决方案。虽然在经过一顿操作后，线上分数得到了肉眼可见的提升，但相比于大佬们的成绩还是差了亿点点的<br><img src="./7.png" alt="Alt text"></p>
<p>所以呢，这次来解读top2选手的解决方案，从优秀开源代码中学习思路，积累经验。</p>
<p>关于赛题的介绍以及数据集说明，可以回看上一篇文章哈：xxxxxx</p>
<h2 id="线下验证方案"><a href="#线下验证方案" class="headerlink" title="线下验证方案"></a>线下验证方案</h2><p>date字段代表的是第几天，训练集中date的取值范围是从1 到116，共116天；测试集中date的取值范围是117到123共7天。于是从训练集中划出最后7天的数据作为验证集进行线下验证：</p>
<p><img src="./1.png" alt="Alt text"></p>
<p>而在最终提交时，取消验证集，用全部训练数据进行训练：</p>
<p><img src="./2.png" alt="Alt text"></p>
<p>数据集划分代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_dataset</span>(<span class="params">data, valid_start_date, gap</span>):</span></span><br><span class="line">    train = data[data[<span class="string">&#x27;date&#x27;</span>]&lt;valid_start_date].copy()</span><br><span class="line">    valid = data[(data[<span class="string">&#x27;date&#x27;</span>]&gt;=valid_start_date)&amp;(data[<span class="string">&#x27;date&#x27;</span>]&lt;valid_start_date+gap)].copy()</span><br><span class="line">    test = data[data[<span class="string">&#x27;date&#x27;</span>]&gt;=valid_start_date+gap].copy()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;训练集样本数: <span class="subst">&#123;train.shape[<span class="number">0</span>]&#125;</span>, 验证集样本数: <span class="subst">&#123;valid.shape[<span class="number">0</span>]&#125;</span>, 测试集样本数: <span class="subst">&#123;test.shape[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> train, valid, test</span><br></pre></td></tr></table></figure>

<p>调用时：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train, valid, test = split_dataset(data=data, valid_start_date=<span class="number">110</span>, gap=<span class="number">7</span>) <span class="comment"># 划分训练\验证集</span></span><br></pre></td></tr></table></figure>
<h2 id="魔法特征"><a href="#魔法特征" class="headerlink" title="魔法特征"></a>魔法特征</h2><p>魔法特征，就是能够给模型带来大幅度涨分的特征。</p>
<p>绘制<code>article_id</code>的折线图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">y=train_df[<span class="string">&#x27;article_id&#x27;</span>][:<span class="number">200</span>]</span><br><span class="line">x=[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y))]</span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;article_id&#x27;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;article_id.png&#x27;</span>,dpi=<span class="number">600</span>)</span><br></pre></td></tr></table></figure>
<p><img src="./3.png" alt="Alt text"></p>
<p>观察上图，发现<code>article_id</code>的取值呈现周期性变化。</p>
<p>纵坐标<code>article_id</code>指的是文章id取值，而横坐标是时间推移，这里的时间在一天内。</p>
<p>而如果绘制全部116天的<code>article_id</code>折线图，这种周期性规律就不复存在了：<br><img src="./4.png" alt="Alt text"></p>
<p>所以，猜想<code>article_id</code>这个特征应该是与时间有关的，具体地，某件商品的销量在一天内会呈现周期性变动。</p>
<p>既然这种规律是存在于一天内的，那自然就想到按照天数进行分组，同一天的数据归为同一组。</p>
<p>然后对每组内的<code>article_id</code>进行排序，就得到了一个新的特征：<code>magic_rank</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&#x27;magic_rank&#x27;</span>] = data.groupby([<span class="string">&#x27;date&#x27;</span>])[<span class="string">&#x27;article_id&#x27;</span>].rank()</span><br></pre></td></tr></table></figure>

<p>基于该思想，可以构建出许多有用的新特征。</p>
<p>比如，将<code>date</code>改为其它特征，将<code>rank</code>改为常见的统计量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">g = data.groupby(f)<span class="comment">#f是某个特征，比如`mall`，`author`</span></span><br><span class="line"><span class="keyword">for</span> stat <span class="keyword">in</span> [<span class="string">&#x27;max&#x27;</span>, <span class="string">&#x27;min&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>]:</span><br><span class="line">    data[<span class="string">f&#x27;magic_<span class="subst">&#123;name&#125;</span>_id_<span class="subst">&#123;stat&#125;</span>&#x27;</span>] = g[<span class="string">&#x27;article_id&#x27;</span>].transform(stat)</span><br></pre></td></tr></table></figure>

<p>再比如，将<code>date</code>改为其它特征，计算偏移量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">g = data.groupby(f)</span><br><span class="line">name = <span class="string">&#x27;_&#x27;</span>.join(f)</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>]:</span><br><span class="line">    data[<span class="string">f&#x27;magic_<span class="subst">&#123;name&#125;</span>_aft_gap<span class="subst">&#123;n&#125;</span>&#x27;</span>] = g[<span class="string">&#x27;article_id&#x27;</span>].shift(-n) - g[<span class="string">&#x27;article_id&#x27;</span>].shift(<span class="number">0</span>)</span><br><span class="line">    data[<span class="string">f&#x27;magic_<span class="subst">&#123;name&#125;</span>_bef_gap<span class="subst">&#123;n&#125;</span>&#x27;</span>] = g[<span class="string">&#x27;article_id&#x27;</span>].shift(<span class="number">0</span>) - g[<span class="string">&#x27;article_id&#x27;</span>].shift(n)</span><br></pre></td></tr></table></figure>
<p>还有许多特征衍生操作，这里不再一一列举，完整代码见文末。</p>
<h2 id="常规特征"><a href="#常规特征" class="headerlink" title="常规特征"></a>常规特征</h2><p>这一部分提取了一些字段的当日，当周以及全局的统计特征，以及历史销量滑窗的统计特征等：<br><img src="./5.png" alt="Alt text"></p>
<p>历史销量滑窗的统计特征:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_his_orders_stats</span>(<span class="params">data, stride</span>):</span></span><br><span class="line">    orders_mean_feats = []</span><br><span class="line">    orders_cols = [<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;level1&#x27;</span>, <span class="string">&#x27;level2&#x27;</span>, <span class="string">&#x27;level3&#x27;</span>, <span class="string">&#x27;level4&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;brand&#x27;</span>, <span class="string">&#x27;mall&#x27;</span>, <span class="string">&#x27;url&#x27;</span>, <span class="string">&#x27;baike_id_1h&#x27;</span>, <span class="string">&#x27;baike_id_2h&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> date <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="number">4</span>, <span class="number">124</span>, <span class="number">7</span>)):</span><br><span class="line">        his_data = data[(data[<span class="string">&#x27;date&#x27;</span>]&lt;=date)&amp;(data[<span class="string">&#x27;date&#x27;</span>]&gt;date-stride)].copy()</span><br><span class="line">        df = data[(data[<span class="string">&#x27;date&#x27;</span>]&gt;date)&amp;(data[<span class="string">&#x27;date&#x27;</span>]&lt;=date+<span class="number">7</span>)][[<span class="string">&#x27;article_id&#x27;</span>, <span class="string">&#x27;date&#x27;</span>]+orders_cols].copy()</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> orders_cols:</span><br><span class="line">            gp = his_data.groupby(col)[<span class="string">&#x27;orders_3h_15h&#x27;</span>].agg([[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_mean&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>],</span><br><span class="line">                                                             [<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_std&#x27;</span>, <span class="string">&#x27;std&#x27;</span>],</span><br><span class="line">                                                             [<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_min&#x27;</span>, <span class="string">&#x27;min&#x27;</span>],</span><br><span class="line">                                                             [<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_max&#x27;</span>, <span class="string">&#x27;max&#x27;</span>],</span><br><span class="line">                                                             [<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_med&#x27;</span>, <span class="string">&#x27;median&#x27;</span>]]).reset_index()</span><br><span class="line">            df = df.merge(gp, on=col, how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">        orders_mean_feats.append(df)</span><br><span class="line">    orders_mean_feats = pd.concat(orders_mean_feats, axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line">    orders_mean_feats.drop(orders_cols, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)<span class="comment">#后面与其它表拼接，这里去除与其它表重复的字段，避免重复。</span></span><br><span class="line">    <span class="keyword">return</span> orders_mean_feats</span><br></pre></td></tr></table></figure>
<p>调用时：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">strides = [<span class="number">7</span>, <span class="number">150</span>] <span class="comment"># 150是指历史全部</span></span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> strides:</span><br><span class="line">    feats = gen_his_orders_stats(data, d)</span><br><span class="line">    data = data.merge(feats, on=[<span class="string">&#x27;article_id&#x27;</span>, <span class="string">&#x27;date&#x27;</span>], how=<span class="string">&#x27;left&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="数据建模"><a href="#数据建模" class="headerlink" title="数据建模"></a>数据建模</h2><p>训练了树模型以及深度学习模型，并将结果进行加权融合<br><img src="./6.png" alt="Alt text"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>对于本题来说，模型以及调参部分，大家都大差不差，分水岭在于特征工程，因此很有必要加强自己的特征工程能力(pandas+业务理解)，这样才有可能在下个赛场冲进前排。</p>
<p>最后奉上完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding：utf-8 -*-</span></span><br><span class="line"><span class="comment"># Author: Ethan</span></span><br><span class="line"><span class="comment"># Time: 2021/8/31 14:20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostRegressor, Pool</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span>(<span class="params">path</span>):</span></span><br><span class="line">    train_df = pd.read_csv(path+<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">    test_df = pd.read_csv(path+<span class="string">&#x27;test.csv&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> train_df, test_df</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_his_orders_stats</span>(<span class="params">data, stride</span>):</span></span><br><span class="line">    orders_mean_feats = []</span><br><span class="line">    orders_cols = [<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;level1&#x27;</span>, <span class="string">&#x27;level2&#x27;</span>, <span class="string">&#x27;level3&#x27;</span>, <span class="string">&#x27;level4&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;brand&#x27;</span>, <span class="string">&#x27;mall&#x27;</span>, <span class="string">&#x27;url&#x27;</span>, <span class="string">&#x27;baike_id_1h&#x27;</span>, <span class="string">&#x27;baike_id_2h&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> date <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="number">4</span>, <span class="number">124</span>, <span class="number">7</span>)):</span><br><span class="line">        his_data = data[(data[<span class="string">&#x27;date&#x27;</span>]&lt;=date)&amp;(data[<span class="string">&#x27;date&#x27;</span>]&gt;date-stride)].copy()</span><br><span class="line">        df = data[(data[<span class="string">&#x27;date&#x27;</span>]&gt;date)&amp;(data[<span class="string">&#x27;date&#x27;</span>]&lt;=date+<span class="number">7</span>)][[<span class="string">&#x27;article_id&#x27;</span>, <span class="string">&#x27;date&#x27;</span>]+orders_cols].copy()</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> orders_cols:</span><br><span class="line">            gp = his_data.groupby(col)[<span class="string">&#x27;orders_3h_15h&#x27;</span>].agg([[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_mean&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>],</span><br><span class="line">                                                             [<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_std&#x27;</span>, <span class="string">&#x27;std&#x27;</span>],</span><br><span class="line">                                                             [<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_min&#x27;</span>, <span class="string">&#x27;min&#x27;</span>],</span><br><span class="line">                                                             [<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_max&#x27;</span>, <span class="string">&#x27;max&#x27;</span>],</span><br><span class="line">                                                             [<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_med&#x27;</span>, <span class="string">&#x27;median&#x27;</span>]]).reset_index()</span><br><span class="line">            df = df.merge(gp, on=col, how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">        orders_mean_feats.append(df)</span><br><span class="line">    orders_mean_feats = pd.concat(orders_mean_feats, axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line">    orders_mean_feats.drop(orders_cols, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)<span class="comment">#后面与其它表拼接，这里去除与其它表重复的字段，避免重复字段。</span></span><br><span class="line">    <span class="keyword">return</span> orders_mean_feats</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_magic_features</span>(<span class="params">data</span>):</span></span><br><span class="line">    data[<span class="string">&#x27;magic_rank&#x27;</span>] = data.groupby([<span class="string">&#x27;date&#x27;</span>])[<span class="string">&#x27;article_id&#x27;</span>].rank()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> tqdm([[<span class="string">&#x27;author&#x27;</span>],</span><br><span class="line">                   [<span class="string">&#x27;brand&#x27;</span>],</span><br><span class="line">                   [<span class="string">&#x27;mall&#x27;</span>],</span><br><span class="line">                   [<span class="string">&#x27;price&#x27;</span>],</span><br><span class="line">                   [<span class="string">&#x27;level1&#x27;</span>],</span><br><span class="line">                   [<span class="string">&#x27;level2&#x27;</span>],</span><br><span class="line">                   [<span class="string">&#x27;price&#x27;</span>],</span><br><span class="line">                   [<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;brand&#x27;</span>]]):</span><br><span class="line">        g = data.groupby(f)</span><br><span class="line">        name = <span class="string">&#x27;_&#x27;</span>.join(f)</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>]:</span><br><span class="line">            data[<span class="string">f&#x27;magic_<span class="subst">&#123;name&#125;</span>_aft_gap<span class="subst">&#123;n&#125;</span>&#x27;</span>] = g[<span class="string">&#x27;article_id&#x27;</span>].shift(-n) - g[<span class="string">&#x27;article_id&#x27;</span>].shift(<span class="number">0</span>)</span><br><span class="line">            data[<span class="string">f&#x27;magic_<span class="subst">&#123;name&#125;</span>_bef_gap<span class="subst">&#123;n&#125;</span>&#x27;</span>] = g[<span class="string">&#x27;article_id&#x27;</span>].shift(<span class="number">0</span>) - g[<span class="string">&#x27;article_id&#x27;</span>].shift(n)</span><br><span class="line">        <span class="keyword">for</span> stat <span class="keyword">in</span> [<span class="string">&#x27;max&#x27;</span>, <span class="string">&#x27;min&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>]:</span><br><span class="line">            data[<span class="string">f&#x27;magic_<span class="subst">&#123;name&#125;</span>_id_<span class="subst">&#123;stat&#125;</span>&#x27;</span>] = g[<span class="string">&#x27;article_id&#x27;</span>].transform(stat)</span><br><span class="line"></span><br><span class="line">    data = data.sort_values(by=[<span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;magic_rank&#x27;</span>]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> [<span class="string">&#x27;author&#x27;</span>]:</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> [<span class="string">&#x27;orders_1h&#x27;</span>, <span class="string">&#x27;orders_2h&#x27;</span>, <span class="string">&#x27;magic_rank&#x27;</span>]:</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_bef&#x27;</span>] = data.groupby([key, <span class="string">&#x27;date&#x27;</span>])[col].shift(<span class="number">1</span>)</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_aft&#x27;</span>] = data.groupby([key, <span class="string">&#x27;date&#x27;</span>])[col].shift(-<span class="number">1</span>)</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_bef_diff&#x27;</span>] = data[col] - data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_bef&#x27;</span>]</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_aft_diff&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_aft&#x27;</span>] - data[col]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> [<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;level1&#x27;</span>, <span class="string">&#x27;level2&#x27;</span>, <span class="string">&#x27;level3&#x27;</span>, <span class="string">&#x27;level4&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;brand&#x27;</span>, <span class="string">&#x27;mall&#x27;</span>, <span class="string">&#x27;url&#x27;</span>, <span class="string">&#x27;baike_id_2h&#x27;</span>]:</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_rank_mean&#x27;</span>] = data.groupby([key, <span class="string">&#x27;date&#x27;</span>])[<span class="string">&#x27;magic_rank&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_rank_std&#x27;</span>] = data.groupby([key, <span class="string">&#x27;date&#x27;</span>])[<span class="string">&#x27;magic_rank&#x27;</span>].transform(<span class="string">&#x27;std&#x27;</span>)</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_rank_min&#x27;</span>] = data.groupby([key, <span class="string">&#x27;date&#x27;</span>])[<span class="string">&#x27;magic_rank&#x27;</span>].transform(<span class="string">&#x27;min&#x27;</span>)</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_rank_max&#x27;</span>] = data.groupby([key, <span class="string">&#x27;date&#x27;</span>])[<span class="string">&#x27;magic_rank&#x27;</span>].transform(<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    data[<span class="string">&#x27;baike_id_group&#x27;</span>] = data.groupby([<span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;baike_id_2h&#x27;</span>])[<span class="string">&#x27;article_id&#x27;</span>].rank(method=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">    data[<span class="string">&#x27;baike_id_group&#x27;</span>] = data[<span class="string">&#x27;magic_rank&#x27;</span>] - data[<span class="string">&#x27;baike_id_group&#x27;</span>]</span><br><span class="line">    data[<span class="string">&#x27;baike_id_group&#x27;</span>] = data.groupby([<span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;baike_id_2h&#x27;</span>])[<span class="string">&#x27;baike_id_group&#x27;</span>].rank(ascending=<span class="literal">False</span>, method=<span class="string">&#x27;dense&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feature_extractor</span>(<span class="params">train_df, test_df</span>):</span></span><br><span class="line">    data = pd.concat([train_df, test_df], axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line">    data[<span class="string">&#x27;week&#x27;</span>] = (data[<span class="string">&#x27;date&#x27;</span>] - <span class="number">5</span>) // <span class="number">7</span> <span class="comment"># 这里把valid和test放入到各自相同的周内</span></span><br><span class="line">    data[<span class="string">&#x27;price_diff_ratio&#x27;</span>] = data[<span class="string">&#x27;price_diff&#x27;</span>] / (data[<span class="string">&#x27;price&#x27;</span>] + data[<span class="string">&#x27;price_diff&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    data[<span class="string">&#x27;zhi_1h_cnt&#x27;</span>] = data[<span class="string">&#x27;zhi_1h&#x27;</span>] + data[<span class="string">&#x27;buzhi_1h&#x27;</span>]</span><br><span class="line">    data[<span class="string">&#x27;zhi_2h_cnt&#x27;</span>] = data[<span class="string">&#x27;zhi_2h&#x27;</span>] + data[<span class="string">&#x27;buzhi_2h&#x27;</span>]</span><br><span class="line">    data[<span class="string">&#x27;zhi_1h_ratio&#x27;</span>] = data[<span class="string">&#x27;zhi_1h&#x27;</span>] / data[<span class="string">&#x27;zhi_1h_cnt&#x27;</span>]</span><br><span class="line">    data.loc[data[<span class="string">&#x27;zhi_1h_cnt&#x27;</span>] == <span class="number">0</span>, <span class="string">&#x27;zhi_1h_ratio&#x27;</span>] = <span class="number">0</span></span><br><span class="line">    data[<span class="string">&#x27;buzhi_1h_ratio&#x27;</span>] = data[<span class="string">&#x27;buzhi_1h&#x27;</span>] / data[<span class="string">&#x27;zhi_1h_cnt&#x27;</span>]</span><br><span class="line">    data.loc[data[<span class="string">&#x27;zhi_1h_cnt&#x27;</span>] == <span class="number">0</span>, <span class="string">&#x27;buzhi_1h_ratio&#x27;</span>] = <span class="number">0</span></span><br><span class="line">    data[<span class="string">&#x27;zhi_2h_ratio&#x27;</span>] = data[<span class="string">&#x27;zhi_2h&#x27;</span>] / data[<span class="string">&#x27;zhi_2h_cnt&#x27;</span>]</span><br><span class="line">    data.loc[data[<span class="string">&#x27;zhi_2h_cnt&#x27;</span>] == <span class="number">0</span>, <span class="string">&#x27;zhi_2h_ratio&#x27;</span>] = <span class="number">0</span></span><br><span class="line">    data[<span class="string">&#x27;buzhi_2h_ratio&#x27;</span>] = data[<span class="string">&#x27;buzhi_2h&#x27;</span>] / data[<span class="string">&#x27;zhi_2h_cnt&#x27;</span>]</span><br><span class="line">    data.loc[data[<span class="string">&#x27;zhi_2h_cnt&#x27;</span>] == <span class="number">0</span>, <span class="string">&#x27;buzhi_2h_ratio&#x27;</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### 1. magic特征</span></span><br><span class="line">    data = gen_magic_features(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 2. 历史销量滑窗统计特征</span></span><br><span class="line">    strides = [<span class="number">7</span>, <span class="number">150</span>] <span class="comment"># 150是指历史全部</span></span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> strides:</span><br><span class="line">        feats = gen_his_orders_stats(data, d)</span><br><span class="line">        data = data.merge(feats, on=[<span class="string">&#x27;article_id&#x27;</span>, <span class="string">&#x27;date&#x27;</span>], how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">        <span class="keyword">del</span> feats</span><br><span class="line">        gc.collect()</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 3. 当日、全局count统计特征</span></span><br><span class="line">    stats_col = [<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;level1&#x27;</span>, <span class="string">&#x27;level2&#x27;</span>, <span class="string">&#x27;level3&#x27;</span>, <span class="string">&#x27;level4&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;brand&#x27;</span>, <span class="string">&#x27;mall&#x27;</span>, <span class="string">&#x27;url&#x27;</span>, <span class="string">&#x27;baike_id_2h&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> tqdm(stats_col):</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_cnt&#x27;</span>] = data.groupby([col, <span class="string">&#x27;date&#x27;</span>])[<span class="string">&#x27;article_id&#x27;</span>].transform(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_global_cnt&#x27;</span>] = data.groupby([col])[<span class="string">&#x27;article_id&#x27;</span>].transform(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_cnt_ratio&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_cnt&#x27;</span>] / data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_global_cnt&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 4. 当日、当周、全局orders_1h、orders_2h统计特征</span></span><br><span class="line">    stats_col = [<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;level1&#x27;</span>, <span class="string">&#x27;level2&#x27;</span>, <span class="string">&#x27;level3&#x27;</span>, <span class="string">&#x27;level4&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;brand&#x27;</span>, <span class="string">&#x27;mall&#x27;</span>, <span class="string">&#x27;url&#x27;</span>, <span class="string">&#x27;baike_id_2h&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> [<span class="string">&#x27;orders_1h&#x27;</span>, <span class="string">&#x27;orders_2h&#x27;</span>]:</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> tqdm(stats_col):</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] = data.groupby([col, <span class="string">&#x27;date&#x27;</span>])[label].transform(<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] = data.groupby([col])[label].transform(<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_ratio&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] / data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>]</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_mean&#x27;</span>] = data.groupby([col, <span class="string">&#x27;date&#x27;</span>])[label].transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_vs_day_<span class="subst">&#123;label&#125;</span>&#x27;</span>] = data[label] / data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_mean&#x27;</span>]</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] = data.groupby([col, <span class="string">&#x27;week&#x27;</span>])[label].transform(<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_in_week_<span class="subst">&#123;label&#125;</span>_ratio&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] / data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>]</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_ratio&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] / data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 5. 当日、当周、全局收藏、点赞、评论统计特征</span></span><br><span class="line">    stats_col = [<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;url&#x27;</span>, <span class="string">&#x27;baike_id_1h&#x27;</span>, <span class="string">&#x27;baike_id_2h&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> [<span class="string">&#x27;comments_1h&#x27;</span>, <span class="string">&#x27;zhi_1h&#x27;</span>, <span class="string">&#x27;buzhi_1h&#x27;</span>, <span class="string">&#x27;favorite_1h&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;comments_2h&#x27;</span>, <span class="string">&#x27;zhi_2h&#x27;</span>, <span class="string">&#x27;buzhi_2h&#x27;</span>, <span class="string">&#x27;favorite_2h&#x27;</span>]:</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> tqdm(stats_col):</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] = data.groupby([col, <span class="string">&#x27;date&#x27;</span>])[label].transform(<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] = data.groupby([col, <span class="string">&#x27;week&#x27;</span>])[label].transform(<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] = data.groupby([col])[label].transform(<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_in_week_<span class="subst">&#123;label&#125;</span>_ratio&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] / data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>]</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_ratio&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] / data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>]</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_ratio&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>] / data[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 6. 商品价格、降价幅度统计特征</span></span><br><span class="line">    stats_col = [<span class="string">&#x27;baike_id_2h&#x27;</span>, <span class="string">&#x27;url&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> tqdm(stats_col):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> [<span class="string">&#x27;price&#x27;</span>, <span class="string">&#x27;price_diff&#x27;</span>, <span class="string">&#x27;price_diff_ratio&#x27;</span>]:</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_mean&#x27;</span>] = data.groupby([key])[col].transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_std&#x27;</span>] = data.groupby([key])[col].transform(<span class="string">&#x27;std&#x27;</span>)</span><br><span class="line">            data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_vs_mean&#x27;</span>] = data[col] / data[<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_mean&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 7. 当日、当周、全局nunique统计特征</span></span><br><span class="line">    stats_col = [[<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;url&#x27;</span>], [<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;baike_id_2h&#x27;</span>], [<span class="string">&#x27;baike_id_2h&#x27;</span>, <span class="string">&#x27;url&#x27;</span>]]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> tqdm(stats_col):</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_day&#x27;</span>] = data.groupby([col[<span class="number">0</span>], <span class="string">&#x27;date&#x27;</span>])[col[<span class="number">1</span>]].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_week&#x27;</span>] = data.groupby([col[<span class="number">0</span>], <span class="string">&#x27;week&#x27;</span>])[col[<span class="number">1</span>]].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_global&#x27;</span>] = data.groupby([col[<span class="number">0</span>]])[col[<span class="number">1</span>]].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_day&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_day&#x27;</span>] / data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_global&#x27;</span>]</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_week&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_week&#x27;</span>] / data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_global&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_day&#x27;</span>] = data.groupby([col[<span class="number">1</span>], <span class="string">&#x27;date&#x27;</span>])[col[<span class="number">0</span>]].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_week&#x27;</span>] = data.groupby([col[<span class="number">1</span>], <span class="string">&#x27;week&#x27;</span>])[col[<span class="number">0</span>]].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_global&#x27;</span>] = data.groupby([col[<span class="number">1</span>]])[col[<span class="number">0</span>]].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_day&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_day&#x27;</span>] / data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_global&#x27;</span>]</span><br><span class="line">        data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_week&#x27;</span>] = data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_week&#x27;</span>] / data[<span class="string">f&#x27;<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_global&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_dataset</span>(<span class="params">data, valid_start_date, gap</span>):</span></span><br><span class="line">    train = data[data[<span class="string">&#x27;date&#x27;</span>]&lt;valid_start_date].copy()</span><br><span class="line">    valid = data[(data[<span class="string">&#x27;date&#x27;</span>]&gt;=valid_start_date)&amp;(data[<span class="string">&#x27;date&#x27;</span>]&lt;valid_start_date+gap)].copy()</span><br><span class="line">    test = data[data[<span class="string">&#x27;date&#x27;</span>]&gt;=valid_start_date+gap].copy()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;训练集样本数: <span class="subst">&#123;train.shape[<span class="number">0</span>]&#125;</span>, 验证集样本数: <span class="subst">&#123;valid.shape[<span class="number">0</span>]&#125;</span>, 测试集样本数: <span class="subst">&#123;test.shape[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> train, valid, test</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lgb_reg_model</span>(<span class="params">train, valid, test, target</span>):</span></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.05</span>,</span><br><span class="line">        <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;regression&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;metric&#x27;</span>: <span class="string">&#x27;l2&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;feature_fraction&#x27;</span>: <span class="number">0.8</span>,</span><br><span class="line">        <span class="string">&#x27;bagging_fraction&#x27;</span>: <span class="number">0.8</span>,</span><br><span class="line">        <span class="string">&#x27;min_data_in_leaf&#x27;</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="string">&#x27;verbose&#x27;</span>: -<span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;nthread&#x27;</span>: <span class="number">16</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    feats = [f <span class="keyword">for</span> f <span class="keyword">in</span> train.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;article_id&#x27;</span>, <span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;orders_3h_15h&#x27;</span>, <span class="string">&#x27;week&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;线下训练集样本数：%d&#x27;</span> % (train.shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;线下验证集样本数：%d&#x27;</span> % (valid.shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;特征个数：%d&#x27;</span> % (<span class="built_in">len</span>(feats)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;开始线下验证......&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    dtrain = lgb.Dataset(train[feats],</span><br><span class="line">                         label=train[target])</span><br><span class="line">    dvalid = lgb.Dataset(valid[feats],</span><br><span class="line">                         label=valid[target])</span><br><span class="line">    lgb_model = lgb.train(params,</span><br><span class="line">                          dtrain,</span><br><span class="line">                          num_boost_round=<span class="number">10000</span>,</span><br><span class="line">                          valid_sets=[dvalid],</span><br><span class="line">                          early_stopping_rounds=<span class="number">100</span>,</span><br><span class="line">                          verbose_eval=<span class="number">100</span>)</span><br><span class="line">    valid_preds = lgb_model.predict(valid[feats].values, num_iteration=lgb_model.best_iteration)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;--------------------------特征重要性----------------------------&#x27;</span>)</span><br><span class="line">    feature_importance = pd.DataFrame()</span><br><span class="line">    feature_importance[<span class="string">&#x27;features&#x27;</span>] = feats</span><br><span class="line">    feature_importance[<span class="string">&#x27;importance&#x27;</span>] = lgb_model.feature_importance(importance_type=<span class="string">&#x27;gain&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(feature_importance.sort_values(by=<span class="string">&#x27;importance&#x27;</span>, ascending=<span class="literal">False</span>).head(<span class="number">15</span>))</span><br><span class="line">    <span class="keyword">del</span> dtrain, dvalid</span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line">    preds = <span class="number">0</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;开始线上预测...&#x27;</span>)</span><br><span class="line">    best_iters = <span class="built_in">int</span>(lgb_model.best_iteration*<span class="number">1.2</span>)</span><br><span class="line">    all_train = pd.concat([train, valid], axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line">    dtrain = lgb.Dataset(all_train[feats],</span><br><span class="line">                         label=all_train[target])</span><br><span class="line">    <span class="keyword">del</span> all_train</span><br><span class="line">    gc.collect()</span><br><span class="line">    lgb_model = lgb.train(params,</span><br><span class="line">                          dtrain,</span><br><span class="line">                          num_boost_round=best_iters,</span><br><span class="line">                          verbose_eval=<span class="number">100</span>,</span><br><span class="line">                          )</span><br><span class="line">    preds = lgb_model.predict(test[feats])</span><br><span class="line">    <span class="keyword">return</span> valid_preds, preds</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cbt_reg_model</span>(<span class="params">train, valid, test, target</span>):</span></span><br><span class="line">    catboost_params = &#123;</span><br><span class="line">        <span class="string">&#x27;iterations&#x27;</span>: <span class="number">10000</span>,</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.05</span>,</span><br><span class="line">        <span class="string">&#x27;eval_metric&#x27;</span>: <span class="string">&#x27;RMSE&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;task_type&#x27;</span>: <span class="string">&#x27;GPU&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;early_stopping_rounds&#x27;</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="string">&#x27;use_best_model&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&#x27;verbose&#x27;</span>: <span class="number">100</span>,</span><br><span class="line">        <span class="string">&#x27;depth&#x27;</span>: <span class="number">10</span>,</span><br><span class="line">        <span class="string">&#x27;bootstrap_type&#x27;</span>: <span class="string">&#x27;Bernoulli&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;Plain&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;subsample&#x27;</span>: <span class="number">0.8</span></span><br><span class="line">    &#125;</span><br><span class="line">    feats = [f <span class="keyword">for</span> f <span class="keyword">in</span> train.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;article_id&#x27;</span>, <span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;orders_3h_15h&#x27;</span>, <span class="string">&#x27;week&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;线下训练集样本数：%d&#x27;</span> % (train.shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;线下验证集样本数：%d&#x27;</span> % (valid.shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;特征个数：%d&#x27;</span> % (<span class="built_in">len</span>(feats)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;开始线下验证......&#x27;</span>)</span><br><span class="line">    dtrain = Pool(train[feats].values,</span><br><span class="line">                  label=train[target])</span><br><span class="line">    dvalid = Pool(valid[feats].values,</span><br><span class="line">                  label=valid[target])</span><br><span class="line">    cbt_model = CatBoostRegressor(**catboost_params)</span><br><span class="line">    cbt_model.fit(dtrain, eval_set=dvalid)</span><br><span class="line">    <span class="comment">#     print(cbt_model.best_score_[&#x27;validation&#x27;])</span></span><br><span class="line">    score = cbt_model.best_score_[<span class="string">&#x27;validation&#x27;</span>][<span class="string">&#x27;RMSE&#x27;</span>]</span><br><span class="line">    valid_preds = cbt_model.predict(valid[feats].values)</span><br><span class="line">    <span class="keyword">del</span> dtrain, dvalid</span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;开始线上预测......&#x27;</span>)</span><br><span class="line">    best_iters = <span class="built_in">int</span>(cbt_model.best_iteration_ * <span class="number">1.2</span>)</span><br><span class="line">    catboost_params = &#123;</span><br><span class="line">        <span class="string">&#x27;iterations&#x27;</span>: best_iters,</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.05</span>,</span><br><span class="line">        <span class="string">&#x27;eval_metric&#x27;</span>: <span class="string">&#x27;RMSE&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;task_type&#x27;</span>: <span class="string">&#x27;GPU&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;early_stopping_rounds&#x27;</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="comment">#         &#x27;use_best_model&#x27;: True,</span></span><br><span class="line">        <span class="string">&#x27;verbose&#x27;</span>: <span class="number">100</span>,</span><br><span class="line">        <span class="string">&#x27;depth&#x27;</span>: <span class="number">10</span>,</span><br><span class="line">        <span class="string">&#x27;bootstrap_type&#x27;</span>: <span class="string">&#x27;Bernoulli&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;Plain&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;subsample&#x27;</span>: <span class="number">0.8</span></span><br><span class="line">    &#125;</span><br><span class="line">    all_train = pd.concat([train, valid], axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    dtrain = Pool(all_train[feats],</span><br><span class="line">                  label=all_train[target])</span><br><span class="line">    <span class="keyword">del</span> all_train</span><br><span class="line">    gc.collect()</span><br><span class="line">    cbt_model = CatBoostRegressor(**catboost_params)</span><br><span class="line">    cbt_model.fit(dtrain)</span><br><span class="line">    <span class="keyword">del</span> dtrain</span><br><span class="line">    gc.collect()</span><br><span class="line">    preds = cbt_model.predict(test[feats].values)</span><br><span class="line">    <span class="keyword">return</span> valid_preds, preds</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xgb_reg_model</span>(<span class="params">train, valid, test, target</span>):</span></span><br><span class="line">    feats = [f <span class="keyword">for</span> f <span class="keyword">in</span> train.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;article_id&#x27;</span>, <span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;orders_3h_15h&#x27;</span>,</span><br><span class="line">                                                   <span class="string">&#x27;week&#x27;</span>, <span class="string">&#x27;baike_id_2h_price_diff_vs_mean&#x27;</span>, <span class="string">&#x27;baike_id_2h_price_diff_ratio_vs_mean&#x27;</span>,</span><br><span class="line">                                                   <span class="string">&#x27;url_price_diff_vs_mean&#x27;</span>, <span class="string">&#x27;url_price_diff_ratio_vs_mean&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;线下训练集样本数：%d&#x27;</span> % (train.shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;线下验证集样本数：%d&#x27;</span> % (valid.shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;特征个数：%d&#x27;</span> % (<span class="built_in">len</span>(feats)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;开始线下验证......&#x27;</span>)</span><br><span class="line">    clf = xgb.XGBRegressor(</span><br><span class="line">        n_estimators=<span class="number">10000</span>,</span><br><span class="line">        max_depth=<span class="number">12</span>,</span><br><span class="line">        learning_rate=<span class="number">0.02</span>,</span><br><span class="line">        subsample=<span class="number">0.8</span>,</span><br><span class="line">        colsample_bytree=<span class="number">0.4</span>,</span><br><span class="line">        missing=-<span class="number">1</span>,</span><br><span class="line">        eval_metric=<span class="string">&#x27;rmse&#x27;</span>,</span><br><span class="line">        <span class="comment"># USE CPU</span></span><br><span class="line">        <span class="comment"># nthread=4,</span></span><br><span class="line">        <span class="comment"># tree_method=&#x27;hist&#x27;</span></span><br><span class="line">        <span class="comment"># USE GPU</span></span><br><span class="line">        tree_method=<span class="string">&#x27;gpu_hist&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    xgb_model = clf.fit(train[feats], train[target],</span><br><span class="line">                        eval_set=[(valid[feats], valid[target])],</span><br><span class="line">                        verbose=<span class="number">100</span>,</span><br><span class="line">                        early_stopping_rounds=<span class="number">200</span>)</span><br><span class="line">    valid_preds = xgb_model.predict(valid[feats].values)</span><br><span class="line">    <span class="comment">#     del dtrain, dvalid</span></span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;开始线上预测......&#x27;</span>)</span><br><span class="line">    best_iters = <span class="built_in">int</span>(xgb_model.best_iteration * <span class="number">1.2</span>)</span><br><span class="line">    clf = xgb.XGBRegressor(</span><br><span class="line">        n_estimators=best_iters,</span><br><span class="line">        max_depth=<span class="number">12</span>,</span><br><span class="line">        learning_rate=<span class="number">0.02</span>,</span><br><span class="line">        subsample=<span class="number">0.8</span>,</span><br><span class="line">        colsample_bytree=<span class="number">0.4</span>,</span><br><span class="line">        missing=-<span class="number">1</span>,</span><br><span class="line">        eval_metric=<span class="string">&#x27;rmse&#x27;</span>,</span><br><span class="line">        <span class="comment"># USE CPU</span></span><br><span class="line">        <span class="comment"># nthread=4,</span></span><br><span class="line">        <span class="comment"># tree_method=&#x27;hist&#x27;</span></span><br><span class="line">        <span class="comment"># USE GPU</span></span><br><span class="line">        tree_method=<span class="string">&#x27;gpu_hist&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    all_train = pd.concat([train, valid], axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    xgb_model = clf.fit(all_train[feats],</span><br><span class="line">                        all_train[target],</span><br><span class="line">                        verbose=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">del</span> all_train</span><br><span class="line">    gc.collect()</span><br><span class="line">    preds = xgb_model.predict(test[feats].values)</span><br><span class="line">    <span class="keyword">return</span> valid_preds, preds</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_submission</span>(<span class="params">df, preds, sub_path</span>):</span></span><br><span class="line">    sub = df[[<span class="string">&#x27;article_id&#x27;</span>]].copy()</span><br><span class="line">    sub[<span class="string">&#x27;orders_3h_15h&#x27;</span>] = preds</span><br><span class="line">    sub[<span class="string">&#x27;orders_3h_15h&#x27;</span>] = sub[<span class="string">&#x27;orders_3h_15h&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="number">0</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> x)</span><br><span class="line">    sub.to_csv(sub_path+<span class="string">&#x27;sub.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">data_path, sub_path</span>):</span></span><br><span class="line">    train_df, test_df = load_dataset(data_path) <span class="comment"># 读取数据</span></span><br><span class="line">    data = feature_extractor(train_df, test_df) <span class="comment"># 生成特征</span></span><br><span class="line">    train, valid, test = split_dataset(data=data, valid_start_date=<span class="number">110</span>, gap=<span class="number">7</span>) <span class="comment"># 划分训练\验证集</span></span><br><span class="line">    <span class="keyword">del</span> train_df, test_df</span><br><span class="line">    gc.collect()</span><br><span class="line">    lgb_oof, lgb_preds = lgb_reg_model(train, valid, test, <span class="string">&#x27;orders_3h_15h&#x27;</span>) <span class="comment"># lightgbm</span></span><br><span class="line">    cbt_oof, cbt_preds = cbt_reg_model(train, valid, test, <span class="string">&#x27;orders_3h_15h&#x27;</span>)  <span class="comment"># catboost</span></span><br><span class="line">    xgb_oof, xgb_preds = xgb_reg_model(train, valid, test, <span class="string">&#x27;orders_3h_15h&#x27;</span>)  <span class="comment"># xgboost</span></span><br><span class="line">    preds = <span class="number">0.3</span>*lgb_preds + <span class="number">0.5</span>*cbt_preds + <span class="number">0.2</span>*xgb_preds <span class="comment"># 加权融合</span></span><br><span class="line">    gen_submission(test, preds, sub_path) <span class="comment"># 生成提交文件</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data_path = <span class="string">&#x27;../data/&#x27;</span></span><br><span class="line">    sub_path = <span class="string">&#x27;../submission/&#x27;</span></span><br><span class="line">    main(data_path, sub_path)</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li>[1] <a target="_blank" rel="noopener" href="https://github.com/cXPromise/2021ECAA_Top2_Solution">https://github.com/cXPromise/2021ECAA_Top2_Solution</a></li>
<li>[2] <a target="_blank" rel="noopener" href="https://www.automl.ai/competitions/19#home">https://www.automl.ai/competitions/19#home</a></li>
<li>[3] <a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/1WLK3Dq6HMTB7Y34dt5b_jqc0Rg0jevNr?usp=sharing">https://drive.google.com/drive/folders/1WLK3Dq6HMTB7Y34dt5b_jqc0Rg0jevNr?usp=sharing</a></li>
</ul>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/">数据竞赛</a></div><div class="post_share"><div class="social-share" data-image="https://www.cdnjson.com/images/2021/10/06/0.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/10/21/%E4%BD%95%E4%B8%BA%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF/"><img class="prev-cover" src="https://www.cdnjson.com/images/2021/10/22/1.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">何为转置卷积?</div></div></a></div><div class="next-post pull-right"><a href="/2021/09/30/%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1AI%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9Bbaseline/"><img class="next-cover" src="https://www.cdnjson.com/images/2021/10/06/0.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">电子商务AI算法大赛baseline</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/08/21/FlyAI%E8%98%91%E8%8F%87%E5%88%86%E7%B1%BB%E7%AB%9E%E8%B5%9BTOP5%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/" title="FlyAI蘑菇分类竞赛TOP5方案分享"><img class="cover" src="https://www.cdnjson.com/images/2021/08/27/thomas-bormans-ZtM-W-3f0C4-unsplash.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-21</div><div class="title">FlyAI蘑菇分类竞赛TOP5方案分享</div></div></a></div><div><a href="/2021/09/30/%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1AI%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9Bbaseline/" title="电子商务AI算法大赛baseline"><img class="cover" src="https://www.cdnjson.com/images/2021/10/06/0.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-09-30</div><div class="title">电子商务AI算法大赛baseline</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">雨落诗山山亦奇</div><div class="author-info__description">本站为读研版&工作版博客，大学版移步 --> fuhanshi.github.io</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">157</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">10</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">本站内容的最终版本将发布在微信公众号[南极Python]</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E4%B8%8B%E9%AA%8C%E8%AF%81%E6%96%B9%E6%A1%88"><span class="toc-number">1.</span> <span class="toc-text">线下验证方案</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AD%94%E6%B3%95%E7%89%B9%E5%BE%81"><span class="toc-number">2.</span> <span class="toc-text">魔法特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%84%E7%89%B9%E5%BE%81"><span class="toc-number">3.</span> <span class="toc-text">常规特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1"><span class="toc-number">4.</span> <span class="toc-text">数据建模</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/01/07/%E5%9B%BE%E5%83%8F%E9%85%8D%E5%87%86/" title="图像配准小结"><img src="https://s21.ax1x.com/2024/04/22/pk9mOqf.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图像配准小结"/></a><div class="content"><a class="title" href="/2024/01/07/%E5%9B%BE%E5%83%8F%E9%85%8D%E5%87%86/" title="图像配准小结">图像配准小结</a><time datetime="2024-01-07T11:18:38.000Z" title="发表于 2024-01-07 19:18:38">2024-01-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/25/SAM%E9%AA%A8%E5%B9%B2%E8%BF%81%E7%A7%BB/" title="将SAM编码器迁移到自定义分割子任务中"><img src="https://s21.ax1x.com/2024/04/22/pk9myG9.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="将SAM编码器迁移到自定义分割子任务中"/></a><div class="content"><a class="title" href="/2023/10/25/SAM%E9%AA%A8%E5%B9%B2%E8%BF%81%E7%A7%BB/" title="将SAM编码器迁移到自定义分割子任务中">将SAM编码器迁移到自定义分割子任务中</a><time datetime="2023-10-25T11:18:38.000Z" title="发表于 2023-10-25 19:18:38">2023-10-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/27/ViT%E9%A2%84%E8%AE%AD%E7%BB%83%E6%9D%83%E9%87%8D%E8%BF%81%E7%A7%BB-%E5%AE%9E%E7%8E%B0%E4%BB%BB%E6%84%8F%E5%B0%BA%E5%AF%B8%E8%BE%93%E5%85%A5/" title="ViT预训练权重迁移-实现任意尺寸输入"><img src="https://z3.ax1x.com/2021/04/10/cajxDs.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ViT预训练权重迁移-实现任意尺寸输入"/></a><div class="content"><a class="title" href="/2023/09/27/ViT%E9%A2%84%E8%AE%AD%E7%BB%83%E6%9D%83%E9%87%8D%E8%BF%81%E7%A7%BB-%E5%AE%9E%E7%8E%B0%E4%BB%BB%E6%84%8F%E5%B0%BA%E5%AF%B8%E8%BE%93%E5%85%A5/" title="ViT预训练权重迁移-实现任意尺寸输入">ViT预训练权重迁移-实现任意尺寸输入</a><time datetime="2023-09-27T11:18:38.000Z" title="发表于 2023-09-27 19:18:38">2023-09-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/02/%E5%A6%82%E4%BD%95%E5%B0%86PyTorch%E6%9D%83%E9%87%8D%E8%BD%AC%E6%8D%A2%E6%88%90TensorRT%E7%9A%84engine/" title="如何将PyTorch权重转换成TensorRT的engine"><img src="https://s21.ax1x.com/2024/04/22/pk9nSiQ.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何将PyTorch权重转换成TensorRT的engine"/></a><div class="content"><a class="title" href="/2023/09/02/%E5%A6%82%E4%BD%95%E5%B0%86PyTorch%E6%9D%83%E9%87%8D%E8%BD%AC%E6%8D%A2%E6%88%90TensorRT%E7%9A%84engine/" title="如何将PyTorch权重转换成TensorRT的engine">如何将PyTorch权重转换成TensorRT的engine</a><time datetime="2023-09-02T11:18:38.000Z" title="发表于 2023-09-02 19:18:38">2023-09-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/09/%E6%89%A9%E6%95%A3/" title="AI绘画的基石-DDPM"><img src="https://s21.ax1x.com/2024/04/22/pk9mBaF.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AI绘画的基石-DDPM"/></a><div class="content"><a class="title" href="/2023/05/09/%E6%89%A9%E6%95%A3/" title="AI绘画的基石-DDPM">AI绘画的基石-DDPM</a><time datetime="2023-05-09T11:18:38.000Z" title="发表于 2023-05-09 19:18:38">2023-05-09</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://www.cdnjson.com/images/2021/10/06/0.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By 雨落诗山山亦奇</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>