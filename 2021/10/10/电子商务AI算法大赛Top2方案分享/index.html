<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>电子商务AI算法大赛Top2方案分享 | 南极Python</title><meta name="description" content="上一次，我们介绍了电子商务AI算法大赛中我个人的解决方案。虽然在经过一顿操作后，线上分数得到了肉眼可见的提升，但相比于大佬们的成绩还是差了亿点点的 所以呢，这次来解读top2选手的解决方案，从优秀开源代码中学习思路，积累经验。 关于赛题的介绍以及数据集说明，可以回看上一篇文章哈：xxxxxx 线下验证方案date字段代表的是第几天，训练集中date的取值范围是从1 到116，共116天；测试集中d"><meta name="keywords" content="数据竞赛"><meta name="author" content="雨落诗山山亦奇"><meta name="copyright" content="雨落诗山山亦奇"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/avatar.png"><link rel="canonical" href="http://yoursite.com/2021/10/10/%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1AI%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9BTop2%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="电子商务AI算法大赛Top2方案分享"><meta property="og:url" content="http://yoursite.com/2021/10/10/%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1AI%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9BTop2%E6%96%B9%E6%A1%88%E5%88%86%E4%BA%AB/"><meta property="og:site_name" content="南极Python"><meta property="og:description" content="上一次，我们介绍了电子商务AI算法大赛中我个人的解决方案。虽然在经过一顿操作后，线上分数得到了肉眼可见的提升，但相比于大佬们的成绩还是差了亿点点的 所以呢，这次来解读top2选手的解决方案，从优秀开源代码中学习思路，积累经验。 关于赛题的介绍以及数据集说明，可以回看上一篇文章哈：xxxxxx 线下验证方案date字段代表的是第几天，训练集中date的取值范围是从1 到116，共116天；测试集中d"><meta property="og:image" content="https://www.cdnjson.com/images/2021/10/06/0.png"><meta property="article:published_time" content="2021-10-10T06:25:26.000Z"><meta property="article:modified_time" content="2021-10-10T09:13:45.856Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="prev" title="经典语义分割网络:FCN" href="http://yoursite.com/2021/10/21/%E7%BB%8F%E5%85%B8%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C-FCN/"><link rel="next" title="算法下" href="http://yoursite.com/2021/10/06/%E7%AE%97%E6%B3%95%E4%B8%8B/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"我爱学习,机器学习,深度学习,学习使我快乐","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-10-10 17:13:45'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><link rel="stylesheet" href="/css/mouse.css">
<link rel="stylesheet" href="/css/gundongtiao.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/macblack.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"> <link rel="stylesheet" href="/css/waigua.css"> <link rel="stylesheet" href="/css/beijing.css"><div class="aplayer" data-id="476185587" data-server="netease" data-type="playlist" data-fixed="true" data-listFolded="false" data-order="list" data-preload="auto"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/lete114/CDN/music/APlayer/APlayer.min.css"><script src="https://cdn.jsdelivr.net/gh/lete114/CDN/music/APlayer/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@1.2.0/dist/Meting.min.js"></script><meta name="generator" content="Hexo 4.2.1"></head><body><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">126</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">12</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#线下验证方案"><span class="toc-number">1.</span> <span class="toc-text">线下验证方案</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#魔法特征"><span class="toc-number">2.</span> <span class="toc-text">魔法特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#常规特征"><span class="toc-number">3.</span> <span class="toc-text">常规特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据建模"><span class="toc-number">4.</span> <span class="toc-text">数据建模</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">5.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div><div id="body-wrap"><div id="web_bg" data-type="color"></div><header class="post-bg" id="page-header" style="background-image: url(https://www.cdnjson.com/images/2021/10/06/0.png)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">南极Python</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">电子商务AI算法大赛Top2方案分享</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2021-10-10 14:25:26"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2021-10-10</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2021-10-10 17:13:45"><i class="fas fa-history fa-fw"></i> 更新于 2021-10-10</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/">数据竞赛</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>上一次，我们介绍了电子商务AI算法大赛中我个人的解决方案。虽然在经过一顿操作后，线上分数得到了肉眼可见的提升，但相比于大佬们的成绩还是差了亿点点的<br><img src= "/img/loading.gif" data-src="./7.png" alt="Alt text"></p>
<p>所以呢，这次来解读top2选手的解决方案，从优秀开源代码中学习思路，积累经验。</p>
<p>关于赛题的介绍以及数据集说明，可以回看上一篇文章哈：xxxxxx</p>
<h2 id="线下验证方案"><a href="#线下验证方案" class="headerlink" title="线下验证方案"></a>线下验证方案</h2><p>date字段代表的是第几天，训练集中date的取值范围是从1 到116，共116天；测试集中date的取值范围是117到123共7天。于是从训练集中划出最后7天的数据作为验证集进行线下验证：</p>
<p><img src= "/img/loading.gif" data-src="./1.png" alt="Alt text"></p>
<p>而在最终提交时，取消验证集，用全部训练数据进行训练：</p>
<p><img src= "/img/loading.gif" data-src="./2.png" alt="Alt text"></p>
<p>数据集划分代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_dataset</span><span class="params">(data, valid_start_date, gap)</span>:</span></span><br><span class="line">    train = data[data[<span class="string">'date'</span>]&lt;valid_start_date].copy()</span><br><span class="line">    valid = data[(data[<span class="string">'date'</span>]&gt;=valid_start_date)&amp;(data[<span class="string">'date'</span>]&lt;valid_start_date+gap)].copy()</span><br><span class="line">    test = data[data[<span class="string">'date'</span>]&gt;=valid_start_date+gap].copy()</span><br><span class="line">    print(<span class="string">f'训练集样本数: <span class="subst">&#123;train.shape[<span class="number">0</span>]&#125;</span>, 验证集样本数: <span class="subst">&#123;valid.shape[<span class="number">0</span>]&#125;</span>, 测试集样本数: <span class="subst">&#123;test.shape[<span class="number">0</span>]&#125;</span>'</span>)</span><br><span class="line">    <span class="keyword">return</span> train, valid, test</span><br></pre></td></tr></table></figure>

<p>调用时：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train, valid, test = split_dataset(data=data, valid_start_date=<span class="number">110</span>, gap=<span class="number">7</span>) <span class="comment"># 划分训练\验证集</span></span><br></pre></td></tr></table></figure>
<h2 id="魔法特征"><a href="#魔法特征" class="headerlink" title="魔法特征"></a>魔法特征</h2><p>魔法特征，就是能够给模型带来大幅度涨分的特征。</p>
<p>绘制<code>article_id</code>的折线图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">y=train_df[<span class="string">'article_id'</span>][:<span class="number">200</span>]</span><br><span class="line">x=[i <span class="keyword">for</span> i <span class="keyword">in</span> range(len(y))]</span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.ylabel(<span class="string">'article_id'</span>)</span><br><span class="line">plt.savefig(<span class="string">'article_id.png'</span>,dpi=<span class="number">600</span>)</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="./3.png" alt="Alt text"></p>
<p>观察上图，发现<code>article_id</code>的取值呈现周期性变化。</p>
<p>纵坐标<code>article_id</code>指的是文章id取值，而横坐标是时间推移，这里的时间在一天内。</p>
<p>而如果绘制全部116天的<code>article_id</code>折线图，这种周期性规律就不复存在了：<br><img src= "/img/loading.gif" data-src="./4.png" alt="Alt text"></p>
<p>所以，猜想<code>article_id</code>这个特征应该是与时间有关的，具体地，某件商品的销量在一天内会呈现周期性变动。</p>
<p>既然这种规律是存在于一天内的，那自然就想到按照天数进行分组，同一天的数据归为同一组。</p>
<p>然后对每组内的<code>article_id</code>进行排序，就得到了一个新的特征：<code>magic_rank</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">'magic_rank'</span>] = data.groupby([<span class="string">'date'</span>])[<span class="string">'article_id'</span>].rank()</span><br></pre></td></tr></table></figure>

<p>基于该思想，可以构建出许多有用的新特征。</p>
<p>比如，将<code>date</code>改为其它特征，将<code>rank</code>改为常见的统计量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">g = data.groupby(f)<span class="comment">#f是某个特征，比如`mall`，`author`</span></span><br><span class="line"><span class="keyword">for</span> stat <span class="keyword">in</span> [<span class="string">'max'</span>, <span class="string">'min'</span>, <span class="string">'mean'</span>]:</span><br><span class="line">    data[<span class="string">f'magic_<span class="subst">&#123;name&#125;</span>_id_<span class="subst">&#123;stat&#125;</span>'</span>] = g[<span class="string">'article_id'</span>].transform(stat)</span><br></pre></td></tr></table></figure>

<p>再比如，将<code>date</code>改为其它特征，计算偏移量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">g = data.groupby(f)</span><br><span class="line">name = <span class="string">'_'</span>.join(f)</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>]:</span><br><span class="line">    data[<span class="string">f'magic_<span class="subst">&#123;name&#125;</span>_aft_gap<span class="subst">&#123;n&#125;</span>'</span>] = g[<span class="string">'article_id'</span>].shift(-n) - g[<span class="string">'article_id'</span>].shift(<span class="number">0</span>)</span><br><span class="line">    data[<span class="string">f'magic_<span class="subst">&#123;name&#125;</span>_bef_gap<span class="subst">&#123;n&#125;</span>'</span>] = g[<span class="string">'article_id'</span>].shift(<span class="number">0</span>) - g[<span class="string">'article_id'</span>].shift(n)</span><br></pre></td></tr></table></figure>
<p>还有许多特征衍生操作，这里不再一一列举，完整代码见文末。</p>
<h2 id="常规特征"><a href="#常规特征" class="headerlink" title="常规特征"></a>常规特征</h2><p>这一部分提取了一些字段的当日，当周以及全局的统计特征，以及历史销量滑窗的统计特征等：<br><img src= "/img/loading.gif" data-src="./5.png" alt="Alt text"></p>
<p>历史销量滑窗的统计特征:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_his_orders_stats</span><span class="params">(data, stride)</span>:</span></span><br><span class="line">    orders_mean_feats = []</span><br><span class="line">    orders_cols = [<span class="string">'author'</span>, <span class="string">'level1'</span>, <span class="string">'level2'</span>, <span class="string">'level3'</span>, <span class="string">'level4'</span>,</span><br><span class="line">                   <span class="string">'brand'</span>, <span class="string">'mall'</span>, <span class="string">'url'</span>, <span class="string">'baike_id_1h'</span>, <span class="string">'baike_id_2h'</span>]</span><br><span class="line">    <span class="keyword">for</span> date <span class="keyword">in</span> tqdm(range(<span class="number">4</span>, <span class="number">124</span>, <span class="number">7</span>)):</span><br><span class="line">        his_data = data[(data[<span class="string">'date'</span>]&lt;=date)&amp;(data[<span class="string">'date'</span>]&gt;date-stride)].copy()</span><br><span class="line">        df = data[(data[<span class="string">'date'</span>]&gt;date)&amp;(data[<span class="string">'date'</span>]&lt;=date+<span class="number">7</span>)][[<span class="string">'article_id'</span>, <span class="string">'date'</span>]+orders_cols].copy()</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> orders_cols:</span><br><span class="line">            gp = his_data.groupby(col)[<span class="string">'orders_3h_15h'</span>].agg([[<span class="string">f'<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_mean'</span>, <span class="string">'mean'</span>],</span><br><span class="line">                                                             [<span class="string">f'<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_std'</span>, <span class="string">'std'</span>],</span><br><span class="line">                                                             [<span class="string">f'<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_min'</span>, <span class="string">'min'</span>],</span><br><span class="line">                                                             [<span class="string">f'<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_max'</span>, <span class="string">'max'</span>],</span><br><span class="line">                                                             [<span class="string">f'<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_med'</span>, <span class="string">'median'</span>]]).reset_index()</span><br><span class="line">            df = df.merge(gp, on=col, how=<span class="string">'left'</span>)</span><br><span class="line">        orders_mean_feats.append(df)</span><br><span class="line">    orders_mean_feats = pd.concat(orders_mean_feats, axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line">    orders_mean_feats.drop(orders_cols, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)<span class="comment">#后面与其它表拼接，这里去除与其它表重复的字段，避免重复。</span></span><br><span class="line">    <span class="keyword">return</span> orders_mean_feats</span><br></pre></td></tr></table></figure>
<p>调用时：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">strides = [<span class="number">7</span>, <span class="number">150</span>] <span class="comment"># 150是指历史全部</span></span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> strides:</span><br><span class="line">    feats = gen_his_orders_stats(data, d)</span><br><span class="line">    data = data.merge(feats, on=[<span class="string">'article_id'</span>, <span class="string">'date'</span>], how=<span class="string">'left'</span>)</span><br></pre></td></tr></table></figure>

<h2 id="数据建模"><a href="#数据建模" class="headerlink" title="数据建模"></a>数据建模</h2><p>训练了树模型以及深度学习模型，并将结果进行加权融合<br><img src= "/img/loading.gif" data-src="./6.png" alt="Alt text"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>对于本题来说，模型以及调参部分，大家都大差不差，分水岭在于特征工程，因此很有必要加强自己的特征工程能力(pandas+业务理解)，这样才有可能在下个赛场冲进前排。</p>
<p>最后奉上完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding：utf-8 -*-</span></span><br><span class="line"><span class="comment"># Author: Ethan</span></span><br><span class="line"><span class="comment"># Time: 2021/8/31 14:20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostRegressor, Pool</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span><span class="params">(path)</span>:</span></span><br><span class="line">    train_df = pd.read_csv(path+<span class="string">'train.csv'</span>)</span><br><span class="line">    test_df = pd.read_csv(path+<span class="string">'test.csv'</span>)</span><br><span class="line">    <span class="keyword">return</span> train_df, test_df</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_his_orders_stats</span><span class="params">(data, stride)</span>:</span></span><br><span class="line">    orders_mean_feats = []</span><br><span class="line">    orders_cols = [<span class="string">'author'</span>, <span class="string">'level1'</span>, <span class="string">'level2'</span>, <span class="string">'level3'</span>, <span class="string">'level4'</span>,</span><br><span class="line">                   <span class="string">'brand'</span>, <span class="string">'mall'</span>, <span class="string">'url'</span>, <span class="string">'baike_id_1h'</span>, <span class="string">'baike_id_2h'</span>]</span><br><span class="line">    <span class="keyword">for</span> date <span class="keyword">in</span> tqdm(range(<span class="number">4</span>, <span class="number">124</span>, <span class="number">7</span>)):</span><br><span class="line">        his_data = data[(data[<span class="string">'date'</span>]&lt;=date)&amp;(data[<span class="string">'date'</span>]&gt;date-stride)].copy()</span><br><span class="line">        df = data[(data[<span class="string">'date'</span>]&gt;date)&amp;(data[<span class="string">'date'</span>]&lt;=date+<span class="number">7</span>)][[<span class="string">'article_id'</span>, <span class="string">'date'</span>]+orders_cols].copy()</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> orders_cols:</span><br><span class="line">            gp = his_data.groupby(col)[<span class="string">'orders_3h_15h'</span>].agg([[<span class="string">f'<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_mean'</span>, <span class="string">'mean'</span>],</span><br><span class="line">                                                             [<span class="string">f'<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_std'</span>, <span class="string">'std'</span>],</span><br><span class="line">                                                             [<span class="string">f'<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_min'</span>, <span class="string">'min'</span>],</span><br><span class="line">                                                             [<span class="string">f'<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_max'</span>, <span class="string">'max'</span>],</span><br><span class="line">                                                             [<span class="string">f'<span class="subst">&#123;col&#125;</span>_orders_<span class="subst">&#123;stride&#125;</span>d_med'</span>, <span class="string">'median'</span>]]).reset_index()</span><br><span class="line">            df = df.merge(gp, on=col, how=<span class="string">'left'</span>)</span><br><span class="line">        orders_mean_feats.append(df)</span><br><span class="line">    orders_mean_feats = pd.concat(orders_mean_feats, axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line">    orders_mean_feats.drop(orders_cols, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)<span class="comment">#后面与其它表拼接，这里去除与其它表重复的字段，避免重复字段。</span></span><br><span class="line">    <span class="keyword">return</span> orders_mean_feats</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_magic_features</span><span class="params">(data)</span>:</span></span><br><span class="line">    data[<span class="string">'magic_rank'</span>] = data.groupby([<span class="string">'date'</span>])[<span class="string">'article_id'</span>].rank()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> tqdm([[<span class="string">'author'</span>],</span><br><span class="line">                   [<span class="string">'brand'</span>],</span><br><span class="line">                   [<span class="string">'mall'</span>],</span><br><span class="line">                   [<span class="string">'price'</span>],</span><br><span class="line">                   [<span class="string">'level1'</span>],</span><br><span class="line">                   [<span class="string">'level2'</span>],</span><br><span class="line">                   [<span class="string">'price'</span>],</span><br><span class="line">                   [<span class="string">'author'</span>, <span class="string">'brand'</span>]]):</span><br><span class="line">        g = data.groupby(f)</span><br><span class="line">        name = <span class="string">'_'</span>.join(f)</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>]:</span><br><span class="line">            data[<span class="string">f'magic_<span class="subst">&#123;name&#125;</span>_aft_gap<span class="subst">&#123;n&#125;</span>'</span>] = g[<span class="string">'article_id'</span>].shift(-n) - g[<span class="string">'article_id'</span>].shift(<span class="number">0</span>)</span><br><span class="line">            data[<span class="string">f'magic_<span class="subst">&#123;name&#125;</span>_bef_gap<span class="subst">&#123;n&#125;</span>'</span>] = g[<span class="string">'article_id'</span>].shift(<span class="number">0</span>) - g[<span class="string">'article_id'</span>].shift(n)</span><br><span class="line">        <span class="keyword">for</span> stat <span class="keyword">in</span> [<span class="string">'max'</span>, <span class="string">'min'</span>, <span class="string">'mean'</span>]:</span><br><span class="line">            data[<span class="string">f'magic_<span class="subst">&#123;name&#125;</span>_id_<span class="subst">&#123;stat&#125;</span>'</span>] = g[<span class="string">'article_id'</span>].transform(stat)</span><br><span class="line"></span><br><span class="line">    data = data.sort_values(by=[<span class="string">'date'</span>, <span class="string">'magic_rank'</span>]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> [<span class="string">'author'</span>]:</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> [<span class="string">'orders_1h'</span>, <span class="string">'orders_2h'</span>, <span class="string">'magic_rank'</span>]:</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_bef'</span>] = data.groupby([key, <span class="string">'date'</span>])[col].shift(<span class="number">1</span>)</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_aft'</span>] = data.groupby([key, <span class="string">'date'</span>])[col].shift(<span class="number">-1</span>)</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_bef_diff'</span>] = data[col] - data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_bef'</span>]</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_aft_diff'</span>] = data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_aft'</span>] - data[col]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> [<span class="string">'author'</span>, <span class="string">'level1'</span>, <span class="string">'level2'</span>, <span class="string">'level3'</span>, <span class="string">'level4'</span>,</span><br><span class="line">                <span class="string">'brand'</span>, <span class="string">'mall'</span>, <span class="string">'url'</span>, <span class="string">'baike_id_2h'</span>]:</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_rank_mean'</span>] = data.groupby([key, <span class="string">'date'</span>])[<span class="string">'magic_rank'</span>].transform(<span class="string">'mean'</span>)</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_rank_std'</span>] = data.groupby([key, <span class="string">'date'</span>])[<span class="string">'magic_rank'</span>].transform(<span class="string">'std'</span>)</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_rank_min'</span>] = data.groupby([key, <span class="string">'date'</span>])[<span class="string">'magic_rank'</span>].transform(<span class="string">'min'</span>)</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_rank_max'</span>] = data.groupby([key, <span class="string">'date'</span>])[<span class="string">'magic_rank'</span>].transform(<span class="string">'max'</span>)</span><br><span class="line"></span><br><span class="line">    data[<span class="string">'baike_id_group'</span>] = data.groupby([<span class="string">'date'</span>, <span class="string">'baike_id_2h'</span>])[<span class="string">'article_id'</span>].rank(method=<span class="string">'first'</span>)</span><br><span class="line">    data[<span class="string">'baike_id_group'</span>] = data[<span class="string">'magic_rank'</span>] - data[<span class="string">'baike_id_group'</span>]</span><br><span class="line">    data[<span class="string">'baike_id_group'</span>] = data.groupby([<span class="string">'date'</span>, <span class="string">'baike_id_2h'</span>])[<span class="string">'baike_id_group'</span>].rank(ascending=<span class="literal">False</span>, method=<span class="string">'dense'</span>)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feature_extractor</span><span class="params">(train_df, test_df)</span>:</span></span><br><span class="line">    data = pd.concat([train_df, test_df], axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line">    data[<span class="string">'week'</span>] = (data[<span class="string">'date'</span>] - <span class="number">5</span>) // <span class="number">7</span> <span class="comment"># 这里把valid和test放入到各自相同的周内</span></span><br><span class="line">    data[<span class="string">'price_diff_ratio'</span>] = data[<span class="string">'price_diff'</span>] / (data[<span class="string">'price'</span>] + data[<span class="string">'price_diff'</span>])</span><br><span class="line"></span><br><span class="line">    data[<span class="string">'zhi_1h_cnt'</span>] = data[<span class="string">'zhi_1h'</span>] + data[<span class="string">'buzhi_1h'</span>]</span><br><span class="line">    data[<span class="string">'zhi_2h_cnt'</span>] = data[<span class="string">'zhi_2h'</span>] + data[<span class="string">'buzhi_2h'</span>]</span><br><span class="line">    data[<span class="string">'zhi_1h_ratio'</span>] = data[<span class="string">'zhi_1h'</span>] / data[<span class="string">'zhi_1h_cnt'</span>]</span><br><span class="line">    data.loc[data[<span class="string">'zhi_1h_cnt'</span>] == <span class="number">0</span>, <span class="string">'zhi_1h_ratio'</span>] = <span class="number">0</span></span><br><span class="line">    data[<span class="string">'buzhi_1h_ratio'</span>] = data[<span class="string">'buzhi_1h'</span>] / data[<span class="string">'zhi_1h_cnt'</span>]</span><br><span class="line">    data.loc[data[<span class="string">'zhi_1h_cnt'</span>] == <span class="number">0</span>, <span class="string">'buzhi_1h_ratio'</span>] = <span class="number">0</span></span><br><span class="line">    data[<span class="string">'zhi_2h_ratio'</span>] = data[<span class="string">'zhi_2h'</span>] / data[<span class="string">'zhi_2h_cnt'</span>]</span><br><span class="line">    data.loc[data[<span class="string">'zhi_2h_cnt'</span>] == <span class="number">0</span>, <span class="string">'zhi_2h_ratio'</span>] = <span class="number">0</span></span><br><span class="line">    data[<span class="string">'buzhi_2h_ratio'</span>] = data[<span class="string">'buzhi_2h'</span>] / data[<span class="string">'zhi_2h_cnt'</span>]</span><br><span class="line">    data.loc[data[<span class="string">'zhi_2h_cnt'</span>] == <span class="number">0</span>, <span class="string">'buzhi_2h_ratio'</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### 1. magic特征</span></span><br><span class="line">    data = gen_magic_features(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 2. 历史销量滑窗统计特征</span></span><br><span class="line">    strides = [<span class="number">7</span>, <span class="number">150</span>] <span class="comment"># 150是指历史全部</span></span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> strides:</span><br><span class="line">        feats = gen_his_orders_stats(data, d)</span><br><span class="line">        data = data.merge(feats, on=[<span class="string">'article_id'</span>, <span class="string">'date'</span>], how=<span class="string">'left'</span>)</span><br><span class="line">        <span class="keyword">del</span> feats</span><br><span class="line">        gc.collect()</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 3. 当日、全局count统计特征</span></span><br><span class="line">    stats_col = [<span class="string">'author'</span>, <span class="string">'level1'</span>, <span class="string">'level2'</span>, <span class="string">'level3'</span>, <span class="string">'level4'</span>,</span><br><span class="line">                  <span class="string">'brand'</span>, <span class="string">'mall'</span>, <span class="string">'url'</span>, <span class="string">'baike_id_2h'</span>]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> tqdm(stats_col):</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_cnt'</span>] = data.groupby([col, <span class="string">'date'</span>])[<span class="string">'article_id'</span>].transform(<span class="string">'count'</span>)</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_global_cnt'</span>] = data.groupby([col])[<span class="string">'article_id'</span>].transform(<span class="string">'count'</span>)</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_cnt_ratio'</span>] = data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_cnt'</span>] / data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_global_cnt'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 4. 当日、当周、全局orders_1h、orders_2h统计特征</span></span><br><span class="line">    stats_col = [<span class="string">'author'</span>, <span class="string">'level1'</span>, <span class="string">'level2'</span>, <span class="string">'level3'</span>, <span class="string">'level4'</span>,</span><br><span class="line">                 <span class="string">'brand'</span>, <span class="string">'mall'</span>, <span class="string">'url'</span>, <span class="string">'baike_id_2h'</span>]</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> [<span class="string">'orders_1h'</span>, <span class="string">'orders_2h'</span>]:</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> tqdm(stats_col):</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum'</span>] = data.groupby([col, <span class="string">'date'</span>])[label].transform(<span class="string">'sum'</span>)</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum'</span>] = data.groupby([col])[label].transform(<span class="string">'sum'</span>)</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_ratio'</span>] = data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum'</span>] / data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum'</span>]</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_mean'</span>] = data.groupby([col, <span class="string">'date'</span>])[label].transform(<span class="string">'mean'</span>)</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_vs_day_<span class="subst">&#123;label&#125;</span>'</span>] = data[label] / data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_mean'</span>]</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum'</span>] = data.groupby([col, <span class="string">'week'</span>])[label].transform(<span class="string">'sum'</span>)</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_in_week_<span class="subst">&#123;label&#125;</span>_ratio'</span>] = data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum'</span>] / data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum'</span>]</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_ratio'</span>] = data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum'</span>] / data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 5. 当日、当周、全局收藏、点赞、评论统计特征</span></span><br><span class="line">    stats_col = [<span class="string">'author'</span>, <span class="string">'url'</span>, <span class="string">'baike_id_1h'</span>, <span class="string">'baike_id_2h'</span>]</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> [<span class="string">'comments_1h'</span>, <span class="string">'zhi_1h'</span>, <span class="string">'buzhi_1h'</span>, <span class="string">'favorite_1h'</span>,</span><br><span class="line">                  <span class="string">'comments_2h'</span>, <span class="string">'zhi_2h'</span>, <span class="string">'buzhi_2h'</span>, <span class="string">'favorite_2h'</span>]:</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> tqdm(stats_col):</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum'</span>] = data.groupby([col, <span class="string">'date'</span>])[label].transform(<span class="string">'sum'</span>)</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum'</span>] = data.groupby([col, <span class="string">'week'</span>])[label].transform(<span class="string">'sum'</span>)</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum'</span>] = data.groupby([col])[label].transform(<span class="string">'sum'</span>)</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_in_week_<span class="subst">&#123;label&#125;</span>_ratio'</span>] = data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum'</span>] / data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum'</span>]</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_ratio'</span>] = data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_week_<span class="subst">&#123;label&#125;</span>_sum'</span>] / data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum'</span>]</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_ratio'</span>] = data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_day_<span class="subst">&#123;label&#125;</span>_sum'</span>] / data[<span class="string">f'<span class="subst">&#123;col&#125;</span>_global_<span class="subst">&#123;label&#125;</span>_sum'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 6. 商品价格、降价幅度统计特征</span></span><br><span class="line">    stats_col = [<span class="string">'baike_id_2h'</span>, <span class="string">'url'</span>]</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> tqdm(stats_col):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> [<span class="string">'price'</span>, <span class="string">'price_diff'</span>, <span class="string">'price_diff_ratio'</span>]:</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_mean'</span>] = data.groupby([key])[col].transform(<span class="string">'mean'</span>)</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_std'</span>] = data.groupby([key])[col].transform(<span class="string">'std'</span>)</span><br><span class="line">            data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_vs_mean'</span>] = data[col] / data[<span class="string">f'<span class="subst">&#123;key&#125;</span>_<span class="subst">&#123;col&#125;</span>_mean'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 7. 当日、当周、全局nunique统计特征</span></span><br><span class="line">    stats_col = [[<span class="string">'author'</span>, <span class="string">'url'</span>], [<span class="string">'author'</span>, <span class="string">'baike_id_2h'</span>], [<span class="string">'baike_id_2h'</span>, <span class="string">'url'</span>]]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> tqdm(stats_col):</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_day'</span>] = data.groupby([col[<span class="number">0</span>], <span class="string">'date'</span>])[col[<span class="number">1</span>]].transform(<span class="string">'nunique'</span>)</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_week'</span>] = data.groupby([col[<span class="number">0</span>], <span class="string">'week'</span>])[col[<span class="number">1</span>]].transform(<span class="string">'nunique'</span>)</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_global'</span>] = data.groupby([col[<span class="number">0</span>]])[col[<span class="number">1</span>]].transform(<span class="string">'nunique'</span>)</span><br><span class="line"></span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_day'</span>] = data[<span class="string">f'<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_day'</span>] / data[<span class="string">f'<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_global'</span>]</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_week'</span>] = data[<span class="string">f'<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_week'</span>] / data[<span class="string">f'<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_nunique_global'</span>]</span><br><span class="line"></span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_day'</span>] = data.groupby([col[<span class="number">1</span>], <span class="string">'date'</span>])[col[<span class="number">0</span>]].transform(<span class="string">'nunique'</span>)</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_week'</span>] = data.groupby([col[<span class="number">1</span>], <span class="string">'week'</span>])[col[<span class="number">0</span>]].transform(<span class="string">'nunique'</span>)</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_global'</span>] = data.groupby([col[<span class="number">1</span>]])[col[<span class="number">0</span>]].transform(<span class="string">'nunique'</span>)</span><br><span class="line"></span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_day'</span>] = data[<span class="string">f'<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_day'</span>] / data[<span class="string">f'<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_global'</span>]</span><br><span class="line">        data[<span class="string">f'<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_week'</span>] = data[<span class="string">f'<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_week'</span>] / data[<span class="string">f'<span class="subst">&#123;col[<span class="number">1</span>]&#125;</span>_<span class="subst">&#123;col[<span class="number">0</span>]&#125;</span>_nunique_global'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_dataset</span><span class="params">(data, valid_start_date, gap)</span>:</span></span><br><span class="line">    train = data[data[<span class="string">'date'</span>]&lt;valid_start_date].copy()</span><br><span class="line">    valid = data[(data[<span class="string">'date'</span>]&gt;=valid_start_date)&amp;(data[<span class="string">'date'</span>]&lt;valid_start_date+gap)].copy()</span><br><span class="line">    test = data[data[<span class="string">'date'</span>]&gt;=valid_start_date+gap].copy()</span><br><span class="line">    print(<span class="string">f'训练集样本数: <span class="subst">&#123;train.shape[<span class="number">0</span>]&#125;</span>, 验证集样本数: <span class="subst">&#123;valid.shape[<span class="number">0</span>]&#125;</span>, 测试集样本数: <span class="subst">&#123;test.shape[<span class="number">0</span>]&#125;</span>'</span>)</span><br><span class="line">    <span class="keyword">return</span> train, valid, test</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lgb_reg_model</span><span class="params">(train, valid, test, target)</span>:</span></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">'learning_rate'</span>: <span class="number">0.05</span>,</span><br><span class="line">        <span class="string">'boosting_type'</span>: <span class="string">'gbdt'</span>,</span><br><span class="line">        <span class="string">'objective'</span>: <span class="string">'regression'</span>,</span><br><span class="line">        <span class="string">'metric'</span>: <span class="string">'l2'</span>,</span><br><span class="line">        <span class="string">'feature_fraction'</span>: <span class="number">0.8</span>,</span><br><span class="line">        <span class="string">'bagging_fraction'</span>: <span class="number">0.8</span>,</span><br><span class="line">        <span class="string">'min_data_in_leaf'</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="string">'verbose'</span>: <span class="number">-1</span>,</span><br><span class="line">        <span class="string">'nthread'</span>: <span class="number">16</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    feats = [f <span class="keyword">for</span> f <span class="keyword">in</span> train.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'article_id'</span>, <span class="string">'date'</span>, <span class="string">'orders_3h_15h'</span>, <span class="string">'week'</span>]]</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'线下训练集样本数：%d'</span> % (train.shape[<span class="number">0</span>]))</span><br><span class="line">    print(<span class="string">'线下验证集样本数：%d'</span> % (valid.shape[<span class="number">0</span>]))</span><br><span class="line">    print(<span class="string">'特征个数：%d'</span> % (len(feats)))</span><br><span class="line">    print(<span class="string">'开始线下验证......'</span>)</span><br><span class="line"></span><br><span class="line">    dtrain = lgb.Dataset(train[feats],</span><br><span class="line">                         label=train[target])</span><br><span class="line">    dvalid = lgb.Dataset(valid[feats],</span><br><span class="line">                         label=valid[target])</span><br><span class="line">    lgb_model = lgb.train(params,</span><br><span class="line">                          dtrain,</span><br><span class="line">                          num_boost_round=<span class="number">10000</span>,</span><br><span class="line">                          valid_sets=[dvalid],</span><br><span class="line">                          early_stopping_rounds=<span class="number">100</span>,</span><br><span class="line">                          verbose_eval=<span class="number">100</span>)</span><br><span class="line">    valid_preds = lgb_model.predict(valid[feats].values, num_iteration=lgb_model.best_iteration)</span><br><span class="line">    print(<span class="string">'--------------------------特征重要性----------------------------'</span>)</span><br><span class="line">    feature_importance = pd.DataFrame()</span><br><span class="line">    feature_importance[<span class="string">'features'</span>] = feats</span><br><span class="line">    feature_importance[<span class="string">'importance'</span>] = lgb_model.feature_importance(importance_type=<span class="string">'gain'</span>)</span><br><span class="line">    print(feature_importance.sort_values(by=<span class="string">'importance'</span>, ascending=<span class="literal">False</span>).head(<span class="number">15</span>))</span><br><span class="line">    <span class="keyword">del</span> dtrain, dvalid</span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line">    preds = <span class="number">0</span></span><br><span class="line">    print(<span class="string">'开始线上预测...'</span>)</span><br><span class="line">    best_iters = int(lgb_model.best_iteration*<span class="number">1.2</span>)</span><br><span class="line">    all_train = pd.concat([train, valid], axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line">    dtrain = lgb.Dataset(all_train[feats],</span><br><span class="line">                         label=all_train[target])</span><br><span class="line">    <span class="keyword">del</span> all_train</span><br><span class="line">    gc.collect()</span><br><span class="line">    lgb_model = lgb.train(params,</span><br><span class="line">                          dtrain,</span><br><span class="line">                          num_boost_round=best_iters,</span><br><span class="line">                          verbose_eval=<span class="number">100</span>,</span><br><span class="line">                          )</span><br><span class="line">    preds = lgb_model.predict(test[feats])</span><br><span class="line">    <span class="keyword">return</span> valid_preds, preds</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cbt_reg_model</span><span class="params">(train, valid, test, target)</span>:</span></span><br><span class="line">    catboost_params = &#123;</span><br><span class="line">        <span class="string">'iterations'</span>: <span class="number">10000</span>,</span><br><span class="line">        <span class="string">'learning_rate'</span>: <span class="number">0.05</span>,</span><br><span class="line">        <span class="string">'eval_metric'</span>: <span class="string">'RMSE'</span>,</span><br><span class="line">        <span class="string">'task_type'</span>: <span class="string">'GPU'</span>,</span><br><span class="line">        <span class="string">'early_stopping_rounds'</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="string">'use_best_model'</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">'verbose'</span>: <span class="number">100</span>,</span><br><span class="line">        <span class="string">'depth'</span>: <span class="number">10</span>,</span><br><span class="line">        <span class="string">'bootstrap_type'</span>: <span class="string">'Bernoulli'</span>,</span><br><span class="line">        <span class="string">'boosting_type'</span>: <span class="string">'Plain'</span>,</span><br><span class="line">        <span class="string">'subsample'</span>: <span class="number">0.8</span></span><br><span class="line">    &#125;</span><br><span class="line">    feats = [f <span class="keyword">for</span> f <span class="keyword">in</span> train.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'article_id'</span>, <span class="string">'date'</span>, <span class="string">'orders_3h_15h'</span>, <span class="string">'week'</span>]]</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'线下训练集样本数：%d'</span> % (train.shape[<span class="number">0</span>]))</span><br><span class="line">    print(<span class="string">'线下验证集样本数：%d'</span> % (valid.shape[<span class="number">0</span>]))</span><br><span class="line">    print(<span class="string">'特征个数：%d'</span> % (len(feats)))</span><br><span class="line">    print(<span class="string">'开始线下验证......'</span>)</span><br><span class="line">    dtrain = Pool(train[feats].values,</span><br><span class="line">                  label=train[target])</span><br><span class="line">    dvalid = Pool(valid[feats].values,</span><br><span class="line">                  label=valid[target])</span><br><span class="line">    cbt_model = CatBoostRegressor(**catboost_params)</span><br><span class="line">    cbt_model.fit(dtrain, eval_set=dvalid)</span><br><span class="line">    <span class="comment">#     print(cbt_model.best_score_['validation'])</span></span><br><span class="line">    score = cbt_model.best_score_[<span class="string">'validation'</span>][<span class="string">'RMSE'</span>]</span><br><span class="line">    valid_preds = cbt_model.predict(valid[feats].values)</span><br><span class="line">    <span class="keyword">del</span> dtrain, dvalid</span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'开始线上预测......'</span>)</span><br><span class="line">    best_iters = int(cbt_model.best_iteration_ * <span class="number">1.2</span>)</span><br><span class="line">    catboost_params = &#123;</span><br><span class="line">        <span class="string">'iterations'</span>: best_iters,</span><br><span class="line">        <span class="string">'learning_rate'</span>: <span class="number">0.05</span>,</span><br><span class="line">        <span class="string">'eval_metric'</span>: <span class="string">'RMSE'</span>,</span><br><span class="line">        <span class="string">'task_type'</span>: <span class="string">'GPU'</span>,</span><br><span class="line">        <span class="string">'early_stopping_rounds'</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="comment">#         'use_best_model': True,</span></span><br><span class="line">        <span class="string">'verbose'</span>: <span class="number">100</span>,</span><br><span class="line">        <span class="string">'depth'</span>: <span class="number">10</span>,</span><br><span class="line">        <span class="string">'bootstrap_type'</span>: <span class="string">'Bernoulli'</span>,</span><br><span class="line">        <span class="string">'boosting_type'</span>: <span class="string">'Plain'</span>,</span><br><span class="line">        <span class="string">'subsample'</span>: <span class="number">0.8</span></span><br><span class="line">    &#125;</span><br><span class="line">    all_train = pd.concat([train, valid], axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    dtrain = Pool(all_train[feats],</span><br><span class="line">                  label=all_train[target])</span><br><span class="line">    <span class="keyword">del</span> all_train</span><br><span class="line">    gc.collect()</span><br><span class="line">    cbt_model = CatBoostRegressor(**catboost_params)</span><br><span class="line">    cbt_model.fit(dtrain)</span><br><span class="line">    <span class="keyword">del</span> dtrain</span><br><span class="line">    gc.collect()</span><br><span class="line">    preds = cbt_model.predict(test[feats].values)</span><br><span class="line">    <span class="keyword">return</span> valid_preds, preds</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xgb_reg_model</span><span class="params">(train, valid, test, target)</span>:</span></span><br><span class="line">    feats = [f <span class="keyword">for</span> f <span class="keyword">in</span> train.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'article_id'</span>, <span class="string">'date'</span>, <span class="string">'orders_3h_15h'</span>,</span><br><span class="line">                                                   <span class="string">'week'</span>, <span class="string">'baike_id_2h_price_diff_vs_mean'</span>, <span class="string">'baike_id_2h_price_diff_ratio_vs_mean'</span>,</span><br><span class="line">                                                   <span class="string">'url_price_diff_vs_mean'</span>, <span class="string">'url_price_diff_ratio_vs_mean'</span>]]</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'线下训练集样本数：%d'</span> % (train.shape[<span class="number">0</span>]))</span><br><span class="line">    print(<span class="string">'线下验证集样本数：%d'</span> % (valid.shape[<span class="number">0</span>]))</span><br><span class="line">    print(<span class="string">'特征个数：%d'</span> % (len(feats)))</span><br><span class="line">    print(<span class="string">'开始线下验证......'</span>)</span><br><span class="line">    clf = xgb.XGBRegressor(</span><br><span class="line">        n_estimators=<span class="number">10000</span>,</span><br><span class="line">        max_depth=<span class="number">12</span>,</span><br><span class="line">        learning_rate=<span class="number">0.02</span>,</span><br><span class="line">        subsample=<span class="number">0.8</span>,</span><br><span class="line">        colsample_bytree=<span class="number">0.4</span>,</span><br><span class="line">        missing=<span class="number">-1</span>,</span><br><span class="line">        eval_metric=<span class="string">'rmse'</span>,</span><br><span class="line">        <span class="comment"># USE CPU</span></span><br><span class="line">        <span class="comment"># nthread=4,</span></span><br><span class="line">        <span class="comment"># tree_method='hist'</span></span><br><span class="line">        <span class="comment"># USE GPU</span></span><br><span class="line">        tree_method=<span class="string">'gpu_hist'</span></span><br><span class="line">    )</span><br><span class="line">    xgb_model = clf.fit(train[feats], train[target],</span><br><span class="line">                        eval_set=[(valid[feats], valid[target])],</span><br><span class="line">                        verbose=<span class="number">100</span>,</span><br><span class="line">                        early_stopping_rounds=<span class="number">200</span>)</span><br><span class="line">    valid_preds = xgb_model.predict(valid[feats].values)</span><br><span class="line">    <span class="comment">#     del dtrain, dvalid</span></span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'开始线上预测......'</span>)</span><br><span class="line">    best_iters = int(xgb_model.best_iteration * <span class="number">1.2</span>)</span><br><span class="line">    clf = xgb.XGBRegressor(</span><br><span class="line">        n_estimators=best_iters,</span><br><span class="line">        max_depth=<span class="number">12</span>,</span><br><span class="line">        learning_rate=<span class="number">0.02</span>,</span><br><span class="line">        subsample=<span class="number">0.8</span>,</span><br><span class="line">        colsample_bytree=<span class="number">0.4</span>,</span><br><span class="line">        missing=<span class="number">-1</span>,</span><br><span class="line">        eval_metric=<span class="string">'rmse'</span>,</span><br><span class="line">        <span class="comment"># USE CPU</span></span><br><span class="line">        <span class="comment"># nthread=4,</span></span><br><span class="line">        <span class="comment"># tree_method='hist'</span></span><br><span class="line">        <span class="comment"># USE GPU</span></span><br><span class="line">        tree_method=<span class="string">'gpu_hist'</span></span><br><span class="line">    )</span><br><span class="line">    all_train = pd.concat([train, valid], axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    xgb_model = clf.fit(all_train[feats],</span><br><span class="line">                        all_train[target],</span><br><span class="line">                        verbose=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">del</span> all_train</span><br><span class="line">    gc.collect()</span><br><span class="line">    preds = xgb_model.predict(test[feats].values)</span><br><span class="line">    <span class="keyword">return</span> valid_preds, preds</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_submission</span><span class="params">(df, preds, sub_path)</span>:</span></span><br><span class="line">    sub = df[[<span class="string">'article_id'</span>]].copy()</span><br><span class="line">    sub[<span class="string">'orders_3h_15h'</span>] = preds</span><br><span class="line">    sub[<span class="string">'orders_3h_15h'</span>] = sub[<span class="string">'orders_3h_15h'</span>].apply(<span class="keyword">lambda</span> x: <span class="number">0</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> x)</span><br><span class="line">    sub.to_csv(sub_path+<span class="string">'sub.csv'</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(data_path, sub_path)</span>:</span></span><br><span class="line">    train_df, test_df = load_dataset(data_path) <span class="comment"># 读取数据</span></span><br><span class="line">    data = feature_extractor(train_df, test_df) <span class="comment"># 生成特征</span></span><br><span class="line">    train, valid, test = split_dataset(data=data, valid_start_date=<span class="number">110</span>, gap=<span class="number">7</span>) <span class="comment"># 划分训练\验证集</span></span><br><span class="line">    <span class="keyword">del</span> train_df, test_df</span><br><span class="line">    gc.collect()</span><br><span class="line">    lgb_oof, lgb_preds = lgb_reg_model(train, valid, test, <span class="string">'orders_3h_15h'</span>) <span class="comment"># lightgbm</span></span><br><span class="line">    cbt_oof, cbt_preds = cbt_reg_model(train, valid, test, <span class="string">'orders_3h_15h'</span>)  <span class="comment"># catboost</span></span><br><span class="line">    xgb_oof, xgb_preds = xgb_reg_model(train, valid, test, <span class="string">'orders_3h_15h'</span>)  <span class="comment"># xgboost</span></span><br><span class="line">    preds = <span class="number">0.3</span>*lgb_preds + <span class="number">0.5</span>*cbt_preds + <span class="number">0.2</span>*xgb_preds <span class="comment"># 加权融合</span></span><br><span class="line">    gen_submission(test, preds, sub_path) <span class="comment"># 生成提交文件</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    data_path = <span class="string">'../data/'</span></span><br><span class="line">    sub_path = <span class="string">'../submission/'</span></span><br><span class="line">    main(data_path, sub_path)</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li>[1] <a href="https://github.com/cXPromise/2021ECAA_Top2_Solution" target="_blank" rel="noopener">https://github.com/cXPromise/2021ECAA_Top2_Solution</a></li>
<li>[2] <a href="https://www.automl.ai/competitions/19#home" target="_blank" rel="noopener">https://www.automl.ai/competitions/19#home</a></li>
<li>[3] <a href="https://drive.google.com/drive/folders/1WLK3Dq6HMTB7Y34dt5b_jqc0Rg0jevNr?usp=sharing" target="_blank" rel="noopener">https://drive.google.com/drive/folders/1WLK3Dq6HMTB7Y34dt5b_jqc0Rg0jevNr?usp=sharing</a></li>
</ul>
</div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/">数据竞赛</a></div><div class="post_share"><div class="social-share" data-image="https://www.cdnjson.com/images/2021/11/03/11111.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/10/21/%E7%BB%8F%E5%85%B8%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C-FCN/"><img class="prev-cover" data-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">经典语义分割网络:FCN</div></div></a></div><div class="next-post pull-right"><a href="/2021/10/06/%E7%AE%97%E6%B3%95%E4%B8%8B/"><img class="next-cover" data-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">算法下</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2021/08/21/FlyAI蘑菇分类竞赛TOP5方案分享/" title="FlyAI蘑菇分类竞赛TOP5方案分享"><img class="relatedPosts_cover" data-src="https://www.cdnjson.com/images/2021/08/27/thomas-bormans-ZtM-W-3f0C4-unsplash.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-21</div><div class="relatedPosts_title">FlyAI蘑菇分类竞赛TOP5方案分享</div></div></a></div><div class="relatedPosts_item"><a href="/2021/09/30/电子商务AI算法大赛baseline/" title="电子商务AI算法大赛baseline"><img class="relatedPosts_cover" data-src="https://www.cdnjson.com/images/2021/10/06/0.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-09-30</div><div class="relatedPosts_title">电子商务AI算法大赛baseline</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 雨落诗山山亦奇</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
document.body.addEventListener('input', POWERMODE);
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/third-party/ClickShowText.js"></script><script src="https://cdn.jsdelivr.net/gh/lete114/CDN/Sum/sakura.js"></script><script src="/js/egao.js"></script><script src="/js/snow.js"></script></body></html>