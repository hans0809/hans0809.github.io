<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">






  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.4.2" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.4.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.4.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.4.2">


  <link rel="mask-icon" href="/images/logo.svg?v=6.4.2" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.4.2',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="在之前的这篇文章中，我们介绍了PyTorch中的交叉熵损失函数的具体使用方法（传送门），并举了大量的栗子进行解释。 在此基础上，就可以尝试对交叉熵进行魔改啦~ CrossEntropyLoss到底做了什么？ 吃瓜群众：那说一下魔改的具体内容呗…  别着急，在开始魔改之前，需要花些篇幅介绍下在PyTorch中的CrossEntropyLoss内部所做的事情。这是官方给出的关于CrossEntropy">
<meta property="og:type" content="article">
<meta property="og:title" content="魔改交叉熵">
<meta property="og:url" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/index.html">
<meta property="og:site_name" content="南极Python">
<meta property="og:description" content="在之前的这篇文章中，我们介绍了PyTorch中的交叉熵损失函数的具体使用方法（传送门），并举了大量的栗子进行解释。 在此基础上，就可以尝试对交叉熵进行魔改啦~ CrossEntropyLoss到底做了什么？ 吃瓜群众：那说一下魔改的具体内容呗…  别着急，在开始魔改之前，需要花些篇幅介绍下在PyTorch中的CrossEntropyLoss内部所做的事情。这是官方给出的关于CrossEntropy">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/1.png">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/2.png">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/3.png">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/4.png">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/5.png">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/6.png">
<meta property="article:published_time" content="2021-05-01T07:43:15.000Z">
<meta property="article:modified_time" content="2021-05-02T12:11:22.598Z">
<meta property="article:author" content="雨落诗山山亦奇">
<meta property="article:tag" content="DL">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/1.png">






  <link rel="canonical" href="http://yoursite.com/2021/05/01/魔改交叉熵/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>魔改交叉熵 | 南极Python</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">南极Python</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Python|机器学习|深度学习</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-主页">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />主页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-关于">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-标签">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-分类">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />分类</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-时间轴">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />时间轴</a>
  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雨落诗山山亦奇">
      <meta itemprop="description" content="昨夜星辰昨夜风">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="南极Python">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">魔改交叉熵
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2021-05-01 15:43:15" itemprop="dateCreated datePublished" datetime="2021-05-01T15:43:15+08:00">2021-05-01</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2021-05-02 20:11:22" itemprop="dateModified" datetime="2021-05-02T20:11:22+08:00">2021-05-02</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">深度学习笔记</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon"
            >
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">22k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">20 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>在之前的这篇文章中，我们介绍了PyTorch中的交叉熵损失函数的具体使用方法（传送门），并举了大量的栗子进行解释。</p>
<p>在此基础上，就可以尝试对交叉熵进行魔改啦~</p>
<h2 id="CrossEntropyLoss到底做了什么？"><a href="#CrossEntropyLoss到底做了什么？" class="headerlink" title="CrossEntropyLoss到底做了什么？"></a>CrossEntropyLoss到底做了什么？</h2><blockquote>
<p>吃瓜群众：那说一下魔改的具体内容呗…</p>
</blockquote>
<p>别着急，在开始魔改之前，需要花些篇幅介绍下在PyTorch中的<code>CrossEntropyLoss</code>内部所做的事情。<br><img src="./1.png" alt="Alt text"><br>这是官方给出的关于<code>CrossEntropyLoss</code>的维度说明。简而言之，分为两种情况：</p>
<ul>
<li>网络的输出shape为<code>[N,C]</code>，对应的真实类别标签维度就得是<code>[N]</code>；</li>
<li>网络的输出shape为<code>[N,C,d1,d2,...]</code>，对应的真实类别标签维度就得是<code>[N,d1,d2,...]</code>；</li>
</ul>
<p>对于第一种情况，我们在这篇文章（传送门）的最后已经讲过，本文将以第二种形式的数据进行举例说明。</p>
<p>来看一下贯穿本文的一个栗子：</p>
<blockquote>
<p>假设网络的输出<code>output</code>的shape为<code>[1,3,256,256]</code>，其中1代表batchsize，3代表这是个三分类问题，后面的两个256可以看作是一张256*256的图片的高(height)和宽(width)，也就是说，总共有<code>256*256</code>个像素点。用代码随机生成<code>output</code>，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#网络的输出</span></span><br><span class="line">output = torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">256</span>,<span class="number">256</span>)</span><br></pre></td></tr></table></figure>

<p>该输出对应的已知<code>target</code>的shape为<code>[1,256,256]</code>，其中4代表batchsize，后面的两个256也可以看作是一张256*256的图片的高(height)和宽(width)，和网络的输出不同的是，这里每一个像素点的取值集合是${0,1,2}$，因为它们代表的是该像素点所属类别。用代码随机生成<code>target</code>，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#traget的取值集合为&#123;0,1,2&#125;</span></span><br><span class="line">target=torch.empty(<span class="number">1</span>, <span class="number">256</span>,<span class="number">256</span>).random_(<span class="number">0</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

</blockquote>
<p>如果使用PyTorch封装好的<code>CrossEntropyLoss</code>，可以直接得到它们之间的交叉熵：<br><img src="./2.png" alt="Alt text"></p>
<p>现在问题来了：<code>CrossEntropyLoss</code>内部究竟做了些什么呢？</p>
<p>如果不能回答这个问题，我们就无法尝试自己用代码写出一个交叉熵函数，而这正是对交叉熵进行魔改的前提！</p>
<p>现在给出答案：</p>
<p><strong>1）对网络的输出<code>output</code>在类别维度上做softmax操作，然后对结果再取log ，得到<code>logsoftmax</code>；</strong><br><strong>2）现在得到了<code>logsoftmax</code>，又已知每个样本的类别标签<code>target</code>，于是将<code>target</code>作为下标索引<code>index</code>，在<code>logsoftmax</code>的类比维度(也就是上一步做softmax的维度)上进行索引，得到每个样本对应的索引值<code>value</code>；</strong><br><strong>3）将每个样本的<code>value</code>加起来求个平均值，再取个负号，就计算出了交叉熵。</strong></p>
<p>为了进行说明，先把之前写过的交叉熵的计算公式搬过来：<br>$$L=-{\frac1N} {\sum_{i=1}^{N}}  {\sum_{c=1}^{K}} y_{ic}log(p_{ic})$$</p>
<p>第(1)步比较容易理解，在类比维度上做softmax是为了将网络预测的类别向量转为概率分布，之后再取log，将预测值的取值范围由$[0,1]$映射到$[-\inf,0]$ ，这对应着交叉熵计算公式中的$log(p_{ic})$;</p>
<p>第(2)步看起来有点奇怪，其实是在简化运算。我们知道，在交叉熵的计算公式中，$y_{ic}$其实是<code>onehot</code>形式的，如果直接求解$y_{ic}log(p_{ic})$，会有大量的$0$出现，这些计算其实是没必要的，我们只需要获取$y_{ic}$中取值为1的元素对应位置的$log(p_{ic})$即可。也就是说，我们可以将对于${\sum_{c=1}^{K}} y_{ic}log(p_{ic})$的计算简化为对于$y_{ic’}log(p_{ic’})$的计算，其中$c’$是第i个样本的真实类标签。</p>
<p>第(3)步也很容易理解，正对应公式中的$-\frac1N\sum_{i=1}^{N}$ 。</p>
<p>了解了这些，就可以根据这三步实现自己的交叉熵了~</p>
<blockquote>
<p>吃瓜群众：期待…</p>
</blockquote>
<h2 id="交叉熵1-0版本"><a href="#交叉熵1-0版本" class="headerlink" title="交叉熵1.0版本"></a>交叉熵1.0版本</h2><p>根据之前的这三个步骤，交叉熵实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_celoss</span><span class="params">(output,target)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># output:[1,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[1,256,256] ，取值集合为&#123;0,1,2&#125;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#（1）做softmax得到概率分布，然后对每个元素取对数</span></span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)<span class="comment">#在类别维度进行softmax</span></span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># （2）在（1）的基础上，对每个像素求解-log_softmax[target],</span></span><br><span class="line">    <span class="comment">#其中log_softmax即为1中所求，它可按通道被分为[c1,c2,c3]，如下：</span></span><br><span class="line">    <span class="comment">#c1 = log_softmax[:,0,:,:]</span></span><br><span class="line">    <span class="comment">#c2 = log_softmax[:, 1,:, :]</span></span><br><span class="line">    <span class="comment">#c3 = log_softmax[:, 2,:, :]</span></span><br><span class="line"></span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line">    s=<span class="number">0</span><span class="comment">#存储loss累加值</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(w):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(h):</span><br><span class="line">                <span class="comment">#获取当前样本点的真实类别标签</span></span><br><span class="line">                ind=int(target[b,i,j].item())</span><br><span class="line">                <span class="comment"># 根据真实类别标签获取log_softmax中对应的value，并累加到总的loss中</span></span><br><span class="line">                s+=log_softmax[b,ind,i,j]</span><br><span class="line">    s=s*(<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> s/(h*w*bsize)</span><br></pre></td></tr></table></figure>
<p>我们可以测试一下：<br><img src="./3.png" alt="Alt text"></p>
<p>计算结果和我们之前调用<code>CrossEntropyLoss</code>计算的结果一模一样。</p>
<blockquote>
<p>吃瓜群众：既然已经实现了，那就准备做魔改吧，快说一下魔改的具体内容…</p>
</blockquote>
<p>等等，还有一个问题，这种实现方式计算loss的速度有点慢啊！别看只有1.36秒，假设共10000个样本，batchsize为1，不考虑其他因素，每迭代一个epoch，光计算loss就需要约13600秒，即3.78个小时。</p>
<p>所以，目前知识理论上实现了交叉熵，但实际上是无法投入使用的。</p>
<blockquote>
<p>吃瓜群众：那怎么办？</p>
</blockquote>
<h2 id="交叉熵2-0版本"><a href="#交叉熵2-0版本" class="headerlink" title="交叉熵2.0版本"></a>交叉熵2.0版本</h2><p>既然速度慢，那就找点加速的方法~</p>
<p>经过与搜索引擎的一番友好互动，我发现了<code>numba</code>，据说可以加速。</p>
<p>那就安装下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numba</span><br></pre></td></tr></table></figure>
<p>具体使用时，只需从numba中导入jit，并在要加速的函数（方法）前面加一行<code>@jit</code>即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> jit</span><br><span class="line"><span class="meta">@jit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>需要注意的是，目前的numba只支持对于原生的Python语法以及部分numpy的加速，所以，并不能直接在之前实现的<code>my_celoss</code>函数之前加一句<code>@jit</code>。</p>
<p>不过也能解决，只需将需要被加速的部分单独拿出来写成一个函数就可以了。在<code>my_celoss</code>中，大部分时间都花在那3个for循环中，所以可以将它们单独写成一个函数。最终实现的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_celoss_numba_accelerate</span><span class="params">(output,target)</span>:</span></span><br><span class="line">    <span class="comment"># input:[4,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[4,256,256] in &#123;0,1,2&#125;</span></span><br><span class="line">    </span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line"></span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#因为numba不支持tensor，因此需要先转成numpy的nparray</span></span><br><span class="line">    target=target.cpu().numpy()</span><br><span class="line">    log_softmax=log_softmax.cpu().numpy()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @jit</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">implement_for_loop</span><span class="params">(log_softmax)</span>:</span></span><br><span class="line">        s = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(w):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(h):</span><br><span class="line">                    ind=int(target[b,i,j].item())</span><br><span class="line">                    s=s+log_softmax[b,ind,i,j]</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    s=implement_for_loop(log_softmax)</span><br><span class="line">    s=s*(<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.tensor(s/(h*w*bsize))</span><br></pre></td></tr></table></figure>
<p>测试一下：<br><img src="./4.png" alt="Alt text"></p>
<p>果然快了很多！</p>
<blockquote>
<p>吃瓜群众：厉害啦！终于可以开始魔改啦！</p>
</blockquote>
<p>好像，，，等等！</p>
<blockquote>
<p>吃瓜群众：啥？还要等？</p>
</blockquote>
<p>这种写法虽然能够加速，但是，我们已知忽略了一点，那就是，参与运算的不是PyTorch的tensor，这些是不能够被自动求导机制进行求导的，从而无法进行反向传播更新参数。而且，说实话，这加速后的速度还是有点不能接受。</p>
<blockquote>
<p>吃瓜群众：额。。。</p>
</blockquote>
<h2 id="交叉熵3-0版本"><a href="#交叉熵3-0版本" class="headerlink" title="交叉熵3.0版本"></a>交叉熵3.0版本</h2><p>事到如今，必须从根本上对<code>my_celoss</code>进行更改了。</p>
<p>之所以速度慢，是因为嵌套的for循环。那么，我们可不可以摒弃for循环的写法，换成另一种方式呢？</p>
<p>对的，我们可以充分利用PyTorch内置函数，这些函数和numpy中的函数都是经过底层优化的，因此运行速度很快，而且可以天然的使用PyTorch自动求导机制进行求导并实现反向传播更新参数。</p>
<p>代码实现如下，每一步的作用都写在代码注释中了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_celoss_final</span><span class="params">(output,target)</span>:</span></span><br><span class="line">    <span class="comment"># input:[1,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[1,256,256] in &#123;0,1,2&#125;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#这一步不用改，因为本来就是用的PyTorch的内置方法</span></span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line">    loss=<span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#由于batchsize一般都不会很大，因此该for循环花费时间很少</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#下面是本次更改的部分</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取每个像素点的真实类别标签</span></span><br><span class="line">        ind = target[b, :, :].type(torch.int64).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#print('ind:',ind.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取预测得到的每个像素点的类别取值分布（3代表类别）</span></span><br><span class="line">        pred_3channels=log_softmax[b,:,:,:]</span><br><span class="line">        <span class="comment">#print('pred_3channels:',pred_3channels.shape)#torch.Size([3, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#使用gather，在第0个维度（类别所在维度）上用ind进行索引得到每个像素点的value</span></span><br><span class="line">        pred=-pred_3channels.gather(<span class="number">0</span>,ind)</span><br><span class="line">        <span class="comment">#print('pred:',pred.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#求这些像素点value的平均值，并累加到总的loss中</span></span><br><span class="line">        current_loss=torch.mean(pred)</span><br><span class="line">        loss+=current_loss</span><br><span class="line">    <span class="keyword">return</span> loss/bsize</span><br></pre></td></tr></table></figure>
<p>现在来测试一下：<br><img src="./5.png" alt="Alt text"></p>
<p>嗯，结果一样，而且速度提升明显。</p>
<blockquote>
<p>吃瓜群众：哇！现在应该可以了吧，不会还要等吧？不会吧不会吧</p>
</blockquote>
<p>不用再等了，现在可以来魔改交叉熵了~</p>
<h2 id="加权的交叉熵"><a href="#加权的交叉熵" class="headerlink" title="加权的交叉熵"></a>加权的交叉熵</h2><p>还是基于我们一直在用的栗子进行操作。</p>
<p>在原始的交叉熵中，每个像素点在总loss中的贡献都是一样的，而现在，我们希望打破这一状态，具体来说，<strong>希望给每个像素点设置一个权重，权重越大，那么该像素点对于总loss的贡献也就越大，反之则越小</strong>。</p>
<p>有了上面那么长的篇幅做铺垫，实现这一魔改操作就很容易了。</p>
<p>我们只需准备一个和<code>target</code>shape一致的<code>tensor</code>，比如这里就是<code>[1,256,256]</code>的<code>tensor</code>，然后将<code>tensor</code>中的<code>256*256</code>个像素点的取值作为<code>target</code>中每个像素点的权重。</p>
<p>最后，将这个<code>tesnor</code>与所有像素点经索引得到的<code>pred</code>做个逐点乘积即可。</p>
<p>现在，上代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weighted_celoss</span><span class="params">(output,target,mask_fill)</span>:</span></span><br><span class="line">    <span class="comment"># input:[1,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[1,256,256] in &#123;0,1,2&#125;</span></span><br><span class="line">    <span class="comment">#mask_fill:[1,256,256]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#这一步不用改，因为本来就是用的PyTorch的内置方法</span></span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line">    loss=<span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#由于batchsize一般都不会很大，因此该for循环花费时间很少</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#下面是本次更改的部分</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取每个像素点的真实类别标签</span></span><br><span class="line">        ind = target[b, :, :].type(torch.int64).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#print('ind:',ind.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取预测得到的每个像素点的类别取值分布（3代表类别）</span></span><br><span class="line">        pred_3channels=log_softmax[b,:,:,:]</span><br><span class="line">        <span class="comment">#print('pred_3channels:',pred_3channels.shape)#torch.Size([3, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#使用gather，在第0个维度（类别所在维度）上用ind进行索引得到每个像素点的value</span></span><br><span class="line">        pred=-pred_3channels.gather(<span class="number">0</span>,ind)</span><br><span class="line">        <span class="comment">#print('pred:',pred.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#添加了这句代码，通过两者的点乘实现了对每个像素点的加权</span></span><br><span class="line">        pred=pred*mask_fill</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#求这些像素点value的平均值，并累加到总的loss中</span></span><br><span class="line">        current_loss=torch.mean(pred)</span><br><span class="line">        loss+=current_loss</span><br><span class="line">    <span class="keyword">return</span> loss/bsize</span><br></pre></td></tr></table></figure>

<p>在之前实现的原始交叉熵代码的基础上，我们只改动了两个地方：</p>
<p>其一，函数多了一个<code>mask_fill</code>参数，它就是我们上面说的用于保存每个像素点权重的<code>tensor</code>；</p>
<p>其二，加了这句代码: <code>pred=pred*mask_fill</code>，它通过点乘实现了对每个像素点的加权。</p>
<p>现在来测试一下：<br><img src="./6.png" alt="Alt text"></p>
<p>这里，我们将<code>mask_fill</code>的每一个像素值都设置为0.1，是为了方便验证，具体地，之前看到不加权的loss输出结果为1.1255，而这里加权后的输出为0.1126，舍去计算带来的误差，两者正好是0.1倍的关系，从而证明了以上代码的有效性。</p>
<p>至于在具体使用时，需要根据不同的情况，对<code>mask_fill</code>中的每个像素点设置对应的值作为权重。</p>
<p>下一次，我会结合自己的魔改经历，介绍这种加权交叉熵在实际问题中的应用，其中的核心就是<code>mask_fill</code>的制作过程。</p>

      
    </div>

    

    
    
    

    
      <div>
        <div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/uploads/wechat-qcode.jpg" alt="雨落诗山山亦奇 wechat" style="width: 200px; max-width: 100%;"/>
    <div>喜欢所以热爱，坚持干货分享，欢迎订阅我的微信公众号</div>
</div>

      </div>
    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>呐，请我吃辣条</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="雨落诗山山亦奇 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="雨落诗山山亦奇 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/DL/" rel="tag"># DL</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/04/28/%E9%82%A3%E4%BA%9B%E5%B9%B4%EF%BC%8C%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E5%AE%9E%E7%8E%B0%E7%9A%84%E4%BA%A4%E5%8F%89%E7%86%B5/" rel="next" title="那些年，我们一起实现的交叉熵">
                <i class="fa fa-chevron-left"></i> 那些年，我们一起实现的交叉熵
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/05/03/%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8BviaYOLOV3/" rel="prev" title="手把手教你打造一个汽车检测器！">
                手把手教你打造一个汽车检测器！ <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">雨落诗山山亦奇</p>
              <p class="site-description motion-element" itemprop="description">昨夜星辰昨夜风</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives">
                
                    <span class="site-state-item-count">114</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">12</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#CrossEntropyLoss到底做了什么？"><span class="nav-number">1.</span> <span class="nav-text">CrossEntropyLoss到底做了什么？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#交叉熵1-0版本"><span class="nav-number">2.</span> <span class="nav-text">交叉熵1.0版本</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#交叉熵2-0版本"><span class="nav-number">3.</span> <span class="nav-text">交叉熵2.0版本</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#交叉熵3-0版本"><span class="nav-number">4.</span> <span class="nav-text">交叉熵3.0版本</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#加权的交叉熵"><span class="nav-number">5.</span> <span class="nav-text">加权的交叉熵</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">雨落诗山山亦奇</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">565k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">8:33</span>
  
</div>










  <div class="footer-custom">微信公众号：我将在南极找寻你</div>





        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv" title="总访客量">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="site-pv" title="总访问量">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  













  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.4.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.4.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.4.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.4.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.4.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.2"></script>



  



  










  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  



<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script
</body>
</html>



