<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>魔改交叉熵 | 南极Python</title><meta name="description" content="在之前的这篇文章中，我们介绍了PyTorch中的交叉熵损失函数的具体使用方法（传送门），并举了大量的栗子进行解释。 在此基础上，就可以尝试对交叉熵进行魔改啦~ CrossEntropyLoss到底做了什么？ 吃瓜群众：那说一下魔改的具体内容呗…  别着急，在开始魔改之前，需要花些篇幅介绍下在PyTorch中的CrossEntropyLoss内部所做的事情。这是官方给出的关于CrossEntropy"><meta name="keywords" content="DL"><meta name="author" content="雨落诗山山亦奇"><meta name="copyright" content="雨落诗山山亦奇"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/avatar.png"><link rel="canonical" href="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="魔改交叉熵"><meta property="og:url" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/"><meta property="og:site_name" content="南极Python"><meta property="og:description" content="在之前的这篇文章中，我们介绍了PyTorch中的交叉熵损失函数的具体使用方法（传送门），并举了大量的栗子进行解释。 在此基础上，就可以尝试对交叉熵进行魔改啦~ CrossEntropyLoss到底做了什么？ 吃瓜群众：那说一下魔改的具体内容呗…  别着急，在开始魔改之前，需要花些篇幅介绍下在PyTorch中的CrossEntropyLoss内部所做的事情。这是官方给出的关于CrossEntropy"><meta property="og:image" content="https://www.cdnjson.com/images/2021/05/02/rishi-WiCvC9u7OpE-unsplash.jpg"><meta property="article:published_time" content="2021-05-01T07:43:15.000Z"><meta property="article:modified_time" content="2021-05-02T12:11:22.598Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="prev" title="手把手教你打造一个汽车检测器！" href="http://yoursite.com/2021/05/03/%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8BviaYOLOV3/"><link rel="next" title="那些年，我们一起实现的交叉熵" href="http://yoursite.com/2021/04/28/%E9%82%A3%E4%BA%9B%E5%B9%B4%EF%BC%8C%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E5%AE%9E%E7%8E%B0%E7%9A%84%E4%BA%A4%E5%8F%89%E7%86%B5/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"我爱学习,机器学习,深度学习,学习使我快乐","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-05-02 20:11:22'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><link rel="stylesheet" href="/css/mouse.css">
<link rel="stylesheet" href="/css/gundongtiao.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/macblack.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"> <link rel="stylesheet" href="/css/waigua.css"> <link rel="stylesheet" href="/css/beijing.css"><div class="aplayer" data-id="476185587" data-server="netease" data-type="playlist" data-fixed="true" data-listFolded="false" data-order="list" data-preload="auto"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/lete114/CDN/music/APlayer/APlayer.min.css"><script src="https://cdn.jsdelivr.net/gh/lete114/CDN/music/APlayer/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@1.2.0/dist/Meting.min.js"></script><meta name="generator" content="Hexo 4.2.1"></head><body><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">134</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">13</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">9</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#CrossEntropyLoss到底做了什么？"><span class="toc-number">1.</span> <span class="toc-text">CrossEntropyLoss到底做了什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#交叉熵1-0版本"><span class="toc-number">2.</span> <span class="toc-text">交叉熵1.0版本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#交叉熵2-0版本"><span class="toc-number">3.</span> <span class="toc-text">交叉熵2.0版本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#交叉熵3-0版本"><span class="toc-number">4.</span> <span class="toc-text">交叉熵3.0版本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#加权的交叉熵"><span class="toc-number">5.</span> <span class="toc-text">加权的交叉熵</span></a></li></ol></div></div></div><div id="body-wrap"><div id="web_bg" data-type="color"></div><header class="post-bg" id="page-header" style="background-image: url(https://www.cdnjson.com/images/2021/05/02/rishi-WiCvC9u7OpE-unsplash.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">南极Python</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">魔改交叉熵</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2021-05-01 15:43:15"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2021-05-01</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2021-05-02 20:11:22"><i class="fas fa-history fa-fw"></i> 更新于 2021-05-02</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>在之前的这篇文章中，我们介绍了PyTorch中的交叉熵损失函数的具体使用方法（传送门），并举了大量的栗子进行解释。</p>
<p>在此基础上，就可以尝试对交叉熵进行魔改啦~</p>
<h2 id="CrossEntropyLoss到底做了什么？"><a href="#CrossEntropyLoss到底做了什么？" class="headerlink" title="CrossEntropyLoss到底做了什么？"></a>CrossEntropyLoss到底做了什么？</h2><blockquote>
<p>吃瓜群众：那说一下魔改的具体内容呗…</p>
</blockquote>
<p>别着急，在开始魔改之前，需要花些篇幅介绍下在PyTorch中的<code>CrossEntropyLoss</code>内部所做的事情。<br><img src= "/img/loading.gif" data-src="./1.png" alt="Alt text"><br>这是官方给出的关于<code>CrossEntropyLoss</code>的维度说明。简而言之，分为两种情况：</p>
<ul>
<li>网络的输出shape为<code>[N,C]</code>，对应的真实类别标签维度就得是<code>[N]</code>；</li>
<li>网络的输出shape为<code>[N,C,d1,d2,...]</code>，对应的真实类别标签维度就得是<code>[N,d1,d2,...]</code>；</li>
</ul>
<p>对于第一种情况，我们在这篇文章（传送门）的最后已经讲过，本文将以第二种形式的数据进行举例说明。</p>
<p>来看一下贯穿本文的一个栗子：</p>
<blockquote>
<p>假设网络的输出<code>output</code>的shape为<code>[1,3,256,256]</code>，其中1代表batchsize，3代表这是个三分类问题，后面的两个256可以看作是一张256*256的图片的高(height)和宽(width)，也就是说，总共有<code>256*256</code>个像素点。用代码随机生成<code>output</code>，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#网络的输出</span></span><br><span class="line">output = torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">256</span>,<span class="number">256</span>)</span><br></pre></td></tr></table></figure>

<p>该输出对应的已知<code>target</code>的shape为<code>[1,256,256]</code>，其中4代表batchsize，后面的两个256也可以看作是一张256*256的图片的高(height)和宽(width)，和网络的输出不同的是，这里每一个像素点的取值集合是${0,1,2}$，因为它们代表的是该像素点所属类别。用代码随机生成<code>target</code>，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#traget的取值集合为&#123;0,1,2&#125;</span></span><br><span class="line">target=torch.empty(<span class="number">1</span>, <span class="number">256</span>,<span class="number">256</span>).random_(<span class="number">0</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

</blockquote>
<p>如果使用PyTorch封装好的<code>CrossEntropyLoss</code>，可以直接得到它们之间的交叉熵：<br><img src= "/img/loading.gif" data-src="./2.png" alt="Alt text"></p>
<p>现在问题来了：<code>CrossEntropyLoss</code>内部究竟做了些什么呢？</p>
<p>如果不能回答这个问题，我们就无法尝试自己用代码写出一个交叉熵函数，而这正是对交叉熵进行魔改的前提！</p>
<p>现在给出答案：</p>
<p><strong>1）对网络的输出<code>output</code>在类别维度上做softmax操作，然后对结果再取log ，得到<code>logsoftmax</code>；</strong><br><strong>2）现在得到了<code>logsoftmax</code>，又已知每个样本的类别标签<code>target</code>，于是将<code>target</code>作为下标索引<code>index</code>，在<code>logsoftmax</code>的类比维度(也就是上一步做softmax的维度)上进行索引，得到每个样本对应的索引值<code>value</code>；</strong><br><strong>3）将每个样本的<code>value</code>加起来求个平均值，再取个负号，就计算出了交叉熵。</strong></p>
<p>为了进行说明，先把之前写过的交叉熵的计算公式搬过来：<br>$$L=-{\frac1N} {\sum_{i=1}^{N}}  {\sum_{c=1}^{K}} y_{ic}log(p_{ic})$$</p>
<p>第(1)步比较容易理解，在类比维度上做softmax是为了将网络预测的类别向量转为概率分布，之后再取log，将预测值的取值范围由$[0,1]$映射到$[-\inf,0]$ ，这对应着交叉熵计算公式中的$log(p_{ic})$;</p>
<p>第(2)步看起来有点奇怪，其实是在简化运算。我们知道，在交叉熵的计算公式中，$y_{ic}$其实是<code>onehot</code>形式的，如果直接求解$y_{ic}log(p_{ic})$，会有大量的$0$出现，这些计算其实是没必要的，我们只需要获取$y_{ic}$中取值为1的元素对应位置的$log(p_{ic})$即可。也就是说，我们可以将对于${\sum_{c=1}^{K}} y_{ic}log(p_{ic})$的计算简化为对于$y_{ic’}log(p_{ic’})$的计算，其中$c’$是第i个样本的真实类标签。</p>
<p>第(3)步也很容易理解，正对应公式中的$-\frac1N\sum_{i=1}^{N}$ 。</p>
<p>了解了这些，就可以根据这三步实现自己的交叉熵了~</p>
<blockquote>
<p>吃瓜群众：期待…</p>
</blockquote>
<h2 id="交叉熵1-0版本"><a href="#交叉熵1-0版本" class="headerlink" title="交叉熵1.0版本"></a>交叉熵1.0版本</h2><p>根据之前的这三个步骤，交叉熵实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_celoss</span><span class="params">(output,target)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># output:[1,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[1,256,256] ，取值集合为&#123;0,1,2&#125;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#（1）做softmax得到概率分布，然后对每个元素取对数</span></span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)<span class="comment">#在类别维度进行softmax</span></span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># （2）在（1）的基础上，对每个像素求解-log_softmax[target],</span></span><br><span class="line">    <span class="comment">#其中log_softmax即为1中所求，它可按通道被分为[c1,c2,c3]，如下：</span></span><br><span class="line">    <span class="comment">#c1 = log_softmax[:,0,:,:]</span></span><br><span class="line">    <span class="comment">#c2 = log_softmax[:, 1,:, :]</span></span><br><span class="line">    <span class="comment">#c3 = log_softmax[:, 2,:, :]</span></span><br><span class="line"></span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line">    s=<span class="number">0</span><span class="comment">#存储loss累加值</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(w):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(h):</span><br><span class="line">                <span class="comment">#获取当前样本点的真实类别标签</span></span><br><span class="line">                ind=int(target[b,i,j].item())</span><br><span class="line">                <span class="comment"># 根据真实类别标签获取log_softmax中对应的value，并累加到总的loss中</span></span><br><span class="line">                s+=log_softmax[b,ind,i,j]</span><br><span class="line">    s=s*(<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> s/(h*w*bsize)</span><br></pre></td></tr></table></figure>
<p>我们可以测试一下：<br><img src= "/img/loading.gif" data-src="./3.png" alt="Alt text"></p>
<p>计算结果和我们之前调用<code>CrossEntropyLoss</code>计算的结果一模一样。</p>
<blockquote>
<p>吃瓜群众：既然已经实现了，那就准备做魔改吧，快说一下魔改的具体内容…</p>
</blockquote>
<p>等等，还有一个问题，这种实现方式计算loss的速度有点慢啊！别看只有1.36秒，假设共10000个样本，batchsize为1，不考虑其他因素，每迭代一个epoch，光计算loss就需要约13600秒，即3.78个小时。</p>
<p>所以，目前知识理论上实现了交叉熵，但实际上是无法投入使用的。</p>
<blockquote>
<p>吃瓜群众：那怎么办？</p>
</blockquote>
<h2 id="交叉熵2-0版本"><a href="#交叉熵2-0版本" class="headerlink" title="交叉熵2.0版本"></a>交叉熵2.0版本</h2><p>既然速度慢，那就找点加速的方法~</p>
<p>经过与搜索引擎的一番友好互动，我发现了<code>numba</code>，据说可以加速。</p>
<p>那就安装下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numba</span><br></pre></td></tr></table></figure>
<p>具体使用时，只需从numba中导入jit，并在要加速的函数（方法）前面加一行<code>@jit</code>即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> jit</span><br><span class="line"><span class="meta">@jit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>需要注意的是，目前的numba只支持对于原生的Python语法以及部分numpy的加速，所以，并不能直接在之前实现的<code>my_celoss</code>函数之前加一句<code>@jit</code>。</p>
<p>不过也能解决，只需将需要被加速的部分单独拿出来写成一个函数就可以了。在<code>my_celoss</code>中，大部分时间都花在那3个for循环中，所以可以将它们单独写成一个函数。最终实现的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_celoss_numba_accelerate</span><span class="params">(output,target)</span>:</span></span><br><span class="line">    <span class="comment"># input:[4,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[4,256,256] in &#123;0,1,2&#125;</span></span><br><span class="line">    </span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line"></span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#因为numba不支持tensor，因此需要先转成numpy的nparray</span></span><br><span class="line">    target=target.cpu().numpy()</span><br><span class="line">    log_softmax=log_softmax.cpu().numpy()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @jit</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">implement_for_loop</span><span class="params">(log_softmax)</span>:</span></span><br><span class="line">        s = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(w):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(h):</span><br><span class="line">                    ind=int(target[b,i,j].item())</span><br><span class="line">                    s=s+log_softmax[b,ind,i,j]</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    s=implement_for_loop(log_softmax)</span><br><span class="line">    s=s*(<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.tensor(s/(h*w*bsize))</span><br></pre></td></tr></table></figure>
<p>测试一下：<br><img src= "/img/loading.gif" data-src="./4.png" alt="Alt text"></p>
<p>果然快了很多！</p>
<blockquote>
<p>吃瓜群众：厉害啦！终于可以开始魔改啦！</p>
</blockquote>
<p>好像，，，等等！</p>
<blockquote>
<p>吃瓜群众：啥？还要等？</p>
</blockquote>
<p>这种写法虽然能够加速，但是，我们已知忽略了一点，那就是，参与运算的不是PyTorch的tensor，这些是不能够被自动求导机制进行求导的，从而无法进行反向传播更新参数。而且，说实话，这加速后的速度还是有点不能接受。</p>
<blockquote>
<p>吃瓜群众：额。。。</p>
</blockquote>
<h2 id="交叉熵3-0版本"><a href="#交叉熵3-0版本" class="headerlink" title="交叉熵3.0版本"></a>交叉熵3.0版本</h2><p>事到如今，必须从根本上对<code>my_celoss</code>进行更改了。</p>
<p>之所以速度慢，是因为嵌套的for循环。那么，我们可不可以摒弃for循环的写法，换成另一种方式呢？</p>
<p>对的，我们可以充分利用PyTorch内置函数，这些函数和numpy中的函数都是经过底层优化的，因此运行速度很快，而且可以天然的使用PyTorch自动求导机制进行求导并实现反向传播更新参数。</p>
<p>代码实现如下，每一步的作用都写在代码注释中了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_celoss_final</span><span class="params">(output,target)</span>:</span></span><br><span class="line">    <span class="comment"># input:[1,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[1,256,256] in &#123;0,1,2&#125;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#这一步不用改，因为本来就是用的PyTorch的内置方法</span></span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line">    loss=<span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#由于batchsize一般都不会很大，因此该for循环花费时间很少</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#下面是本次更改的部分</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取每个像素点的真实类别标签</span></span><br><span class="line">        ind = target[b, :, :].type(torch.int64).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#print('ind:',ind.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取预测得到的每个像素点的类别取值分布（3代表类别）</span></span><br><span class="line">        pred_3channels=log_softmax[b,:,:,:]</span><br><span class="line">        <span class="comment">#print('pred_3channels:',pred_3channels.shape)#torch.Size([3, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#使用gather，在第0个维度（类别所在维度）上用ind进行索引得到每个像素点的value</span></span><br><span class="line">        pred=-pred_3channels.gather(<span class="number">0</span>,ind)</span><br><span class="line">        <span class="comment">#print('pred:',pred.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#求这些像素点value的平均值，并累加到总的loss中</span></span><br><span class="line">        current_loss=torch.mean(pred)</span><br><span class="line">        loss+=current_loss</span><br><span class="line">    <span class="keyword">return</span> loss/bsize</span><br></pre></td></tr></table></figure>
<p>现在来测试一下：<br><img src= "/img/loading.gif" data-src="./5.png" alt="Alt text"></p>
<p>嗯，结果一样，而且速度提升明显。</p>
<blockquote>
<p>吃瓜群众：哇！现在应该可以了吧，不会还要等吧？不会吧不会吧</p>
</blockquote>
<p>不用再等了，现在可以来魔改交叉熵了~</p>
<h2 id="加权的交叉熵"><a href="#加权的交叉熵" class="headerlink" title="加权的交叉熵"></a>加权的交叉熵</h2><p>还是基于我们一直在用的栗子进行操作。</p>
<p>在原始的交叉熵中，每个像素点在总loss中的贡献都是一样的，而现在，我们希望打破这一状态，具体来说，<strong>希望给每个像素点设置一个权重，权重越大，那么该像素点对于总loss的贡献也就越大，反之则越小</strong>。</p>
<p>有了上面那么长的篇幅做铺垫，实现这一魔改操作就很容易了。</p>
<p>我们只需准备一个和<code>target</code>shape一致的<code>tensor</code>，比如这里就是<code>[1,256,256]</code>的<code>tensor</code>，然后将<code>tensor</code>中的<code>256*256</code>个像素点的取值作为<code>target</code>中每个像素点的权重。</p>
<p>最后，将这个<code>tesnor</code>与所有像素点经索引得到的<code>pred</code>做个逐点乘积即可。</p>
<p>现在，上代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weighted_celoss</span><span class="params">(output,target,mask_fill)</span>:</span></span><br><span class="line">    <span class="comment"># input:[1,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[1,256,256] in &#123;0,1,2&#125;</span></span><br><span class="line">    <span class="comment">#mask_fill:[1,256,256]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#这一步不用改，因为本来就是用的PyTorch的内置方法</span></span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line">    loss=<span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#由于batchsize一般都不会很大，因此该for循环花费时间很少</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#下面是本次更改的部分</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取每个像素点的真实类别标签</span></span><br><span class="line">        ind = target[b, :, :].type(torch.int64).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#print('ind:',ind.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取预测得到的每个像素点的类别取值分布（3代表类别）</span></span><br><span class="line">        pred_3channels=log_softmax[b,:,:,:]</span><br><span class="line">        <span class="comment">#print('pred_3channels:',pred_3channels.shape)#torch.Size([3, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#使用gather，在第0个维度（类别所在维度）上用ind进行索引得到每个像素点的value</span></span><br><span class="line">        pred=-pred_3channels.gather(<span class="number">0</span>,ind)</span><br><span class="line">        <span class="comment">#print('pred:',pred.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#添加了这句代码，通过两者的点乘实现了对每个像素点的加权</span></span><br><span class="line">        pred=pred*mask_fill</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#求这些像素点value的平均值，并累加到总的loss中</span></span><br><span class="line">        current_loss=torch.mean(pred)</span><br><span class="line">        loss+=current_loss</span><br><span class="line">    <span class="keyword">return</span> loss/bsize</span><br></pre></td></tr></table></figure>

<p>在之前实现的原始交叉熵代码的基础上，我们只改动了两个地方：</p>
<p>其一，函数多了一个<code>mask_fill</code>参数，它就是我们上面说的用于保存每个像素点权重的<code>tensor</code>；</p>
<p>其二，加了这句代码: <code>pred=pred*mask_fill</code>，它通过点乘实现了对每个像素点的加权。</p>
<p>现在来测试一下：<br><img src= "/img/loading.gif" data-src="./6.png" alt="Alt text"></p>
<p>这里，我们将<code>mask_fill</code>的每一个像素值都设置为0.1，是为了方便验证，具体地，之前看到不加权的loss输出结果为1.1255，而这里加权后的输出为0.1126，舍去计算带来的误差，两者正好是0.1倍的关系，从而证明了以上代码的有效性。</p>
<p>至于在具体使用时，需要根据不同的情况，对<code>mask_fill</code>中的每个像素点设置对应的值作为权重。</p>
<p>下一次，我会结合自己的魔改经历，介绍这种加权交叉熵在实际问题中的应用，其中的核心就是<code>mask_fill</code>的制作过程。</p>
</div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DL/">DL</a></div><div class="post_share"><div class="social-share" data-image="https://www.cdnjson.com/images/2021/11/19/122.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/05/03/%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8BviaYOLOV3/"><img class="prev-cover" data-src="https://www.cdnjson.com/images/2021/05/17/16.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">手把手教你打造一个汽车检测器！</div></div></a></div><div class="next-post pull-right"><a href="/2021/04/28/%E9%82%A3%E4%BA%9B%E5%B9%B4%EF%BC%8C%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E5%AE%9E%E7%8E%B0%E7%9A%84%E4%BA%A4%E5%8F%89%E7%86%B5/"><img class="next-cover" data-src="https://z3.ax1x.com/2021/04/29/gFotZF.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">那些年，我们一起实现的交叉熵</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2021/04/05/1小时快速入门PyTorch/" title="1小时快速入门PyTorch"><img class="relatedPosts_cover" data-src="https://z3.ax1x.com/2021/04/10/cajxDs.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-05</div><div class="relatedPosts_title">1小时快速入门PyTorch</div></div></a></div><div class="relatedPosts_item"><a href="/2020/10/12/Keras中关于模型的trainable状态的问题/" title="Keras中关于模型的trainable状态的问题"><img class="relatedPosts_cover" data-src="https://s1.ax1x.com/2020/07/19/URRLqI.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-12</div><div class="relatedPosts_title">Keras中关于模型的trainable状态的问题</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/16/LSTM/" title="LSTM"><img class="relatedPosts_cover" data-src="https://s1.ax1x.com/2020/08/16/dVcI61.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-16</div><div class="relatedPosts_title">LSTM</div></div></a></div><div class="relatedPosts_item"><a href="/2021/03/02/ProGAN/" title="ProGAN"><img class="relatedPosts_cover" data-src="https://www.cdnjson.com/images/2021/05/01/1.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-02</div><div class="relatedPosts_title">ProGAN</div></div></a></div><div class="relatedPosts_item"><a href="/2021/06/11/NLP极简入门笔记/" title="NLP极简入门笔记"><img class="relatedPosts_cover" data-src="https://www.cdnjson.com/images/2021/06/11/87.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-11</div><div class="relatedPosts_title">NLP极简入门笔记</div></div></a></div><div class="relatedPosts_item"><a href="/2020/11/23/ResNet/" title="ResNet"><img class="relatedPosts_cover" data-src="https://s3.ax1x.com/2020/11/23/DYivdK.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-23</div><div class="relatedPosts_title">ResNet</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 雨落诗山山亦奇</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
document.body.addEventListener('input', POWERMODE);
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/third-party/ClickShowText.js"></script><script src="https://cdn.jsdelivr.net/gh/lete114/CDN/Sum/sakura.js"></script><script src="/js/egao.js"></script><script src="/js/snow.js"></script></body></html>