<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="雨落诗山山亦奇"><meta name="copyright" content="雨落诗山山亦奇"><meta name="generator" content="Hexo 4.2.1"><meta name="theme" content="hexo-theme-yun"><title>魔改交叉熵 | 南极Python</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.25/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_dxory92pb0h.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="icon" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"yoursite.com","root":"/","title":"云游君的小站","version":"1.6.3","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><meta name="description" content="在之前的这篇文章中，我们介绍了PyTorch中的交叉熵损失函数的具体使用方法（传送门），并举了大量的栗子进行解释。 在此基础上，就可以尝试对交叉熵进行魔改啦~ CrossEntropyLoss到底做了什么？ 吃瓜群众：那说一下魔改的具体内容呗…  别着急，在开始魔改之前，需要花些篇幅介绍下在PyTorch中的CrossEntropyLoss内部所做的事情。这是官方给出的关于CrossEntropy">
<meta property="og:type" content="article">
<meta property="og:title" content="魔改交叉熵">
<meta property="og:url" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/index.html">
<meta property="og:site_name" content="南极Python">
<meta property="og:description" content="在之前的这篇文章中，我们介绍了PyTorch中的交叉熵损失函数的具体使用方法（传送门），并举了大量的栗子进行解释。 在此基础上，就可以尝试对交叉熵进行魔改啦~ CrossEntropyLoss到底做了什么？ 吃瓜群众：那说一下魔改的具体内容呗…  别着急，在开始魔改之前，需要花些篇幅介绍下在PyTorch中的CrossEntropyLoss内部所做的事情。这是官方给出的关于CrossEntropy">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/1.png">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/2.png">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/3.png">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/4.png">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/5.png">
<meta property="og:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/6.png">
<meta property="article:published_time" content="2021-05-01T07:43:15.000Z">
<meta property="article:modified_time" content="2021-05-02T12:11:22.598Z">
<meta property="article:author" content="雨落诗山山亦奇">
<meta property="article:tag" content="DL">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/1.png"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="雨落诗山山亦奇"><img width="96" loading="lazy" src="/yun.png" alt="雨落诗山山亦奇"></a><div class="site-author-name"><a href="/about/">雨落诗山山亦奇</a></div><span class="site-name">南极Python</span><sub class="site-subtitle">Python|机器学习|深度学习</sub><div class="site-desciption">昨夜星辰昨夜风</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">134</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">9</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">13</span></a></div><a class="site-state-item hty-icon-button" href="https://yun.yunyoujun.cn" target="_blank" rel="noopener" title="文档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-settings-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://qm.qq.com/cgi-bin/qm/qr?k=kZJzggTTCf4SpvEQ8lXWoi5ZjhAx0ILZ&amp;jump_from=webapi" title="QQ 群 1050458482" target="_blank" style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/YunYouJun" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://weibo.com/jizhideyunyoujun" title="微博" target="_blank" style="color:#E6162D"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-weibo-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.douban.com/people/yunyoujun/" title="豆瓣" target="_blank" style="color:#007722"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-douban-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://music.163.com/#/user/home?id=247102977" title="网易云音乐" target="_blank" style="color:#C20C0C"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-netease-cloud-music-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.zhihu.com/people/yunyoujun/" title="知乎" target="_blank" style="color:#0084FF"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhihu-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/1579790" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/about/white-qrcode-and-search.jpg" title="微信公众号" target="_blank" style="color:#1AAD19"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-2-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://twitter.com/YunYouJun" title="Twitter" target="_blank" style="color:#1da1f2"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-twitter-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://t.me/elpsycn" title="Telegram Channel" target="_blank" style="color:#0088CC"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-telegram-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:me@yunyoujun.cn" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://travellings.link" title="Travelling" target="_blank" style="color:var(--hty-text-color)"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-train-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#CrossEntropyLoss到底做了什么？"><span class="toc-number">1.</span> <span class="toc-text">CrossEntropyLoss到底做了什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#交叉熵1-0版本"><span class="toc-number">2.</span> <span class="toc-text">交叉熵1.0版本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#交叉熵2-0版本"><span class="toc-number">3.</span> <span class="toc-text">交叉熵2.0版本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#交叉熵3-0版本"><span class="toc-number">4.</span> <span class="toc-text">交叉熵3.0版本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#加权的交叉熵"><span class="toc-number">5.</span> <span class="toc-text">加权的交叉熵</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="雨落诗山山亦奇"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="南极Python"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">魔改交叉熵</h1><div class="post-meta"><div class="post-time" style="display:inline-block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2021-05-01 15:43:15" itemprop="dateCreated datePublished" datetime="2021-05-01T15:43:15+08:00">2021-05-01</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-2-line"></use></svg></span> <time title="修改时间：2021-05-02 20:11:22" itemprop="dateModified" datetime="2021-05-02T20:11:22+08:00">2021-05-02</time></div><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">深度学习笔记</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag-item" href="/tags/DL/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">DL</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#0078E7;"><p>在之前的这篇文章中，我们介绍了PyTorch中的交叉熵损失函数的具体使用方法（传送门），并举了大量的栗子进行解释。</p>
<p>在此基础上，就可以尝试对交叉熵进行魔改啦~</p>
<h2 id="CrossEntropyLoss到底做了什么？"><a href="#CrossEntropyLoss到底做了什么？" class="headerlink" title="CrossEntropyLoss到底做了什么？"></a>CrossEntropyLoss到底做了什么？</h2><blockquote>
<p>吃瓜群众：那说一下魔改的具体内容呗…</p>
</blockquote>
<p>别着急，在开始魔改之前，需要花些篇幅介绍下在PyTorch中的<code>CrossEntropyLoss</code>内部所做的事情。<br><img src="./1.png" alt="Alt text" loading="lazy"><br>这是官方给出的关于<code>CrossEntropyLoss</code>的维度说明。简而言之，分为两种情况：</p>
<ul>
<li>网络的输出shape为<code>[N,C]</code>，对应的真实类别标签维度就得是<code>[N]</code>；</li>
<li>网络的输出shape为<code>[N,C,d1,d2,...]</code>，对应的真实类别标签维度就得是<code>[N,d1,d2,...]</code>；</li>
</ul>
<p>对于第一种情况，我们在这篇文章（传送门）的最后已经讲过，本文将以第二种形式的数据进行举例说明。</p>
<p>来看一下贯穿本文的一个栗子：</p>
<blockquote>
<p>假设网络的输出<code>output</code>的shape为<code>[1,3,256,256]</code>，其中1代表batchsize，3代表这是个三分类问题，后面的两个256可以看作是一张256*256的图片的高(height)和宽(width)，也就是说，总共有<code>256*256</code>个像素点。用代码随机生成<code>output</code>，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#网络的输出</span></span><br><span class="line">output = torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">256</span>,<span class="number">256</span>)</span><br></pre></td></tr></table></figure>

<p>该输出对应的已知<code>target</code>的shape为<code>[1,256,256]</code>，其中4代表batchsize，后面的两个256也可以看作是一张256*256的图片的高(height)和宽(width)，和网络的输出不同的是，这里每一个像素点的取值集合是${0,1,2}$，因为它们代表的是该像素点所属类别。用代码随机生成<code>target</code>，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#traget的取值集合为&#123;0,1,2&#125;</span></span><br><span class="line">target=torch.empty(<span class="number">1</span>, <span class="number">256</span>,<span class="number">256</span>).random_(<span class="number">0</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

</blockquote>
<p>如果使用PyTorch封装好的<code>CrossEntropyLoss</code>，可以直接得到它们之间的交叉熵：<br><img src="./2.png" alt="Alt text" loading="lazy"></p>
<p>现在问题来了：<code>CrossEntropyLoss</code>内部究竟做了些什么呢？</p>
<p>如果不能回答这个问题，我们就无法尝试自己用代码写出一个交叉熵函数，而这正是对交叉熵进行魔改的前提！</p>
<p>现在给出答案：</p>
<p><strong>1）对网络的输出<code>output</code>在类别维度上做softmax操作，然后对结果再取log ，得到<code>logsoftmax</code>；</strong><br><strong>2）现在得到了<code>logsoftmax</code>，又已知每个样本的类别标签<code>target</code>，于是将<code>target</code>作为下标索引<code>index</code>，在<code>logsoftmax</code>的类比维度(也就是上一步做softmax的维度)上进行索引，得到每个样本对应的索引值<code>value</code>；</strong><br><strong>3）将每个样本的<code>value</code>加起来求个平均值，再取个负号，就计算出了交叉熵。</strong></p>
<p>为了进行说明，先把之前写过的交叉熵的计算公式搬过来：<br>$$L=-{\frac1N} {\sum_{i=1}^{N}}  {\sum_{c=1}^{K}} y_{ic}log(p_{ic})$$</p>
<p>第(1)步比较容易理解，在类比维度上做softmax是为了将网络预测的类别向量转为概率分布，之后再取log，将预测值的取值范围由$[0,1]$映射到$[-\inf,0]$ ，这对应着交叉熵计算公式中的$log(p_{ic})$;</p>
<p>第(2)步看起来有点奇怪，其实是在简化运算。我们知道，在交叉熵的计算公式中，$y_{ic}$其实是<code>onehot</code>形式的，如果直接求解$y_{ic}log(p_{ic})$，会有大量的$0$出现，这些计算其实是没必要的，我们只需要获取$y_{ic}$中取值为1的元素对应位置的$log(p_{ic})$即可。也就是说，我们可以将对于${\sum_{c=1}^{K}} y_{ic}log(p_{ic})$的计算简化为对于$y_{ic’}log(p_{ic’})$的计算，其中$c’$是第i个样本的真实类标签。</p>
<p>第(3)步也很容易理解，正对应公式中的$-\frac1N\sum_{i=1}^{N}$ 。</p>
<p>了解了这些，就可以根据这三步实现自己的交叉熵了~</p>
<blockquote>
<p>吃瓜群众：期待…</p>
</blockquote>
<h2 id="交叉熵1-0版本"><a href="#交叉熵1-0版本" class="headerlink" title="交叉熵1.0版本"></a>交叉熵1.0版本</h2><p>根据之前的这三个步骤，交叉熵实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_celoss</span><span class="params">(output,target)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># output:[1,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[1,256,256] ，取值集合为&#123;0,1,2&#125;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#（1）做softmax得到概率分布，然后对每个元素取对数</span></span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)<span class="comment">#在类别维度进行softmax</span></span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># （2）在（1）的基础上，对每个像素求解-log_softmax[target],</span></span><br><span class="line">    <span class="comment">#其中log_softmax即为1中所求，它可按通道被分为[c1,c2,c3]，如下：</span></span><br><span class="line">    <span class="comment">#c1 = log_softmax[:,0,:,:]</span></span><br><span class="line">    <span class="comment">#c2 = log_softmax[:, 1,:, :]</span></span><br><span class="line">    <span class="comment">#c3 = log_softmax[:, 2,:, :]</span></span><br><span class="line"></span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line">    s=<span class="number">0</span><span class="comment">#存储loss累加值</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(w):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(h):</span><br><span class="line">                <span class="comment">#获取当前样本点的真实类别标签</span></span><br><span class="line">                ind=int(target[b,i,j].item())</span><br><span class="line">                <span class="comment"># 根据真实类别标签获取log_softmax中对应的value，并累加到总的loss中</span></span><br><span class="line">                s+=log_softmax[b,ind,i,j]</span><br><span class="line">    s=s*(<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> s/(h*w*bsize)</span><br></pre></td></tr></table></figure>
<p>我们可以测试一下：<br><img src="./3.png" alt="Alt text" loading="lazy"></p>
<p>计算结果和我们之前调用<code>CrossEntropyLoss</code>计算的结果一模一样。</p>
<blockquote>
<p>吃瓜群众：既然已经实现了，那就准备做魔改吧，快说一下魔改的具体内容…</p>
</blockquote>
<p>等等，还有一个问题，这种实现方式计算loss的速度有点慢啊！别看只有1.36秒，假设共10000个样本，batchsize为1，不考虑其他因素，每迭代一个epoch，光计算loss就需要约13600秒，即3.78个小时。</p>
<p>所以，目前知识理论上实现了交叉熵，但实际上是无法投入使用的。</p>
<blockquote>
<p>吃瓜群众：那怎么办？</p>
</blockquote>
<h2 id="交叉熵2-0版本"><a href="#交叉熵2-0版本" class="headerlink" title="交叉熵2.0版本"></a>交叉熵2.0版本</h2><p>既然速度慢，那就找点加速的方法~</p>
<p>经过与搜索引擎的一番友好互动，我发现了<code>numba</code>，据说可以加速。</p>
<p>那就安装下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numba</span><br></pre></td></tr></table></figure>
<p>具体使用时，只需从numba中导入jit，并在要加速的函数（方法）前面加一行<code>@jit</code>即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> jit</span><br><span class="line"><span class="meta">@jit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>需要注意的是，目前的numba只支持对于原生的Python语法以及部分numpy的加速，所以，并不能直接在之前实现的<code>my_celoss</code>函数之前加一句<code>@jit</code>。</p>
<p>不过也能解决，只需将需要被加速的部分单独拿出来写成一个函数就可以了。在<code>my_celoss</code>中，大部分时间都花在那3个for循环中，所以可以将它们单独写成一个函数。最终实现的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_celoss_numba_accelerate</span><span class="params">(output,target)</span>:</span></span><br><span class="line">    <span class="comment"># input:[4,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[4,256,256] in &#123;0,1,2&#125;</span></span><br><span class="line">    </span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line"></span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#因为numba不支持tensor，因此需要先转成numpy的nparray</span></span><br><span class="line">    target=target.cpu().numpy()</span><br><span class="line">    log_softmax=log_softmax.cpu().numpy()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @jit</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">implement_for_loop</span><span class="params">(log_softmax)</span>:</span></span><br><span class="line">        s = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(w):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(h):</span><br><span class="line">                    ind=int(target[b,i,j].item())</span><br><span class="line">                    s=s+log_softmax[b,ind,i,j]</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    s=implement_for_loop(log_softmax)</span><br><span class="line">    s=s*(<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.tensor(s/(h*w*bsize))</span><br></pre></td></tr></table></figure>
<p>测试一下：<br><img src="./4.png" alt="Alt text" loading="lazy"></p>
<p>果然快了很多！</p>
<blockquote>
<p>吃瓜群众：厉害啦！终于可以开始魔改啦！</p>
</blockquote>
<p>好像，，，等等！</p>
<blockquote>
<p>吃瓜群众：啥？还要等？</p>
</blockquote>
<p>这种写法虽然能够加速，但是，我们已知忽略了一点，那就是，参与运算的不是PyTorch的tensor，这些是不能够被自动求导机制进行求导的，从而无法进行反向传播更新参数。而且，说实话，这加速后的速度还是有点不能接受。</p>
<blockquote>
<p>吃瓜群众：额。。。</p>
</blockquote>
<h2 id="交叉熵3-0版本"><a href="#交叉熵3-0版本" class="headerlink" title="交叉熵3.0版本"></a>交叉熵3.0版本</h2><p>事到如今，必须从根本上对<code>my_celoss</code>进行更改了。</p>
<p>之所以速度慢，是因为嵌套的for循环。那么，我们可不可以摒弃for循环的写法，换成另一种方式呢？</p>
<p>对的，我们可以充分利用PyTorch内置函数，这些函数和numpy中的函数都是经过底层优化的，因此运行速度很快，而且可以天然的使用PyTorch自动求导机制进行求导并实现反向传播更新参数。</p>
<p>代码实现如下，每一步的作用都写在代码注释中了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_celoss_final</span><span class="params">(output,target)</span>:</span></span><br><span class="line">    <span class="comment"># input:[1,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[1,256,256] in &#123;0,1,2&#125;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#这一步不用改，因为本来就是用的PyTorch的内置方法</span></span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line">    loss=<span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#由于batchsize一般都不会很大，因此该for循环花费时间很少</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#下面是本次更改的部分</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取每个像素点的真实类别标签</span></span><br><span class="line">        ind = target[b, :, :].type(torch.int64).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#print('ind:',ind.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取预测得到的每个像素点的类别取值分布（3代表类别）</span></span><br><span class="line">        pred_3channels=log_softmax[b,:,:,:]</span><br><span class="line">        <span class="comment">#print('pred_3channels:',pred_3channels.shape)#torch.Size([3, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#使用gather，在第0个维度（类别所在维度）上用ind进行索引得到每个像素点的value</span></span><br><span class="line">        pred=-pred_3channels.gather(<span class="number">0</span>,ind)</span><br><span class="line">        <span class="comment">#print('pred:',pred.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#求这些像素点value的平均值，并累加到总的loss中</span></span><br><span class="line">        current_loss=torch.mean(pred)</span><br><span class="line">        loss+=current_loss</span><br><span class="line">    <span class="keyword">return</span> loss/bsize</span><br></pre></td></tr></table></figure>
<p>现在来测试一下：<br><img src="./5.png" alt="Alt text" loading="lazy"></p>
<p>嗯，结果一样，而且速度提升明显。</p>
<blockquote>
<p>吃瓜群众：哇！现在应该可以了吧，不会还要等吧？不会吧不会吧</p>
</blockquote>
<p>不用再等了，现在可以来魔改交叉熵了~</p>
<h2 id="加权的交叉熵"><a href="#加权的交叉熵" class="headerlink" title="加权的交叉熵"></a>加权的交叉熵</h2><p>还是基于我们一直在用的栗子进行操作。</p>
<p>在原始的交叉熵中，每个像素点在总loss中的贡献都是一样的，而现在，我们希望打破这一状态，具体来说，<strong>希望给每个像素点设置一个权重，权重越大，那么该像素点对于总loss的贡献也就越大，反之则越小</strong>。</p>
<p>有了上面那么长的篇幅做铺垫，实现这一魔改操作就很容易了。</p>
<p>我们只需准备一个和<code>target</code>shape一致的<code>tensor</code>，比如这里就是<code>[1,256,256]</code>的<code>tensor</code>，然后将<code>tensor</code>中的<code>256*256</code>个像素点的取值作为<code>target</code>中每个像素点的权重。</p>
<p>最后，将这个<code>tesnor</code>与所有像素点经索引得到的<code>pred</code>做个逐点乘积即可。</p>
<p>现在，上代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weighted_celoss</span><span class="params">(output,target,mask_fill)</span>:</span></span><br><span class="line">    <span class="comment"># input:[1,3,256,256]</span></span><br><span class="line">    <span class="comment"># target:[1,256,256] in &#123;0,1,2&#125;</span></span><br><span class="line">    <span class="comment">#mask_fill:[1,256,256]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#这一步不用改，因为本来就是用的PyTorch的内置方法</span></span><br><span class="line">    ls=nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">    log_softmax=ls(output)</span><br><span class="line">    bsize,h,w=target.shape[<span class="number">0</span>],target.shape[<span class="number">1</span>],target.shape[<span class="number">2</span>]</span><br><span class="line">    loss=<span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#由于batchsize一般都不会很大，因此该for循环花费时间很少</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> range(bsize):</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#下面是本次更改的部分</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取每个像素点的真实类别标签</span></span><br><span class="line">        ind = target[b, :, :].type(torch.int64).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#print('ind:',ind.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取预测得到的每个像素点的类别取值分布（3代表类别）</span></span><br><span class="line">        pred_3channels=log_softmax[b,:,:,:]</span><br><span class="line">        <span class="comment">#print('pred_3channels:',pred_3channels.shape)#torch.Size([3, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#使用gather，在第0个维度（类别所在维度）上用ind进行索引得到每个像素点的value</span></span><br><span class="line">        pred=-pred_3channels.gather(<span class="number">0</span>,ind)</span><br><span class="line">        <span class="comment">#print('pred:',pred.shape)#torch.Size([1, 256, 256])</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#添加了这句代码，通过两者的点乘实现了对每个像素点的加权</span></span><br><span class="line">        pred=pred*mask_fill</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#求这些像素点value的平均值，并累加到总的loss中</span></span><br><span class="line">        current_loss=torch.mean(pred)</span><br><span class="line">        loss+=current_loss</span><br><span class="line">    <span class="keyword">return</span> loss/bsize</span><br></pre></td></tr></table></figure>

<p>在之前实现的原始交叉熵代码的基础上，我们只改动了两个地方：</p>
<p>其一，函数多了一个<code>mask_fill</code>参数，它就是我们上面说的用于保存每个像素点权重的<code>tensor</code>；</p>
<p>其二，加了这句代码: <code>pred=pred*mask_fill</code>，它通过点乘实现了对每个像素点的加权。</p>
<p>现在来测试一下：<br><img src="./6.png" alt="Alt text" loading="lazy"></p>
<p>这里，我们将<code>mask_fill</code>的每一个像素值都设置为0.1，是为了方便验证，具体地，之前看到不加权的loss输出结果为1.1255，而这里加权后的输出为0.1126，舍去计算带来的误差，两者正好是0.1倍的关系，从而证明了以上代码的有效性。</p>
<p>至于在具体使用时，需要根据不同的情况，对<code>mask_fill</code>中的每个像素点设置对应的值作为权重。</p>
<p>下一次，我会结合自己的魔改经历，介绍这种加权交叉熵在实际问题中的应用，其中的核心就是<code>mask_fill</code>的制作过程。</p>
</div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="打赏" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">I'm so cute. Please give me money.</div><div id="qr" style="display:none;"><div style="display:inline-block"><a href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/alipay-qrcode.jpg" target="_blank" rel="noopener"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/alipay-qrcode.jpg" alt="支付宝" title="支付宝"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/qqpay-qrcode.png" target="_blank" rel="noopener"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/qqpay-qrcode.png" alt="QQ 支付" title="QQ 支付"></a><div><span style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></span></div></div><div style="display:inline-block"><a href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/wechatpay-qrcode.jpg" target="_blank" rel="noopener"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/wechatpay-qrcode.jpg" alt="微信支付" title="微信支付"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>雨落诗山山亦奇</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/" title="魔改交叉熵">http://yoursite.com/2021/05/01/%E9%AD%94%E6%94%B9%E4%BA%A4%E5%8F%89%E7%86%B5/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2021/05/03/%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8BviaYOLOV3/" rel="prev" title="手把手教你打造一个汽车检测器！"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">手把手教你打造一个汽车检测器！</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2021/04/28/%E9%82%A3%E4%BA%9B%E5%B9%B4%EF%BC%8C%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E5%AE%9E%E7%8E%B0%E7%9A%84%E4%BA%A4%E5%8F%89%E7%86%B5/" rel="next" title="那些年，我们一起实现的交叉熵"><span class="post-nav-text">那些年，我们一起实现的交叉熵</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>要不要和我说些什么？</span><br></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 雨落诗山山亦奇</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v4.2.1</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.6.3</span></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a></div></body></html>