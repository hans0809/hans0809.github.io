<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>南极Python - Python|机器学习|深度学习</title><meta name="keywords" content="Python|机器学习|深度学习|生活感悟"><meta name="author" content="雨落诗山山亦奇"><meta name="copyright" content="雨落诗山山亦奇"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本站为读研版&amp;工作版博客，大学版移步 --&gt; fuhanshi.github.io">
<meta property="og:type" content="website">
<meta property="og:title" content="南极Python">
<meta property="og:url" content="http://yoursite.com/page/14/index.html">
<meta property="og:site_name" content="南极Python">
<meta property="og:description" content="本站为读研版&amp;工作版博客，大学版移步 --&gt; fuhanshi.github.io">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png">
<meta property="article:author" content="雨落诗山山亦奇">
<meta property="article:tag" content="Python|机器学习|深度学习|生活感悟">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png"><link rel="shortcut icon" href="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png"><link rel="canonical" href="http://yoursite.com/page/14/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '南极Python',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-03-07 23:36:42'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/macblack.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">169</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div></div><hr/></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/tag1.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">南极Python</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">南极Python</h1><div id="site-subtitle"><span id="subtitle"></span></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2020/10/12/Keras%E4%B8%AD%E5%85%B3%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84trainable%E7%8A%B6%E6%80%81%E7%9A%84%E9%97%AE%E9%A2%98/" title="Keras中关于模型的trainable状态的问题"><img class="post_bg" src="https://s1.ax1x.com/2020/07/19/URRLqI.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Keras中关于模型的trainable状态的问题"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/12/Keras%E4%B8%AD%E5%85%B3%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84trainable%E7%8A%B6%E6%80%81%E7%9A%84%E9%97%AE%E9%A2%98/" title="Keras中关于模型的trainable状态的问题">Keras中关于模型的trainable状态的问题</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-10-12T04:28:36.000Z" title="发表于 2020-10-12 12:28:36">2020-10-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">提出问题在看GAN的实现代码的时候，发现了这么一个地方：
123456789101112131415161718192021222324252627282930313233class GAN():    def __init__(self):        self.img_rows = 28        self.img_cols = 28        self.channels = 1        self.img_shape = (self.img_rows, self.img_cols, self.channels)        self.latent_dim = 100        optimizer = Adam(0.0002, 0.5)        # Build and compile the discriminator        self.discriminator = self.build_discriminator()        self.discriminator.compile(loss=&#x27;binary_crossentropy& ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2020/10/11/CDCGAN/" title="CDCGAN"><img class="post_bg" src="https://s1.ax1x.com/2020/10/11/0cPDHg.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CDCGAN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/11/CDCGAN/" title="CDCGAN">CDCGAN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-10-11T05:39:57.000Z" title="发表于 2020-10-11 13:39:57">2020-10-11</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">和CGAN一样，只是采用了卷积层替换全连接层的方法来搭建生成器和判别器的网络
导入所需函数12345678910import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layersfrom tensorflow.keras.layers import Input,multiply,Flatten,Embeddingfrom tensorflow.keras.models import  Modelimport matplotlib.pyplot as pltimport numpy as npimport globimport osfrom tensorflow.keras.utils import to_categorical   

准备数据1(train_images,train_labels),(_,_)=tf.keras.datasets.mnist.load_data()


1train_images.shape




(60000, 28, 28)

1train_ ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2020/10/11/CGAN/" title="CGAN"><img class="post_bg" src="https://s1.ax1x.com/2020/10/11/0cPDHg.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CGAN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/11/CGAN/" title="CGAN">CGAN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-10-11T01:03:36.000Z" title="发表于 2020-10-11 09:03:36">2020-10-11</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">什么是CGAN所谓CGAN，就是在GAN的基础上，多施加了一些条件信息，比如图像的标签等，使得生成器可以按照我们指定的标签去生成所对应的图像。
普通GAN的目标函数为：

而CGAN的目标函数为：

CGAN的网络结构如下：

如何构建CGAN本文在普通GAN（全连接层搭建）的基础上，将生成器的输入由“噪声”改为“噪声+对应该批次图像的真实标签”，将判别器的输入由”图像”改为”图像+对应该批次图像的真实标签”，最后在测试生成器的生成能力时，人为构建了0到9这10个数字作为标签（因为训练数据是mnist数据集），和随机噪声一起喂入生成器以产生新的图片。
Tensorflow2.0 实现CGAN导入所需函数12345678910import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layersfrom tensorflow.keras.layers import Input,multiply,Flatten,Embeddingfrom tensorflow.keras.models i ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2020/10/10/tf-keras-layers-Embedding/" title="tf.keras.layers.Embedding"><img class="post_bg" src="https://s1.ax1x.com/2020/07/10/UKkian.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="tf.keras.layers.Embedding"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/10/tf-keras-layers-Embedding/" title="tf.keras.layers.Embedding">tf.keras.layers.Embedding</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-10-10T14:27:37.000Z" title="发表于 2020-10-10 22:27:37">2020-10-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">函数原型1tf.keras.layers.Embedding(input_dim, output_dim, embeddings_initializer=&#x27;uniform&#x27;,    embeddings_regularizer=None, activity_regularizer=None,    embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs)

举个图像数据的例子这里的input_shape是(10)，output_shape是np.prod((28, 28, 1))
1234567from tensorflow.keras.layers import multiply,Flatten,Embeddingimg=tf.ones((2,28,28,1))#两张图片label=np.array([1,2])#两个标签label_embedding = Flatten()(Embedding(10, np.prod((28, 28, 1)))(label))flat_im ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2020/10/10/FrechetInceptionDistance/" title="FrechetInceptionDistance"><img class="post_bg" src="https://s1.ax1x.com/2020/10/10/0yk7E4.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="FrechetInceptionDistance"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/10/FrechetInceptionDistance/" title="FrechetInceptionDistance">FrechetInceptionDistance</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-10-10T05:30:39.000Z" title="发表于 2020-10-10 13:30:39">2020-10-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">什么是FIDFréchet Inception Distance (FID) 度量了真实图片和生成图片在 feature 层面的距离
FID越小，则图像多样性越好，质量也越好 
众所周知，预训练好的神经网络顶层可以提取图片的高级信息，一定程度能反映图片的本质。因此，FID 的提出者通过预训练的 Inception V3 来提取全连接层之前的 2048 维向量，作为图片的特征。 具体的做法是：去掉最后的输出层（ 最后一层是一个pooling层，原来的网络通过该pooling层可以输出一张图像的类别 ），然后得到一个2048维的高层特征，这个高层特征是一个长向量形式。
FID的计算公式如下：
   
 
在这里，将每一张图片输入分类器中，都会得到一个2048维的长向量，对所有图片得到的长向量求平均值，求协方差矩阵，就得到了公式中的四个部分的值。
FID 只把 Inception V3 作为特征提取器，并不依赖它判断图片的具体类别，因此不必担心 Inception V3 的训练数据和生成模型的训练数据不同。同时，由于直接衡量生成数据和真实数据的分布之间的距离，也不必担心每个类别内部只产生一模 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2020/10/09/InceptionScore/" title="InceptionScore"><img class="post_bg" src="https://s1.ax1x.com/2020/10/09/0DzSun.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="InceptionScore"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/09/InceptionScore/" title="InceptionScore">InceptionScore</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-10-09T04:51:32.000Z" title="发表于 2020-10-09 12:51:32">2020-10-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">  IS使用两个标准来衡量GAN的性能： 

The quality of the generated images, and
their diversity.

熵可以看作是对随机性的度量。如果随机变量x的值是高度可预测的，则其熵较低。相反，如果它是高度不可预测的，那么熵就很高。例如，在下图中，我们有两个概率分布p（x）。p2具有比p1更高的熵，因为p2具有更均匀的分布，所以更难以预测x。 
  
质量在GAN中，我们希望条件概率P（y | x）具有高度可预测性（低熵），比如红色线表示的分布。
（Images that are classified strongly as one class over all other classes indicate a high quality. As such, the conditional probability of all generated images in the collection should have a low entropy. ）
即给定一张图像，我们应该容易地知道对象的类型。因此，我们使用Inception网络对生 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2020/10/08/WGAN/" title="WGAN"><img class="post_bg" src="https://s1.ax1x.com/2020/10/08/00iuyd.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="WGAN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/08/WGAN/" title="WGAN">WGAN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-10-08T07:38:51.000Z" title="发表于 2020-10-08 15:38:51">2020-10-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">网络结构在基础GAN或DCGAN（本文）的基础上，使用推土机距离衡量真实样本分布与生成样本分布之间的距离，此时，即使两个分布没有重合部分（这经常发生，容易导致梯度突变），也能准确的衡量分布的差异。
 
从上图可以看出，WGAN的梯度永远不会为0，而普通GAN会出现梯度为0的情况。
根据
 
可以确定判别器和生成器的损失为：
 
其中，1-Lipscgitz是指$||f(x_1)-f(x_2)||\le1*||x_1-x_2||$
也就是导数要≤1
这一点，可以通过对权值进行clip的方式，使得权值固定在某个区间内，从而也使得导数固定在某一区间内(比如≤1)
下面的代码在DCGAN的基础上，修改了判别器和生成器的损失函数，并在每次权值更新后做了权值裁剪，其余未变。
导入相关函数12345import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layersimport matplotlib.pyplot as pltimport numpy as np

准备数据1(train_imag ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2020/10/07/LSGAN/" title="LSGAN"><img class="post_bg" src="https://s1.ax1x.com/2020/10/07/0dQ7qS.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LSGAN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/07/LSGAN/" title="LSGAN">LSGAN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-10-07T10:23:33.000Z" title="发表于 2020-10-07 18:23:33">2020-10-07</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">网络结构在DCGAN(本文)或者普通GAN的基础上，将交叉熵损失改为均方误差损失，就得到了LSGAN
LSGAN是对之前两种GAN的优化，因为当生成器生成的数据分布$P_G$与数据的真实分布$P_{data}$不重叠时，JS散度永远都是log2，从而导致生成器难以更新，见下图
 
 
导入相关函数12345import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layersimport matplotlib.pyplot as pltimport numpy as np

准备数据1(train_images,_),(_,_)=tf.keras.datasets.mnist.load_data()


1train_images.shape




(60000, 28, 28)

1train_images.dtype




dtype(&#39;uint8&#39;)

1train_images=train_images.reshape(train_images.shape[ ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2020/10/07/DCGAN/" title="DCGAN"><img class="post_bg" src="https://s1.ax1x.com/2020/10/07/0dSxjx.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DCGAN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/07/DCGAN/" title="DCGAN">DCGAN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-10-07T08:24:10.000Z" title="发表于 2020-10-07 16:24:10">2020-10-07</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">网络结构同普通GAN ，只是将生成器与判别器网络中的Dense层换为了卷积层与转置卷积层，故整体代码只需改动生成器和判别器的网络搭建函数即可。
导入相关函数12345import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layersimport matplotlib.pyplot as pltimport numpy as np

准备数据1(train_images,_),(_,_)=tf.keras.datasets.mnist.load_data()


1train_images.shape




(60000, 28, 28)

1train_images.dtype




dtype(&#39;uint8&#39;)

1train_images=train_images.reshape(train_images.shape[0],28,28,1).astype(&#x27;float32&#x27;)


1train_images.shape




(6000 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2020/10/06/%E5%9F%BA%E7%A1%80GAN/" title="基础GAN"><img class="post_bg" src="https://s1.ax1x.com/2020/10/06/0U2zKf.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基础GAN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/06/%E5%9F%BA%E7%A1%80GAN/" title="基础GAN">基础GAN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-10-06T14:23:20.000Z" title="发表于 2020-10-06 22:23:20">2020-10-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">网络结构 
导入相关函数12345import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layersimport matplotlib.pyplot as pltimport numpy as np

准备数据1(train_images,_),(_,_)=tf.keras.datasets.mnist.load_data()


1train_images.shape




(60000, 28, 28)

1train_images.dtype




dtype(&#39;uint8&#39;)

1train_images=train_images.reshape(train_images.shape[0],28,28,1).astype(&#x27;float32&#x27;)


1train_images.shape




(60000, 28, 28, 1)

1train_images.dtype




dtype(&#39;float32&#39;)

1 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/13/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/#content-inner">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/#content-inner">15</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/#content-inner">17</a><a class="extend next" rel="next" href="/page/15/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://www.cdnjson.com/images/2021/11/27/_20210211193948.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">雨落诗山山亦奇</div><div class="author-info__description">本站为读研版&工作版博客，大学版移步 --> fuhanshi.github.io</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">169</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">本站内容的最终版本将发布在微信公众号[南极Python]</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/03/07/%E5%8A%A8%E6%89%8B%E6%90%AD%E5%BB%BAGPT2%E6%9E%B6%E6%9E%84-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%B8%89)/" title="动手搭建GPT2架构-大模型炼丹术(三)"><img src="https://i.miji.bid/2025/02/24/d3f99c0abebc6eb1a20faf08505cfc1f.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="动手搭建GPT2架构-大模型炼丹术(三)"/></a><div class="content"><a class="title" href="/2025/03/07/%E5%8A%A8%E6%89%8B%E6%90%AD%E5%BB%BAGPT2%E6%9E%B6%E6%9E%84-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%B8%89)/" title="动手搭建GPT2架构-大模型炼丹术(三)">动手搭建GPT2架构-大模型炼丹术(三)</a><time datetime="2025-03-07T15:35:12.000Z" title="发表于 2025-03-07 23:35:12">2025-03-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/03/04/%E4%BB%8E%E5%8D%95%E5%A4%B4%E5%88%B0%E5%A4%9A%E5%A4%B4%EF%BC%8C%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%B8%89)/" title="从单头到多头，深度解析大模型的注意力机制-大模型炼丹术(三)"><img src="https://i.miji.bid/2025/02/24/d3f99c0abebc6eb1a20faf08505cfc1f.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从单头到多头，深度解析大模型的注意力机制-大模型炼丹术(三)"/></a><div class="content"><a class="title" href="/2025/03/04/%E4%BB%8E%E5%8D%95%E5%A4%B4%E5%88%B0%E5%A4%9A%E5%A4%B4%EF%BC%8C%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%B8%89)/" title="从单头到多头，深度解析大模型的注意力机制-大模型炼丹术(三)">从单头到多头，深度解析大模型的注意力机制-大模型炼丹术(三)</a><time datetime="2025-03-04T14:03:57.000Z" title="发表于 2025-03-04 22:03:57">2025-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/24/%E4%BB%8E%E7%A6%BB%E6%95%A3%E7%9A%84tokenID%E5%88%B0%E5%85%B7%E6%9C%89%E8%AF%AD%E4%B9%89%E4%BF%A1%E6%81%AF%E7%9A%84embedding-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%BA%8C)/" title="从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)"><img src="https://i.miji.bid/2025/02/24/d3f99c0abebc6eb1a20faf08505cfc1f.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)"/></a><div class="content"><a class="title" href="/2025/02/24/%E4%BB%8E%E7%A6%BB%E6%95%A3%E7%9A%84tokenID%E5%88%B0%E5%85%B7%E6%9C%89%E8%AF%AD%E4%B9%89%E4%BF%A1%E6%81%AF%E7%9A%84embedding-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%BA%8C)/" title="从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)">从离散的token IDs到具有语义信息的embedding-大模型炼丹术(二)</a><time datetime="2025-02-24T14:28:29.000Z" title="发表于 2025-02-24 22:28:29">2025-02-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/20/%E4%BB%8Etokenizer%E8%AF%B4%E8%B5%B7%EF%BC%8C%E4%B8%BALLM%E8%87%AA%E5%9B%9E%E5%BD%92%E9%A2%84%E8%AE%AD%E7%BB%83%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%B8%80)/" title="从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)"><img src="https://i.miji.bid/2025/02/24/d3f99c0abebc6eb1a20faf08505cfc1f.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)"/></a><div class="content"><a class="title" href="/2025/02/20/%E4%BB%8Etokenizer%E8%AF%B4%E8%B5%B7%EF%BC%8C%E4%B8%BALLM%E8%87%AA%E5%9B%9E%E5%BD%92%E9%A2%84%E8%AE%AD%E7%BB%83%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF(%E4%B8%80)/" title="从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)">从tokenizer说起，为LLM自回归预训练准备数据集-大模型炼丹术(一)</a><time datetime="2025-02-20T14:28:29.000Z" title="发表于 2025-02-20 22:28:29">2025-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/30/%E6%8A%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%90%AC%E5%88%B0GPU-%E8%8B%B1%E4%BC%9F%E8%BE%BEDALI%E5%8A%A0%E9%80%9F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" title="把数据预处理搬到GPU-英伟达DALI加速数据预处理"><img src="https://ice.frostsky.com/2024/12/30/88a897ed803ad9cb7462f4320a31ac67.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="把数据预处理搬到GPU-英伟达DALI加速数据预处理"/></a><div class="content"><a class="title" href="/2024/12/30/%E6%8A%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%90%AC%E5%88%B0GPU-%E8%8B%B1%E4%BC%9F%E8%BE%BEDALI%E5%8A%A0%E9%80%9F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" title="把数据预处理搬到GPU-英伟达DALI加速数据预处理">把数据预处理搬到GPU-英伟达DALI加速数据预处理</a><time datetime="2024-12-30T13:32:21.000Z" title="发表于 2024-12-30 21:32:21">2024-12-30</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%91%93%E8%AF%AD%E7%B3%BB%E5%88%97%E8%BF%9E%E8%BD%BD/"><span class="card-category-list-name">呓语系列连载</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%82%BC%E4%B8%B9%E6%9C%AF/"><span class="card-category-list-name">大模型炼丹术</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"><span class="card-category-list-name">推荐系统</span><span class="card-category-list-count">18</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/"><span class="card-category-list-name">数据竞赛</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"><span class="card-category-list-name">机器学习算法</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="card-category-list-name">深度学习笔记</span><span class="card-category-list-count">95</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%A5%9E%E5%A5%87%E7%9A%84Python/"><span class="card-category-list-name">神奇的Python</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%B7%A8%E8%80%83%E5%B0%8F%E7%99%BD%E5%AD%A6%E5%88%B7%E9%A2%98/"><span class="card-category-list-name">跨考小白学刷题</span><span class="card-category-list-count">2</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/DL/" style="font-size: 1.5em; color: #99a9bf">DL</a> <a href="/tags/GAN/" style="font-size: 1.43em; color: #99a6b9">GAN</a> <a href="/tags/LLM/" style="font-size: 1.23em; color: #999ea6">LLM</a> <a href="/tags/ML/" style="font-size: 1.3em; color: #99a1ac">ML</a> <a href="/tags/Python/" style="font-size: 1.43em; color: #99a6b9">Python</a> <a href="/tags/RL/" style="font-size: 1.1em; color: #999">RL</a> <a href="/tags/Spark/" style="font-size: 1.1em; color: #999">Spark</a> <a href="/tags/Transformer/" style="font-size: 1.1em; color: #999">Transformer</a> <a href="/tags/%E5%91%93%E8%AF%AD/" style="font-size: 1.3em; color: #99a1ac">呓语</a> <a href="/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/" style="font-size: 1.1em; color: #999">性能优化</a> <a href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" style="font-size: 1.1em; color: #999">扩散模型</a> <a href="/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/" style="font-size: 1.37em; color: #99a4b2">推荐算法</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/" style="font-size: 1.17em; color: #999c9f">数据竞赛</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86/" style="font-size: 1.1em; color: #999">模型推理</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/" style="font-size: 1.1em; color: #999">计算机基础</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/03/"><span class="card-archive-list-date">三月 2025</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/02/"><span class="card-archive-list-date">二月 2025</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">十二月 2024</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">十月 2024</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">五月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/01/"><span class="card-archive-list-date">一月 2024</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">169</div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">358.3k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-03-07T15:36:42.215Z"></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/tag1.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By 雨落诗山山亦奇</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#subtitle", {
      strings: ["期望始终为零，方差交给时间"],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '期望始终为零，方差交给时间'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>