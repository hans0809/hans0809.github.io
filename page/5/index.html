<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>南极Python - Python|机器学习|深度学习</title><meta name="description" content="昨夜星辰昨夜风"><meta name="keywords" content="Python|机器学习|深度学习|生活感悟"><meta name="author" content="雨落诗山山亦奇"><meta name="copyright" content="雨落诗山山亦奇"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/avatar.png"><link rel="canonical" href="http://yoursite.com/page/5/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="website"><meta property="og:title" content="南极Python"><meta property="og:url" content="http://yoursite.com/page/5/"><meta property="og:site_name" content="南极Python"><meta property="og:description" content="昨夜星辰昨夜风"><meta property="og:image" content="http://yoursite.com/img/avatar.png"><meta property="article:published_time" content="2021-11-27T06:25:46.323Z"><meta property="article:modified_time" content="2021-11-27T06:25:46.323Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"我爱学习,机器学习,深度学习,学习使我快乐","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isSidebar: false,
  postUpdate: '2021-11-27 14:25:46'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><link rel="stylesheet" href="/css/mouse.css">
<link rel="stylesheet" href="/css/gundongtiao.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/macblack.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"> <link rel="stylesheet" href="/css/waigua.css"> <link rel="stylesheet" href="/css/beijing.css"><div class="aplayer" data-id="476185587" data-server="netease" data-type="playlist" data-fixed="true" data-listFolded="false" data-order="list" data-preload="auto"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/lete114/CDN/music/APlayer/APlayer.min.css"><script src="https://cdn.jsdelivr.net/gh/lete114/CDN/music/APlayer/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@1.2.0/dist/Meting.min.js"></script><meta name="generator" content="Hexo 4.2.1"></head><body><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">134</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">13</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">9</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><div id="web_bg" data-type="color"></div><header class="full_page" id="page-header" style="background-image: url(/img/tag1.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">南极Python</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="site-info"><h1 id="site_title">南极Python</h1><div id="site_subtitle"><span id="subtitle"></span></div></div><div id="scroll_down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout_page" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/05/31/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-MobileNet-v1/" title="经典卷积架构:MobileNet-v1">     <img class="post_bg" data-src="https://www.cdnjson.com/images/2021/06/06/franck-YOyZVglvuQ8-unsplash.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="经典卷积架构:MobileNet-v1"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/05/31/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-MobileNet-v1/" title="经典卷积架构:MobileNet-v1">经典卷积架构:MobileNet-v1</a><div class="article-meta-wrap"><time class="post-meta__date" title="发表于 2021-05-31 14:27:46"><i class="far fa-calendar-alt"></i>2021-05-31</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">MobileNet V1MobileNet V1 有点像VGG，它们的网络结构都是单分支的，通俗点说就是：一条路走到底。
只不过，相比于VGG，MobileNet V1 大量使用了深度可分离卷积，在模型的预测能力变化很小的前提下，极大地提升了模型的速度。
ps：关于深度可分离卷积，可以查看这篇文章；关于VGG，可以查看这篇文章。
MobileNet V1 的网络结构如下：
其中，Conv表示普通卷积，Conv dw表示逐通道卷积，s1表示卷积步长为1，s2表示卷积步长为2。
PyTorch 实现 MobileNet V1对于普通的卷积，即上面结构图中的Conv直接调用torch.nn.Conv2d就可以了；
而在上面的网络结构图中，每一个蓝色框起来的两部分组合起来就是深度可分离卷积，它包括了逐通道卷积(Conv dw)和逐点卷积(Conv，kernel_size=1)，其结构如下(左侧是普通卷积，右侧是深度可分离卷积)：
根据这个结构，就可以写代码实现深度可分离卷积了：
1234567891011121314151617181920212223242526272829303132333 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/05/27/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-Xception/" title="经典卷积架构:Xception">     <img class="post_bg" data-src="https://www.cdnjson.com/images/2021/06/06/zoltan-tasi-APvZiFU7v1A-unsplash.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="经典卷积架构:Xception"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/05/27/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-Xception/" title="经典卷积架构:Xception">经典卷积架构:Xception</a><div class="article-meta-wrap"><time class="post-meta__date" title="发表于 2021-05-27 13:00:28"><i class="far fa-calendar-alt"></i>2021-05-27</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">XceptionXception将Inception中的Inception模块替换为深度可分离卷积。在几乎不增加参数量的前提下，Xception在一些图像分类任务中的表现超越了Inception V3。 
我们之前介绍的深度可分离卷积是先做逐通道卷积，再做逐点卷积，而在Xception的论文描述中，这两步的顺序正好相反（见下图）。不过没关系，论文中也指出，这里的顺序并不影响效果（理由：in particular because these operations are meant to be used in a stacked setting.）。

同时，经过实验发现，深度可分离卷积中的卷积层之间不加非线性激活函数的效果相较于加入非线性激活函数来说会更好一些。
Xception的网络结构如下：
网络总共可以分为3个部分：Entry flow，Middle flow，以及Exit flow，并且借鉴了ResNet的思想，引入了跳连(skip connection)。注意每个卷积（包括普通卷积与深度可分离卷积）之后都做了批归一化操作，只是没在网络结构图中画出。
PyTorch 实现Xce ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/05/25/%E5%88%86%E7%BB%84%E5%8D%B7%E7%A7%AF%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF/" title="分组卷积与深度可分离卷积">     <img class="post_bg" data-src="https://www.cdnjson.com/images/2021/06/06/austin-scherbarth-qSrFTyh-IB0-unsplash.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="分组卷积与深度可分离卷积"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/05/25/%E5%88%86%E7%BB%84%E5%8D%B7%E7%A7%AF%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF/" title="分组卷积与深度可分离卷积">分组卷积与深度可分离卷积</a><div class="article-meta-wrap"><time class="post-meta__date" title="发表于 2021-05-25 13:21:24"><i class="far fa-calendar-alt"></i>2021-05-25</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">分组卷积(Group Convolution)分组卷积将输入特征图进行分组，分别对每组的特征图进行卷积操作，得到输出的特征图，最后再将每组卷积后得到的特征图拼接在一起，就完成了整个卷积操作。
在PyTorch中，输入特征图个数与输出特征图个数需要能够被分组数整除，因为输出特征图个数需要均摊给每一组。比如输入特征图个数为X，输出特征图个数为Y，分组数为g，且g可整除X和Y，那么每一组的输入特征图个数为X/g，输出特征图个数为Y/g，总的输出特征图个数为(Y/g)*g=Y
假设输入特征图个数为6，卷积核尺寸为3*3，输出特征图个数为10，不考虑偏置项。以下操作基于本例》
普通卷积：当分组数为1时，就是普通的卷积
12345678910import torchimport torch.nn as  nnfrom torchsummary import summaryclass Model(nn.Module):    def __init__(self):        super().__init__()        self.conv=nn.Conv2d(in_channels=6,o ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/05/22/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-ResNet/" title="经典卷积架构:ResNet">     <img class="post_bg" data-src="https://www.cdnjson.com/images/2021/06/06/gleb-lucky-7U7Km6fcTKM-unsplash48e9975514f5d208.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="经典卷积架构:ResNet"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/05/22/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-ResNet/" title="经典卷积架构:ResNet">经典卷积架构:ResNet</a><div class="article-meta-wrap"><time class="post-meta__date" title="发表于 2021-05-22 19:50:42"><i class="far fa-calendar-alt"></i>2021-05-22</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">ResNet一般来说，网络越深越复杂，同时网络提取特征的能力也就越强。但是，实验发现，当继续增加网络层数，使得网络越来越深时，网络能力不增反减。
似乎，当网络层数达到一定程度时，就达到了深度学习的天花板了？
ResNet的提出，解决了这一问题。深度学习的天花板还远着呢！
对于一个浅层网络，我们想在此基础上加深网络，同时希望加深后的网络至少能力不能退化。也就是说，新加进来的几层即使不能提升网络的能力，也不要影响到加入这些新的层之前的网络的能力。
具体地，直接将添加新的层之前的网络输出与添加新的层之后的网络输出做一个加法，然后让网络自己去学习新加进来的层是否起作用，起多大的作用。
这样，如果新加进来的层不怎么起作用，那么网络最终的输出就是添加新的层之前的输出，这样就能保证网络的能力至少不会因为网络的加深而退化。

这张图描绘了上述文字所要传达的思想：
对于浅层网络的输出x，有两个分支，一个分支直线向下，代表映射F，它将x映射为F(x)；另一个分支直接将x连接到F(x)处，这被称之为skip connection(跳连)。这样，输出等于浅层网络的输出x与加深后的网络输出F(x)之和，即F(x ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/05/17/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-GoogLeNet/" title="经典卷积架构:GoogLeNet">     <img class="post_bg" data-src="https://www.cdnjson.com/images/2021/05/05/jasper-geys-NyRe1Mj1pm4-unsplash.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="经典卷积架构:GoogLeNet"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/05/17/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-GoogLeNet/" title="经典卷积架构:GoogLeNet">经典卷积架构:GoogLeNet</a><div class="article-meta-wrap"><time class="post-meta__date" title="发表于 2021-05-17 10:10:37"><i class="far fa-calendar-alt"></i>2021-05-17</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">GoogLeNetGoogLeNet，也叫做Inception，没错，翻译过来就是《盗梦空间》。
相较于之前的网络，GoogLeNet网络层数更多，网络变得更深，网络结构也变得更加复杂。
不过，虽然网络结构复杂，但由于使用了1*1卷积来减少通道数，GoogLeNet所包含的参数不增反减，这也是GoogLeNet表现如此出众的重要原因之一。
GoogleNet的网络结构参数表如下：
type：网络层类型patch size/stride：(卷积核or池化窗口)尺寸/（卷积/池化）步长output size：该层输出特征图的shape
GoogLeNet重复使用了inception，和NiN基础块一样，它也是一个单独的块，不妨记作inception block，蓝色框起来的是便是inception block需要的参数。
inception block结构如下：
inception block使用了4个并行的分支，最后在通道维度上将4个分支的结果做了concat融合。这样，网络变宽了，我们无需考虑到底是用卷积层还是池化层，卷积核的尺寸是3x3还是5x5比较好，这一切，都交给模型，让模型自己 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/05/15/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%B8%AD%E7%9A%84IoU%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3-PyTorch%E5%AE%9E%E7%8E%B0/" title="语义分割中的IoU理论讲解+PyTorch实现">     <img class="post_bg" data-src="https://www.cdnjson.com/images/2021/05/17/1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="语义分割中的IoU理论讲解+PyTorch实现"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/05/15/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%B8%AD%E7%9A%84IoU%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3-PyTorch%E5%AE%9E%E7%8E%B0/" title="语义分割中的IoU理论讲解+PyTorch实现">语义分割中的IoU理论讲解+PyTorch实现</a><div class="article-meta-wrap"><time class="post-meta__date" title="发表于 2021-05-15 10:37:29"><i class="far fa-calendar-alt"></i>2021-05-15</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">语义分割中的IoU之前的文章介绍过目标检测中的IoU，它等于预测框与真实框的交集区域面积除以并集区域面积。
在语义分割问题中，IoU经常被作为指标来评估模型学习的好坏。和目标检测中的IoU一样，语义分割中的IoU也是用预测结果和真实结果的交集除以并集。
只不过，语义分割问题并不像目标检测问题那样存在所谓的框，它通常是对每个像素进行分类，然后根据分类结果分别计算每个类别的交集和并集，从而进一步计算得到IoU。
因此，语义分割问题的IoU计算方式会与目标检测中IoU的计算方式会有所不同（两者思想一样，具体计算方式不一样）。
计算IoU需要预测类别和真实类别，后者是已知的，而前者需要模型去预测，再经过一些后处理得到。将模型预测值转为我们需要的预测类别的步骤（即：后处理过程）如下：
输入1张shape为C*H*W的图片，输出的shape为C&#39;*H*W。C表示图片通道数，一般是3，C&#39;表示语义分割问题的总类别数，比如一共有4类，那么C&#39;=4。在C&#39;所在维度上做个切片，比如C&#39;[:,3,3]取了坐标为[3,3]的像素点在C&#39;维度上的取值，该取值是一个 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/05/14/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-NiN/" title="经典卷积架构:NiN">     <img class="post_bg" data-src="https://www.cdnjson.com/images/2021/05/17/chloe-lam-I4ScSrKsfIg-unsplash.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="经典卷积架构:NiN"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/05/14/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-NiN/" title="经典卷积架构:NiN">经典卷积架构:NiN</a><div class="article-meta-wrap"><time class="post-meta__date" title="发表于 2021-05-14 23:54:36"><i class="far fa-calendar-alt"></i>2021-05-14</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">NiNNiN在已有网络的基础上进行了改进，并且这些改进影响了后续网络模型的发展。经典之作，值得回味，今天我们就来一起实现它~
NiN的网络结构主要由多个NiN基础块堆叠而成。
1*1卷积NiN基础块含有3个卷积层，除了第一个卷积层，其余两个卷积层的卷积核尺寸都是1*1的，这种卷积核不会改变特征图的尺寸，并且可以在不增加太多参数量的前提下，实现通道数的变化，相当于是将每个通道上的特征图做了一个融合(比如，卷之前，维度是[C,224*224]，卷之后，维度是[D,224*224]，看吧，只有通道数发生了变化)。
全局平均池化在网络尾部进行分类结果输出时，NiN使用了全局平均池化层来代替之前的网络中使用的全连接层，这种提取全局信息的方式极大的减少了网络参数量，同时也不会像全连接层那样容易导致模型过拟合。你可以对比之前介绍的AlexNet，它在最后使用全连接层来输出分类结果，而这里的NiN使用的是全局平均池化。
NiN将网络最后一个NiN基础块的输出通道数设置为总类别数，紧接其后的全局平均池化层会在通道维度上对每张特征图求平均。假设总类别为10，那么就会有10个通道，经过全局平均池化层就能得到 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/05/12/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-VGG%E7%B3%BB%E5%88%97/" title="经典卷积架构:VGG系列">     <img class="post_bg" data-src="https://www.cdnjson.com/images/2021/05/17/marek-piwnicki-f9NK7nkxgJ8-unsplash.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="经典卷积架构:VGG系列"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/05/12/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-VGG%E7%B3%BB%E5%88%97/" title="经典卷积架构:VGG系列">经典卷积架构:VGG系列</a><div class="article-meta-wrap"><time class="post-meta__date" title="发表于 2021-05-12 20:28:44"><i class="far fa-calendar-alt"></i>2021-05-12</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">VGGVGG的提出者所在实验室名字为Visual Geometry Group ，因此就地取名，VGG诞生了。
VGG通过堆叠大量的VGG块，实现了更深的网络结构。
这里的VGG块，包含了多个卷积层一个池化层：

卷积层的卷积核尺寸为3*3，stride为1，padding为1；这种结构保证了输入图片(或特征图)经过卷积后得到的特征图的尺寸与输入尺寸是一样的。也就是或，卷积仅仅改变通道数，而不改变图像(特征图)的尺寸。

池化层的池化窗口尺寸和stride都是2，从而使得特征图的尺寸减半。


在堆叠的多个VGG块之后，是一些全连接层，负责最后的分类结果输出。
根据网络层数的不同，VGG有多个版本，如下图：

可以看出，不同版本之间的差异体现在卷积层（VGG 块个数不同），而全连接层是通用的。
在代码实现时，我们将写一个基本通用的框架，它可以帮助我们快捷实现不同版本的VGG。
注意：

我们将忽略现在已经不怎么使用的LRN，并且会添加一些现在常用的网络层，如ReLU，BN等。
对于图中的第4列(C)，该框架不是通用的，因为含有1*1卷积。不过这对于实现来说完全不是问题，比如将全部层堆叠 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/05/11/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-AlexNet/" title="经典卷积架构:AlexNet">     <img class="post_bg" data-src="https://www.cdnjson.com/images/2021/05/05/jasper-geys-NyRe1Mj1pm4-unsplash.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="经典卷积架构:AlexNet"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/05/11/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-AlexNet/" title="经典卷积架构:AlexNet">经典卷积架构:AlexNet</a><div class="article-meta-wrap"><time class="post-meta__date" title="发表于 2021-05-11 15:04:29"><i class="far fa-calendar-alt"></i>2021-05-11</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">AlexNet在2012年的Imagenet竞赛中，AlexNet以低于第二名10.8个百分点的top-5错误率赢得了冠军，自此以后，基于CNN的图像分类算法开始流行起来，深度学习时代到来了。

AlexNet的网络结构如上图所示。相比于之前的LeNet-5，AlexNet堆叠了更多的卷积块，从而网络更深。同时，它还引入了Dropout的技巧，以及ReLU激活函数等。
在AlexNet刚被提出时，受限于当时的算力，作者采用了多个GPU进行训练。而随着技术的发展，现在的算力已经可以在单卡上训练AlexNet了，且显存绰绰有余。
更多细节，将在代码实现中体现。
PyTorch 实现AlexNet代码实现时，去除了现在已经很少被使用的LRN(局部响应归一化)；并且将最后一个池化层由最大池化改为自适应平均池化，这种池化方法可以将不同尺寸的输入图片固定到特定尺寸，于是就可以固定住该池化层后面紧挨着的第一个全连接层的参数（最后一个池化层到第一个全连接之间有一个flatten操作，由于池化层输出的尺寸是固定的，因此flatten后再输入到这个全连接层的神经元个数也是固定的），使用起来更加方便。
12 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/05/10/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-LeNet-5/" title="经典卷积架构:LeNet-5">     <img class="post_bg" data-src="https://www.cdnjson.com/images/2021/05/17/tim-marshall-qKlD2QlK-CY-unsplash.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="经典卷积架构:LeNet-5"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/05/10/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E6%9E%B6%E6%9E%84-LeNet-5/" title="经典卷积架构:LeNet-5">经典卷积架构:LeNet-5</a><div class="article-meta-wrap"><time class="post-meta__date" title="发表于 2021-05-10 12:19:50"><i class="far fa-calendar-alt"></i>2021-05-10</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a></span></div><div class="content">LeNet-5LeNet-5作为CNN的开山之作，在如今看来并不复杂，但在当时可以称得上是开创性的成就，并且其之后出现的许多卷积架构基本遵循LeNet-5的思想。LeNet-5的网络结构如上图所示，它最开始被用于解决手写数字识别问题。
对于一张32*32单通道手写数字图片，首先经过卷积（kernel_size: 5）得到6张28*28的特征图，然后做下采样(池化,kernel_size=2,stride=2)将特征图尺寸减半；接着经过一顿卷，得到120张1*1的特征图；将其展平，得到120维的向量，经过两个全连接层，输出10维的向量，代表该图片中的数字取值的概率（取值集合为0到9）。
当然，卷积与池化操作之间做了激活操作，在当时用的Simoid和Tanh。在稍后的代码实现中，我们会改成现在更常用的ReLU。更多细节，将在代码实现中体现。
PyTorch 实现LeNet-5123456789101112131415161718192021222324252627282930import torchimport torch.nn as nnclass LeNet(nn.Module):   ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/4/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/6/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">雨落诗山山亦奇</div><div class="author-info__description">昨夜星辰昨夜风</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives"><div class="headline">文章</div><div class="length_num">134</div></a></div><div class="card-info-data-item is-center">      <a href="/tags"><div class="headline">标签</div><div class="length_num">13</div></a></div><div class="card-info-data-item is-center">     <a href="/categories"><div class="headline">分类</div><div class="length_num">9</div></a></div></div><div class="card-info-bookmark is-center"><button class="button--animated" id="bookmark-it" type="button" title="加入书签"><i class="fas fa-bookmark"></i><span>加入书签</span></button></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">本站的时光机正在紧急研发中，预计很快便能实现时间旅行了orz~</div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-recent-item"><div class="aside-recent-post"><a href="/2021/11/23/%E7%BB%8F%E5%85%B8%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B-NFM/"><div class="aside-post-cover"><img class="aside-post-bg" data-src="https://www.cdnjson.com/images/2021/11/23/2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" title="经典推荐模型:NFM" alt="经典推荐模型:NFM"/></div><div class="aside-post-title"><div class="aside-post_title" href="/2021/11/23/%E7%BB%8F%E5%85%B8%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B-NFM/" title="经典推荐模型:NFM">经典推荐模型:NFM</div><time class="aside-post_meta post-meta__date" title="发表于 2021-11-23 21:34:19">2021-11-23</time></div></a></div><div class="aside-recent-post"><a href="/2021/11/19/%E7%94%A8Python%E5%AE%9E%E7%8E%B0%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95/"><div class="aside-post-cover"><img class="aside-post-bg" data-src="https://www.cdnjson.com/images/2021/11/19/122.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" title="用Python实现协同过滤算法" alt="用Python实现协同过滤算法"/></div><div class="aside-post-title"><div class="aside-post_title" href="/2021/11/19/%E7%94%A8Python%E5%AE%9E%E7%8E%B0%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95/" title="用Python实现协同过滤算法">用Python实现协同过滤算法</div><time class="aside-post_meta post-meta__date" title="发表于 2021-11-19 14:39:33">2021-11-19</time></div></a></div><div class="aside-recent-post"><a href="/2021/11/18/%E7%BB%8F%E5%85%B8%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B-FNN/"><div class="aside-post-cover"><img class="aside-post-bg" data-src="https://www.cdnjson.com/images/2021/11/21/marc-olivier-jodoin-NqOInJ-ttqM-unsplash.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" title="经典推荐模型:FNN，DeepFM" alt="经典推荐模型:FNN，DeepFM"/></div><div class="aside-post-title"><div class="aside-post_title" href="/2021/11/18/%E7%BB%8F%E5%85%B8%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B-FNN/" title="经典推荐模型:FNN，DeepFM">经典推荐模型:FNN，DeepFM</div><time class="aside-post_meta post-meta__date" title="发表于 2021-11-18 13:54:19">2021-11-18</time></div></a></div><div class="aside-recent-post"><a href="/2021/11/17/%E5%9F%BA%E4%BA%8ENeuralCF%E7%9A%84%E5%9B%BE%E4%B9%A6%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"><div class="aside-post-cover"><img class="aside-post-bg" data-src="https://www.cdnjson.com/images/2021/11/02/7.png" onerror="this.onerror=null;this.src='/img/404.jpg'" title="基于NeuralCF的图书推荐系统" alt="基于NeuralCF的图书推荐系统"/></div><div class="aside-post-title"><div class="aside-post_title" href="/2021/11/17/%E5%9F%BA%E4%BA%8ENeuralCF%E7%9A%84%E5%9B%BE%E4%B9%A6%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" title="基于NeuralCF的图书推荐系统">基于NeuralCF的图书推荐系统</div><time class="aside-post_meta post-meta__date" title="发表于 2021-11-17 15:40:50">2021-11-17</time></div></a></div><div class="aside-recent-post"><a href="/2021/11/16/%E7%AE%97%E6%B3%95(%E4%B8%8A)/%E7%AE%97%E6%B3%95(%E4%B8%8A)/"><div class="aside-post-cover"><img class="aside-post-bg" data-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" title="算法(上)/算法(上)" alt="算法(上)/算法(上)"/></div><div class="aside-post-title"><div class="aside-post_title" href="/2021/11/16/%E7%AE%97%E6%B3%95(%E4%B8%8A)/%E7%AE%97%E6%B3%95(%E4%B8%8A)/" title="算法(上)/算法(上)">算法(上)/算法(上)</div><time class="aside-post_meta post-meta__date" title="发表于 2021-11-16 16:34:08">2021-11-16</time></div></a></div></div></div></div><div class="card-widget card-categories"><div class="card-content"><div class="item-headline"><i class="fas fa-folder-open"></i><span>分类</span></div><ul class="card-category-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%91%93%E8%AF%AD%E7%B3%BB%E5%88%97%E8%BF%9E%E8%BD%BD/"><span class="card-category-list-name">呓语系列连载</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"><span class="card-category-list-name">大数据</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"><span class="card-category-list-name">推荐系统</span><span class="card-category-list-count">17</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/"><span class="card-category-list-name">数据竞赛</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"><span class="card-category-list-name">机器学习算法</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="card-category-list-name">深度学习笔记</span><span class="card-category-list-count">70</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%A5%9E%E5%A5%87%E7%9A%84Python/"><span class="card-category-list-name">神奇的Python</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%B7%A8%E8%80%83%E5%B0%8F%E7%99%BD%E5%AD%A6%E5%88%B7%E9%A2%98/"><span class="card-category-list-name">跨考小白学刷题</span><span class="card-category-list-count">3</span></a></li>
            <li class="card-category-list-item more is-center"><a class="card-category-list-link-more" href="/categories">
                <span>查看更多</span><i class="fas fa-angle-right"></i></a></li>           
            </ul></div></div><div class="card-widget card-tags"><div class="card-content"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/6D%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/" style="font-size: 17.33px; color: #999da1">6D姿态估计</a> <a href="/tags/CV/" style="font-size: 16.67px; color: #999b9d">CV</a> <a href="/tags/DL/" style="font-size: 22px; color: #99a9bf">DL</a> <a href="/tags/GAN/" style="font-size: 20px; color: #99a4b2">GAN</a> <a href="/tags/ML/" style="font-size: 18px; color: #999ea6">ML</a> <a href="/tags/Python/" style="font-size: 21.33px; color: #99a7bb">Python</a> <a href="/tags/RL/" style="font-size: 16px; color: #999">RL</a> <a href="/tags/Spark/" style="font-size: 16px; color: #999">Spark</a> <a href="/tags/Tensorflow/" style="font-size: 19.33px; color: #99a2ae">Tensorflow</a> <a href="/tags/%E5%91%93%E8%AF%AD/" style="font-size: 18.67px; color: #99a0aa">呓语</a> <a href="/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/" style="font-size: 20.67px; color: #99a5b7">推荐算法</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/" style="font-size: 16.67px; color: #999b9d">数据竞赛</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/" style="font-size: 16px; color: #999">计算机基础</a></div></div></div><div class="card-widget card-archives"><div class="card-content"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/11/"><span class="card-archive-list-date">十一月 2021</span><span class="card-archive-list-count">14</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/10/"><span class="card-archive-list-date">十月 2021</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/09/"><span class="card-archive-list-date">九月 2021</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/08/"><span class="card-archive-list-date">八月 2021</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/07/"><span class="card-archive-list-date">七月 2021</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/06/"><span class="card-archive-list-date">六月 2021</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/05/"><span class="card-archive-list-date">五月 2021</span><span class="card-archive-list-count">15</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/04/"><span class="card-archive-list-date">四月 2021</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item more is-center"><a class="card-archive-list-link-more" href="/archives">
              <span>查看更多</span><i class="fas fa-angle-right"  ></i></a></li></ul></div></div><div class="card-widget card-webinfo"><div class="card-content"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="webinfo-article-name">文章数目 :</div><div class="webinfo-article-count">134</div></div><div class="webinfo-item"><div class="webinfo-runtime-name">已运行时间 :</div><div class="webinfo-runtime-count" id="webinfo-runtime-count" publish_date="7/2/2020 18:00:00">     </div></div><div class="webinfo-item"><div class="webinfo-site-wordcount-name">本站总字数 :</div><div class="webinfo-site-wordcount">314.6k</div></div><div class="webinfo-item">      <div class="webinfo-site-uv-name">本站访客数 :</div><div class="webinfo-site-uv-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="webinfo-site-name">本站总访问量 :</div><div class="webinfo-site-pv-count" id="busuanzi_value_site_pv"></div></div></div></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 雨落诗山山亦奇</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script defer id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
document.body.addEventListener('input', POWERMODE);
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/third-party/ClickShowText.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js"></script><script>var subtitleEffect = true
if (subtitleEffect) { 
  var typed = new Typed("#subtitle", {
    strings: "期望始终为零，方差交给时间".split(","),
    startDelay: 300,
    typeSpeed: 150,
    loop: true,
    backSpeed: 50
  })
} else {
  document.getElementById("subtitle").innerHTML = '期望始终为零，方差交给时间'
}</script><script src="https://cdn.jsdelivr.net/gh/lete114/CDN/Sum/sakura.js"></script><script src="/js/egao.js"></script><script src="/js/snow.js"></script></body></html>